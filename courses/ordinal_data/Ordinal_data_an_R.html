<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8" />
<meta name="generator" content="quarto-1.3.450" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />

<meta name="author" content="Matteo Ventura" />
<meta name="dcterms.date" content="2025-06-09" />

<title>Matteo Ventura – Ordinal Data Analysis in R</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<!-- htmldependencies:E3FAD763 -->
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-listing .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: [{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] },{ data: ['listing-file-modified-sort'] }],
      
      searchColumns: [],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-listing'] = new List('listing-listing', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  </script>

<link href="../../site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="../../site_libs/pagedtable-1.1/js/pagedtable.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css" />
<link rel="stylesheet" href="styles.css" />
</head>

<body>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="/index.html">
    <span class="navbar-title">Matteo Ventura</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse"
  aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation"
  onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="/about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="/publications.html" rel="" target="">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="/courses.html" rel="" target="">
 <span class="menu-text">Courses</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="/contacts.html" rel="" target="">
 <span class="menu-text">Contacts</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div id="quarto-toc-target"></div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" ></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Ordinal Data Analysis in R</h1>
<p class="subtitle lead">Measuring Human Perceptions from Surveys</p>
  <div class="quarto-categories">
    <div class="quarto-category">ordinal data</div>
    <div class="quarto-category">CUB</div>
    <div class="quarto-category">survey</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Matteo Ventura </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 9, 2025</p>
    </div>
  </div>
  
    
  </div>
  

</header>
<nav id="TOC" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-to-ordinal-data-and-survey-design" id="toc-introduction-to-ordinal-data-and-survey-design"><span class="header-section-number">1</span> Introduction to Ordinal Data and Survey Design</a>
  <ul>
  <li><a href="#the-role-of-measurement-in-science" id="toc-the-role-of-measurement-in-science"><span class="header-section-number">1.1</span> The Role of Measurement in Science</a></li>
  <li><a href="#scales-and-questionnaires-development" id="toc-scales-and-questionnaires-development"><span class="header-section-number">1.2</span> Scales and Questionnaires development</a></li>
  <li><a href="#visualizing-ordinal-data" id="toc-visualizing-ordinal-data"><span class="header-section-number">1.3</span> Visualizing Ordinal Data</a></li>
  </ul></li>
  <li><a href="#classical-models-for-ordinal-data" id="toc-classical-models-for-ordinal-data"><span class="header-section-number">2</span> Classical Models for Ordinal Data</a>
  <ul>
  <li><a href="#limitations-of-most-commonly-used-models" id="toc-limitations-of-most-commonly-used-models"><span class="header-section-number">2.1</span> Limitations of most commonly used models</a></li>
  <li><a href="#modeling-cumulative-probabilities" id="toc-modeling-cumulative-probabilities"><span class="header-section-number">2.2</span> Modeling Cumulative Probabilities</a></li>
  <li><a href="#the-cumulative-logit-with-proportional-odds-assumption" id="toc-the-cumulative-logit-with-proportional-odds-assumption"><span class="header-section-number">2.3</span> The Cumulative Logit with Proportional Odds Assumption</a></li>
  <li><a href="#coefficients-interpretation" id="toc-coefficients-interpretation"><span class="header-section-number">2.4</span> Coefficients interpretation</a></li>
  <li><a href="#beyond-the-proportional-odds-logit-model" id="toc-beyond-the-proportional-odds-logit-model"><span class="header-section-number">2.5</span> Beyond the Proportional Odds Logit Model</a></li>
  <li><a href="#alternative-model-structures" id="toc-alternative-model-structures"><span class="header-section-number">2.6</span> Alternative Model Structures</a></li>
  </ul></li>
  <li><a href="#beyond-standard-approaches-modeling-ordinal-data-with-cub-models" id="toc-beyond-standard-approaches-modeling-ordinal-data-with-cub-models"><span class="header-section-number">3</span> Beyond Standard Approaches: Modeling Ordinal Data with CUB Models</a>
  <ul>
  <li><a href="#the-psychological-reasons-behind-the-cub-model" id="toc-the-psychological-reasons-behind-the-cub-model"><span class="header-section-number">3.1</span> The Psychological Reasons Behind the CUB Model</a></li>
  <li><a href="#the-cub-model-statistical-formulation" id="toc-the-cub-model-statistical-formulation"><span class="header-section-number">3.2</span> The CUB Model: Statistical Formulation</a></li>
  <li><a href="#extensions-of-the-cub-model-incorporating-covariates" id="toc-extensions-of-the-cub-model-incorporating-covariates"><span class="header-section-number">3.3</span> Extensions of the CUB Model: Incorporating Covariates</a></li>
  <li><a href="#cub-model-with-shelter-option" id="toc-cub-model-with-shelter-option"><span class="header-section-number">3.4</span> CUB Model with Shelter Option</a></li>
  <li><a href="#treatment-of-dont-know-dk-options-within-the-cub-framework" id="toc-treatment-of-dont-know-dk-options-within-the-cub-framework"><span class="header-section-number">3.5</span> Treatment of “Don’t Know” (DK) Options within the CUB Framework</a></li>
  </ul></li>
  </ul>
</nav>
<!-- <p> -->
<!--   <a href="materials/CUM7vsCUB.r" download style="margin-right: 15px;"> -->
<!--     <i class="bi bi-file-earmark-code-fill" style="font-size: 1.2em; vertical-align: middle;"></i> -->
<!--     <span style="margin-left: 5px; vertical-align: middle;">R Script</span> -->
<!--   </a> -->
<!--   <a href="materials/CV_VENTURA_ITA_nodata.pdf" download> -->
<!--     <i class="bi bi-file-earmark-slides-fill" style="font-size: 1.2em; vertical-align: middle;"></i> -->
<!--     <span style="margin-left: 5px; vertical-align: middle;">Slides</span> -->
<!--   </a> -->
<!-- </p> -->
<div class="cell">
<style> p { text-align: justify; } </style>
</div>
<h1>
Description of the course
</h1>
<p>Surveys are key tools for measuring human perceptions, capturing latent traits through structured responses. Among the data they generate, ordinal and rating data are particularly important yet often less studied, requiring specialized statistical techniques. Ordinal data appears frequently in real-world applications, such as customer satisfaction surveys, psychological assessments, and medical research, making its correct analysis crucial for obtaining reliable insights. This short course provides instructor-led, hands-on training in the analysis of ordinal data. It begins with an overview of survey design and the validation of results, focusing on building effective surveys and ensuring the reliability of the data obtained. The course then covers the most commonly used statistical models for analyzing ordinal data, with an emphasis on discovering latent patterns and traits. Both theoretical foundations and practical applications will be explored, using real-world case studies from domains such as marketing, social sciences, tourism and culture.</p>
<p>A common approach to analyzing ordinal data is to treat it as numerical, but this can lead to a loss of statistical power. In this course, participants will learn how to apply specialized methods designed for ordinal data, allowing them to draw more effective and reliable conclusions.</p>
<h1>
Objectives of the course
</h1>
<p>By the end of the course, participants will have both theoretical knowledge and practical skills to analyze ordinal data in research and professional settings. Specifically, they will be able to:</p>
<ul>
<li>Understand what ordinal data is, how it differs from other types of data, and the challenges involved in its analysis</li>
<li>Compute and interpret reliability and validity measures</li>
<li>Fit proportional odds models in R and interpret the results</li>
<li>Analyse rating data by applying CUB models</li>
</ul>
<section id="introduction-to-ordinal-data-and-survey-design" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction to Ordinal Data and Survey Design</h1>
<div class="column-margin">
<p>
<a href="materials/Script_plots_examples.R" download style="margin-right: 5px;"> <i class="bi bi-file-earmark-code-fill" style="font-size: 0.9em; vertical-align: middle;"></i> <span style="margin-left: 2px; vertical-align: middle;">R Script</span> </a>
</p>
<p>
<a href="materials/Ordinal Data Analysis in R - Module 1.pdf" download> <i class="bi bi-file-earmark-slides-fill" style="font-size: 0.9em; vertical-align: middle;"></i> <span style="margin-left: 2px; vertical-align: middle;">Slides</span> </a>
</p>
</div>
<section id="the-role-of-measurement-in-science" class="level2" data-number="1.1">
<h2 data-number="1.1"><span class="header-section-number">1.1</span> The Role of Measurement in Science</h2>
<p>Measurement is a fundamental activity in science, indeed we acquire knowledge about the world around us by observing it, and we usually quantify to give a sense to what we observe. Therefore, measurement is essential in a wide range of research contexts.</p>
<p>There exist several situations in which scientists come up with measurement problems, even though they are not interested primary in measurement. For instance:</p>
<ol type="1">
<li><p>A health psychologist needs a measurement scale which doesn’t seem to exist. The study depends on a tool that can clearly distinguish between what individuals want to happen and what they expect to happen when visiting a physician. However, the review of previous research reveals that existing scales often blur this distinction, unintentionally mixing the two concepts. None of the available instruments capture the separation in the specific way her study requires. While the psychologist could create a few items that appear to address the difference between wants and expectations, she/he is concerned that these improvised questions may lack the reliability and validity necessary to serve as accurate measures.</p></li>
<li><p>An epidemiologist is conducting secondary analyses on data from a national health survey. They wish to investigate the link between perceived psychological stress and health status. Unfortunately, the survey did not include a validated stress measure. While it may be possible to construct one using existing items, a poorly constructed scale could lead to misleading conclusions.</p></li>
<li><p>A marketing team is struggling to design a campaign for a new line of high-end infant toys. Focus groups suggest that parents are heavily influenced by a toy’s perceived educational value. The team hypothesizes that parents with strong educational and career aspirations for their children are more likely to be interested in the product. To test this idea across a broad, geographically diverse sample, the team needs a way to reliably measure parental aspirations. Something that additional focus groups can’t easily provide.</p></li>
</ol>
<p>Despite coming from different disciplines, these researchers share a common understanding: using arbitrary or poorly designed measurement tools increases the risk of collecting inaccurate data. As a result, developing their own carefully constructed measurement instruments appears to be the most reliable solution.</p>
<p>Historically, measurement problems were well-known in natural sciences such as physics and astronomy, even concerning figures like Isaac Newton. However, among social scientists, a debate arose regarding the measurability of psychological variables. While physical attributes like mass and length seem to possess an intrinsic mathematical structure similar to positive real numbers, the measurement of psychological variables was considered impossible by the Commission of the British Association for the Advancement of Science. The primary reason was the difficulty in objectively ordering or summing sensory perceptions, as well illustrated by the question: how can one establish that a sensation of “a little warm” plus another similar sensation equals “twice as warm”?</p>
<section id="measurement-classification" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Measurement classification</h3>
<p>The americal psychologist Stevens (1946) disagreed with this perspective. He contended that the rigid requirement of “strict additivity,” as seen in measurements of length or mass, was not essential for measuring sensations. He pointed out that individuals could make reasonably consistent ratio judgments regarding the loudness of sounds. For instance, they could determine if one sound was twice as loud as another.</p>
<p>Stevens further argued that this “ratio” characteristic enabled the data derived from such measurements to be mathematically analyzed. He is known for categorizing measurements into nominal, ordinal, interval, and ratio scales. In his view, judgments about sound “loudness” belonged to the ratio scale.</p>
<p>Despite the classification proposed by Stevens has been criticized by several authors and new classifications has been proposed, it is the most commonly accepted and used internationally.</p>
<p>Stevens identified four properties for describing the scales of measurement:</p>
<ul>
<li><strong>Identity</strong>: each value has a unique meaning.</li>
<li><strong>Magnitude</strong>: the values of the variable have an ordered relationship to one another, so there is a specific order to the variables.</li>
<li><strong>Equal intervals</strong>: the data points along the scale are equally spaced, so the difference between data points one and two, is the same as data points three and four.</li>
<li><strong>A minimum value of zero</strong>: the scale has a true zero point.</li>
</ul>
<p>As previously said, Stevens identified four scales of measurement, that is how variables are defined and categorised:</p>
<ul>
<li><p><strong>Nominal scale of measurement</strong>: This scale has certain characteristics, but doesn’t have any form of numerical meaning. The data can be placed into categories but can’t be multiplied, divided, added or subtracted from one another. It’s also not possible to measure the difference between data points. It defines only the identity property of data.<br />
Examples: Gender, Etnicity, Eye colour…</p></li>
<li><p><strong>Ordinal scale of measurement</strong>: It defines data that is placed in a specific order. While each value is ranked, there’s no information that specifies what differentiates the categories from each other. These values can’t be added to or subtracted from.<br />
Examples: satisfaction data points in a survey, where ‘one = happy, two = neutral and three = unhappy.’</p></li>
<li><p><strong>Interval scale of measurement</strong>: The interval scale contains properties of nominal and ordered data, but the difference between data points can be quantified. This type of data shows both the order of the variables and the exact differences between the variables. They can be added to or subtracted from each other, but not multiplied or divided (For example, 40 degrees is not 20 degrees multiplied by two.).<br />
In this scale of measurement the zero is just a convention and not absolute, it is an existing value of the variable itself.</p></li>
<li><p><strong>Ratio scale of measurement</strong>: This scale include properties from all four scales of measurement. The data is nominal and defined by an identity, can be classified in order, contains intervals and can be broken down into exact value. Weight, height and distance are all examples of ratio variables. Data in the ratio scale can be added, subtracted, divided and multiplied. Ratio scales also differ from interval scales in that the scale has a ‘true zero’. The number zero means that the data has no value point.<br />
An example of this is height or weight, as someone cannot be zero centimetres tall or weigh zero kilos.</p></li>
</ul>
</section>
</section>
<section id="scales-and-questionnaires-development" class="level2" data-number="1.2">
<h2 data-number="1.2"><span class="header-section-number">1.2</span> Scales and Questionnaires development</h2>
<p>Measurement plays a vital role across scientific disciplines, with each field creating specialized methods and tools tailored to its unique subjects of study. In the behavioral and social sciences, the area devoted to measurement is called psychometrics. This subfield concentrates on evaluating psychological and social constructs, which are most often assessed using questionnaires. Theaching how to build effective questionnaires would require a specific course, but this is out of the scope of this course. The following are some practical guidelines that researchers can use to develop measurement scales and questionnaires.</p>
<section id="determine-clearly-what-you-want-to-measure" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Determine Clearly What You Want to Measure</h3>
<p>Researchers often discover their initial ideas about what they want to measure are vague, which can lead to costly changes later. Key questions include whether the scale should be theory-based or explore new directions, its level of specificity, and which aspects of the phenomenon to emphasize.</p>
<ul>
<li><p><strong>Define the theory</strong>: Basing scale development on relevant substantive theories is essential for clearly defining the construct being measured, particularly when dealing with abstract or non-observable phenomena. A theoretical basis helps establish the construct’s boundaries, reducing the risk of the scale extending into unrelated areas. In the absence of an existing theory, developers should create a conceptual framework of their own—beginning with a precise definition and linking the new construct to related, established ones.</p></li>
<li><p><strong>Determine the level of specificity</strong>: In psychometric scale development, it’s important to consider how general or specific the measurement should be. This decision affects how well the scale works in predicting or relating to other variables. For example, if you’re interested in general attitudes about personal control, a broad scale scale works well. But if you’re studying beliefs about controlling a specific health issue, a focused scale is more appropriate.</p></li>
<li><p><strong>Define which aspects are enphasised</strong>: Scale developers must clearly distinguish the target construct from related ones. Scales can be broad (e.g., general anxiety) or narrow (e.g., test anxiety). Including items outside the intended focus can lead to confusion or inaccurate measurement. For example, in health contexts, physical symptoms caused by an illness might be mistaken for psychological symptoms (like depression), leading to misleading results. Therefore, item selection should match the specific research purpose and avoid overlap with unrelated constructs. <!-- When building a scale, it's important to make sure it measures only the construct of interest—not other, similar ones. For instance, if you're interested in measuring test anxiety, including items about social anxiety would muddy the results. Similarly, if a depression scale includes physical symptoms like fatigue, it might confuse illness-related issues (like arthritis-related tiredness) with depression. This can distort results, especially in clinical or medical research. So, researchers need to be deliberate about item selection, ensuring the scale reflects exactly what they want to measure—and nothing else. --></p></li>
</ul>
<!-- ::: {.callout-tip} -->
<!-- If a depression scale includes physical symptoms like fatigue, it might confuse illness-related issues (like arthritis-related tiredness) with depression. This can distort results, especially in clinical or medical research.  -->
<!-- ::: -->
</section>
<section id="generate-an-item-pool" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Generate an Item Pool</h3>
<p>When developing a psychometric scale, items should be <strong>carefully selected</strong> or created to match the specific construct you aim to measure. That means you need a clear idea of what the scale is supposed to do, and every item on the scale should reflect that goal.</p>
<p>Imagine the construct (like anxiety, motivation, or trust) as something hidden or latent, which can’t be observed directly. The items on your scale are the visible signs or behaviors that reflect this hidden thing. So, each item acts like a small “test” of how much of that construct a person has. If your items truly measure the construct, then someone with a high level of the trait should tend to score higher on all of them.</p>
<p>When constructing the item pool, it is important to consider the following aspects:</p>
<ul>
<li><p><strong>The latent construct</strong> A good scale includes multiple items to improve reliability, but every single item must still be strongly connected to the latent construct. You should think broadly and creatively when writing items to make sure they cover all the different ways the construct can be expressed—but without straying into measuring something else.<br />
A construct is a single, unified idea (like “attitudes toward punishing drug abusers”) that can be thought of as causing how someone responds to related items. A category, on the other hand, is just a grouping of different constructs (like “attitudes” in general, or “barriers to compliance”).<br />
Just because several items relate to the same category doesn’t mean they measure the same underlying construct. For instance, “Barriers to compliance” is a category that can include many distinct things (fear of symptoms, cost concerns, distance to treatment, etc.). Each of these could be a separate construct with its own latent variable, so a scale that mixes these up wouldn’t truly be unidimensional (i.e., measuring just one thing).</p></li>
<li><p><strong>Redundancy</strong> is crucial for reliability: multiple items allow common content to summate while idiosyncrasies cancel out. However, avoid superficial redundancy (e.g., minor wording changes, identical grammatical structures) which can inflate reliability estimates. Useful redundancy involves expressing the same core idea differently. Overly specific or redundant items within a broader scale can create subclusters (e.g., multiple specific anxiety items in a general emotion scale), potentially undermining unidimensionality and biasing the scale. This is less of a problem if the items match the scale’s intended specificity.</p></li>
<li><p><strong>The number of items</strong> Start with more items than planned for the final scale (e.g., 3-4 times as many) to allow for careful selection and ensure good internal consistency. An initial pool 50% larger might suffice if items are hard to generate or fewer are needed for reliability. If the pool is too large, eliminate items based on criteria like lack of clarity or relevance.</p></li>
<li><p><strong>The wording</strong> Including both positively worded items (indicating the presence of the construct) and negatively worded items (indicating its absence or low levels) is a common strategy to reduce acquiescence bias—the tendency of respondents to agree with statements regardless of their content. However, reversing the wording can sometimes confuse participants, particularly in general population or community samples, and this confusion may reduce the scale’s reliability.</p></li>
</ul>
<!-- Explanation: -->
<div class="callout callout-style-simple callout-caution">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-body-container">
<p>Reversing the wording of items (also known as reversed polarity) can confuse respondents, especially if the items are complex or abstract, ot if the respondents have lower reading comprehension or aren’t used to taking surveys.<br />
This confusion can lead to inconsistent or inaccurate responses, which lowers the reliability of the scale (i.e., how consistently it measures the construct).</p>
</div>
</div>
</div>
<!-- When people respond to surveys, some tend to just agree with statements out of habit—this is called acquiescence bias. To prevent this, researchers often mix in negatively worded items (e.g., “I rarely feel confident” alongside “I feel confident”) to check whether the respondent is paying attention and to balance out response patterns. -->
<!-- However, this technique can backfire. Reversing the wording of items (also known as reversed polarity) can confuse respondents, especially if: -->
<!-- The items are complex or abstract. -->
<!-- The respondents have lower reading comprehension or aren’t used to taking surveys (as is sometimes the case in community or general population samples). -->
<!-- This confusion can lead to inconsistent or inaccurate responses, which lowers the reliability of the scale (i.e., how consistently it measures the construct). So, while including both types of items has its benefits, it should be done carefully, with attention to clarity and the characteristics of the target population. -->
<!-- Conclusion (Item Pool): The item pool should be large, relevant, and contain useful redundancy. Items should be grammatically sound, avoid ambiguity, and not force respondents into "package deals".  -->
</section>
<section id="determine-the-format-for-measurement" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Determine the Format for Measurement</h3>
<p>Defining the measurement format is a critical step in designing data collection instruments like questionnaires and scales. This decision, ideally made concurrently with item generation, impacts data quality, variability, instrument sensitivity, and ultimately, research conclusions.</p>
<!-- Thurstone Scaling: Aims to create items that respond ("resonate") to specific levels of an attribute, like tuning forks. Judges typically sort items into piles representing equal intervals of the construct. Respondents' agreement patterns theoretically pinpoint their level of the attribute. Elegant but difficult to implement effectively.  -->
<!-- Guttman Scaling: Items tap progressively higher levels of an attribute, so endorsing one implies endorsing all lower-level items. The score is the highest item endorsed. Works well for objective, hierarchical data (e.g., smoking frequency) but less so for subjective constructs where the order might vary across individuals.  -->
<!-- Scales With Equally Weighted Items: Fit well with models where items are roughly equivalent indicators of a common phenomenon. Allows flexibility in response formats.  -->
<p>Most scale items consist of two parts: a stem and a series of response options. A kew aspect of the scale items is the number of response options. A desiderable quality of a measurement scale is variability. One way to increase opportunities for variability is to include lots of scale items. Another way is to provide numerous respose options within each item, especially with fewer items.</p>
<p>In this view, continuous formats (e.g., thermometer scales) offer many gradations, and so increase the opportunities for variability. However, too many options can exceed respondents’ ability to meaningfully discriminate, leading to “false precision” and increased error variance. Researchers must balance the need for variability with respondents’ cognitive limitations.</p>
<p>Another issue the investigator has to concern with, is whether the number of options should be even or odd. This choice depends on the type of question. the type of response option, and the objectives of the investigator.</p>
<p>An odd number of categories usually allows to express neutrality, while an even number of categories forces a choice from the respondent. The choice depends on whether allowing neutrality is desirable or should be avoided.</p>
<p>There exist several ways to present items that are commonly used:</p>
<ul>
<li><strong>Likert scales</strong>: are widely used psychometric tools designed to measure attitudes, opinions, and perceptions by assessing the degree of agreement or disagreement with a statement. These scales typically present a statement (called a Likert item) followed by an ordered series of response options, generally consisting of five or seven points. However, scales with four, nine, or ten points can also be employed.</li>
</ul>
<p>Response anchors are the labels that define each point on the scale (for example, “Strongly disagree,” “Disagree,” “Neutral,” “Agree,” “Strongly agree”). Scales with an odd number of points often include a neutral midpoint, while scales with an even number of points force the respondent to express a direction (agreement or disagreement).</p>
<p>Likert scales are extensively applied in surveys to assess employee engagement, customer satisfaction, product feedback, and clinical evaluations.</p>
<!-- Key Insight: The structure of a Likert scale, including the number of points and the wording of the anchors, significantly influences the data collected. Researchers must carefully consider these factors to ensure the scale accurately measures the desired construct. -->
<div class="callout callout-style-simple callout-warning">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-body-container">
<p>Although Likert scale data is often numerically coded to facilitate analysis, it’s essential to remember their ordinal nature and approach the calculation of means with caution.</p>
</div>
</div>
</div>
<!-- Median and mode represent more robust measures of central tendency for this type of data.  -->
<ul>
<li><ul>
<li><strong>Semantic Differential scales</strong>: are assessment tools used to measure attitudes and opinions toward an object, person, event, or idea through pairs of bipolar adjectives. Developed by psychologist Charles E. Osgood, these scales present a concept followed by several rows of opposite adjective pairs placed at the extremes of a continuum, typically with five to seven intermediate points. Respondents evaluate the concept on each adjectival scale by selecting the point that best represents their attitude. Examples of bipolar adjective pairs include “Good - Bad,” “Happy - Sad,” “Strong - Weak,” and “Pleasant - Unpleasant.” These scales are commonly used in market research, branding, and customer satisfaction assessments to understand perceptions and associations.</li>
</ul></li>
</ul>
<p>Semantic differential scales explore the connotative meaning of a concept, revealing the emotional and evaluative dimensions of attitudes, unlike Likert scales which primarily focus on the degree of agreement.</p>
<!-- Data visualization for semantic differential scales can be accomplished through semantic differential graphs (often resembling line profiles connecting the average ratings for each adjective pair) or by treating each scale as an ordinal variable and using divergent stacked bar charts. -->
<!-- Visualization Considerations: When visualizing semantic differential scale data, it's crucial to clearly represent the bipolar nature of the scales, allowing for easy comparison of responses across different adjective pairs for the same concept or between different groups for the same adjective pair. -->
<ul>
<li><strong>Rankings</strong>: represent data where items are ordered according to a specific criterion or preference. Respondents arrange items in a sequence based on their preference, importance, or another defined attribute. Examples include ranking favorite movies, product features by importance, or job candidates. Ranking data indicates relative order but not the magnitude of difference between positions. The difference between the first and second positions might be substantial, while the difference between lower positions might be negligible.</li>
</ul>
<!-- Key Insight: Analysis of ranking data focuses on the position of items within the ordered sequence. Visualizations should emphasize the distribution of positions for each item and facilitate comparisons regarding how frequently items appear in different positions. -->
<ul>
<li><strong>Visual Analog Scale</strong> (VAS): Presents a continuous line between two descriptors and the respondents mark a point on the line. Therefore, it is clear that this scale allows continuous scoring but it has to be noted that interpretation can be subjective, and comparisons across individuals may be difficult. An advantage of this type of scale is that it is shghly sensitive, so it useful for detecting subtle changes within individuals over time; moreover they may reduce reduce bias from recalling previous discrete responses.</li>
</ul>
<!-- - **Numerical Response Formats**: Research suggests linear arrays of numbers may align with fundamental neural processing of quantity, potentially giving formats like Likert scales special merit.  -->
<ul>
<li><strong>Binary Options</strong>: Offer two choices (e.g., agree/disagree, yes/no, check if applies). This type of option is simple for respondents but yields to minimal variability per item, therefore more items are required for obtaining an adequate scale variance. However, the ease of response may allow for more items to be administered.</li>
</ul>
<!-- Item Time Frames: Consider the temporal aspect. Some scales imply an enduring trait (e.g., locus of control), while others assess transient states (e.g., depression "in the past week") or have separate state/trait forms (e.g., anxiety). The choice should be active and theory-driven, matching the nature of the phenomenon and the scale's intended use.  -->
</section>
<section id="experts-review" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Experts’ review</h3>
<p>Expert review plays a key role in strengthening content validity during scale development. By drawing on their subject-matter expertise, reviewers help ensure that the items meaningfully represent the construct.</p>
<p>Experts are typically asked to assess how well each item reflects the construct definition, providing feedback that can confirm or refine the conceptual framework. They also evaluate the clarity and precision of item wording, offering suggestions to reduce ambiguity. In addition, experts may highlight important aspects of the construct that have been overlooked.</p>
<p>However, it’s important to note that content experts may not be familiar with psychometric principles. For instance, they might recommend eliminating seemingly redundant items, not realizing that some redundancy is intentional and necessary for reliability. While expert input is highly valuable, final decisions should rest with the scale developer, who must balance expert judgment with methodological rigor.</p>
<!-- ### Step 5: Include Validation Items {.unnumbered .toc-ignore} -->
<!-- Rationale: Including additional items during development can aid later validation efforts. -->
<!-- Types of Items: -->
<!-- Detecting Problems: Items to assess response biases like social desirability. Items correlating highly with social desirability may need exclusion. Standard scales (e.g., Strahan & Gerbasi; MMPI bias scales) can be included. -->
<!-- Construct Validity: Measures of theoretically related (or unrelated) constructs can be included to examine convergent and discriminant validity early on. -->
<!-- ### Step 6: Administer Items to a Development Sample {.unnumbered .toc-ignore}  -->

<!-- Sample Size: Needs to be large enough to minimize subject variance as a concern and ensure stable item covariation patterns. Nunnally suggests 300, but smaller samples are sometimes used, depending on the number of items/scales. Risks of small samples include unstable results (e.g., inflated alpha estimates) and poor representation of the target population. -->
<!-- Sample Representativeness: The sample should resemble the intended population. Non-representativeness can be quantitative (different mean level or range of the attribute) or qualitative (different relationships among items/constructs). Quantitative differences may be less problematic for assessing internal consistency. Qualitative differences, where items have different meanings or underlying structures in the sample versus the population (e.g., due to language/cultural differences), are more serious and can undermine the development effort.  -->
<!-- ### Step 7: Evaluate the Items {.unnumbered .toc-ignore} -->
<!-- Goal: Identify the best-performing items from the pool to form the final scale, assessing their relationship with the latent variable's true score.  -->
<!-- Key Qualities & Analyses: -->
<!-- High Intercorrelations: Items should correlate highly with each other, indicating they share a common latent variable and have higher individual reliability. Inspect the correlation matrix.  -->
<!-- Reverse Scoring: Address negatively correlated items, potentially by reverse scoring them if they reflect the opposite pole of the construct. Reverse scoring can be done during administration (potentially confusing), data coding (tedious/error-prone), or electronically (easiest) using formulas like NEW = (k + 1) - OLD. If reverse scoring doesn't resolve inconsistent correlations, the item likely doesn't belong.  -->
<!-- Item-Scale Correlations: Each item should correlate substantially with the sum of the other items (corrected item-scale correlation is preferred over uncorrected to avoid inflation). -->
<!-- Item Variances: Items should have relatively high variance, indicating they discriminate between individuals. Very low variance suggests poor discrimination. Markedly different variances might signal inconsistent error or violation of model assumptions (like essential tau equivalence). -->
<!-- Item Means: Means should be close to the center of the possible score range. Extreme means often lead to low variance and poor correlations. Check means/variances after initial selection based on correlations. -->
<!-- Dimensionality: Use factor analysis to determine if the items form a single, unidimensional set, which is an assumption for coefficient alpha. -->

<!-- Reliability (Alpha): Calculate coefficient alpha (or alternatives like omega if assumptions aren't met) to assess internal consistency – the proportion of variance due to the true score. Can be computed using statistical software (SPSS RELIABILITY, SAS PROC CORR ALPHA) or by hand using variance-based formulas (preferred) or correlation-based Spearman-Brown. Alpha ranges from 0 to 1 (negative alpha indicates problems like negative inter-item correlations). Common (subjective) benchmarks for research scales: <.60 unacceptable, .60-.65 undesirable, .65-.70 minimal, .70-.80 respectable, .80-.90 very good; >.90 consider shortening. Aim higher during development as alpha might drop in new samples. Scales for individual assessment (clinical, diagnostic) require much higher reliability (e.g., mid-.90s). Single-item measures cannot use alpha; test-retest is an imperfect alternative. Omega is an option if assumptions for alpha are unmet.  -->
<!-- ### Step 8: Optimize Scale Length  {.unnumbered .toc-ignore} -->
<!-- Trade-off: Shorter scales reduce respondent burden, while longer scales are generally more reliable. The goal is an optimal balance. Brevity is pointless if reliability is too low. Consider shortening only when reliability is high.  -->
<!-- Dropping Items: Removing weak items (low correlation with others) can increase alpha, especially in shorter scales where each item has more impact. If an item's correlation is only slightly below average, keeping it usually benefits alpha more than removing it hurts.  -->
<!-- Process: Identify items for potential removal based on their impact on alpha (using software output), low item-scale correlations, or low squared multiple correlations (communality).  -->
<!-- Alpha Precision: Alpha itself is an estimate; its stability (reliability) increases with the number of items. Longer scales yield more consistent alpha values across administrations. Build in a safety margin, as alpha may decrease in new samples. -->
<!-- Split Samples: If the development sample is large enough, split it (e.g., in half or unevenly). Develop/optimize the scale on one subsample and cross-validate (check stability of alpha and other stats) on the second subsample, whose data did not influence item selection. This helps assess if initial results were inflated by chance, though subsamples are still more similar than entirely separate samples.  -->
</section>
<section id="subsequent-steps-in-scales-development" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Subsequent Steps in Scales Development</h3>
<p>Following the initial design of the questionnaire, including the selection and construction of appropriate scales, the next crucial phase involves preparing for validation and data collection. This includes strategically incorporating additional items aimed at facilitating later validation efforts, such as those designed to detect response biases or to assess the questionnaire’s construct validity by measuring theoretically related concepts.</p>
<p>Subsequently, the questionnaire is administered to a development sample. It’s essential that this sample is sufficiently large and representative of the target population to ensure stable results and minimize concerns about subject variance.</p>
<p>Once the data is collected, a thorough evaluation of the individual items is undertaken. This involves examining their intercorrelations to ensure they are measuring a common underlying construct, addressing any negatively correlated items through techniques like reverse scoring, and assessing the correlation of each item with the overall scale. Furthermore, the variance and means of the items are analyzed to ensure they discriminate effectively among respondents. Factor analysis is employed to confirm the dimensionality of the scale, and reliability, often measured by Cronbach’s alpha, is calculated to assess the internal consistency of the items.</p>
<p>Finally, the length of the scale is optimized. This involves balancing the need for brevity to reduce respondent burden with the desire for higher reliability, which is generally associated with longer scales. Weak items that negatively impact reliability are considered for removal, and techniques like splitting the development sample for cross-validation can be used to ensure the stability of the optimized scale in new samples.</p>
</section>
</section>
<section id="visualizing-ordinal-data" class="level2" data-number="1.3">
<h2 data-number="1.3"><span class="header-section-number">1.3</span> Visualizing Ordinal Data</h2>
<p>The most important principle in visualizing ordinal data is to always represent ordinal categories in their natural, ordered sequence in any visual representation. In bar charts, bars should be arranged along the axis based on the logical order of the ordinal scale (e.g., from “Low” to “High”). For stacked and divergent bar charts, the segments representing ordinal categories should also follow this intrinsic order within each bar.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode" id="cb1"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample data</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>satisfaction <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">level =</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="st">&quot;Very Dissatisfied&quot;</span>, <span class="st">&quot;Dissatisfied&quot;</span>, <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Satisfied&quot;</span>, <span class="st">&quot;Very Satisfied&quot;</span>),</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;Very Dissatisfied&quot;</span>, <span class="st">&quot;Dissatisfied&quot;</span>, <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Satisfied&quot;</span>, <span class="st">&quot;Very Satisfied&quot;</span>)),</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">count =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">23</span>, <span class="dv">30</span>, <span class="dv">45</span>, <span class="dv">27</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create bar chart with ordered categories</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(satisfaction, <span class="fu">aes</span>(<span class="at">x =</span> level, <span class="at">y =</span> count)) <span class="sc">+</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;steelblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Customer Satisfaction Levels&quot;</span>,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Satisfaction Level&quot;</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Number of Responses&quot;</span>) <span class="sc">+</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>))</span></code></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Ordinal_data_an_R_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>The choice of chart should align with the research question and the specific aspect of ordinal data being investigated. Not all chart types are equally effective for representing ordered categorical data.</p>
<section id="bar-charts" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Bar Charts</h3>
<p>Represent each ordinal category with a bar, whose height or length corresponds to the frequency or count of that category. Fundamentally, the bars must be arranged in the logical order of the ordinal variable (e.g., from lowest to highest category). They can be vertical or horizontal; horizontal orientation is often preferred for readability of long category labels.</p>
<p>Bar charts provide a clear and easily understandable visualization of the distribution of a single ordinal variable, highlighting the frequency of each ordered category.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode" id="cb2"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample Likert scale data for one survey question</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>likert_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">response_category =</span> <span class="fu">factor</span>(</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="st">&quot;Strongly Disagree&quot;</span>, <span class="st">&quot;Disagree&quot;</span>, </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>      <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Agree&quot;</span>, <span class="st">&quot;Strongly Agree&quot;</span>),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;Strongly Disagree&quot;</span>, <span class="st">&quot;Disagree&quot;</span>, </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>               <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Agree&quot;</span>, <span class="st">&quot;Strongly Agree&quot;</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">frequency =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">27</span>, <span class="dv">43</span>, <span class="dv">85</span>, <span class="dv">30</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create horizontal bar chart with properly ordered categories</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(likert_data, <span class="fu">aes</span>(<span class="at">x =</span> response_category,</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>                        <span class="at">y =</span> frequency, </span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>                        <span class="at">fill =</span> response_category)) <span class="sc">+</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>) <span class="sc">+</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Strongly Disagree&quot;</span> <span class="ot">=</span> <span class="st">&quot;#d7191c&quot;</span>,</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Disagree&quot;</span> <span class="ot">=</span> <span class="st">&quot;#fdae61&quot;</span>,</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Neutral&quot;</span> <span class="ot">=</span> <span class="st">&quot;#ffffbf&quot;</span>,</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Agree&quot;</span> <span class="ot">=</span> <span class="st">&quot;#abd9e9&quot;</span>,</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Strongly Agree&quot;</span> <span class="ot">=</span> <span class="st">&quot;#2c7bb6&quot;</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">+</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span>  <span class="co"># Horizontal orientation for better label readability</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Responses to: &#39;The new software </span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="st">    interface is intuitive to use&#39;&quot;</span>,</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">&quot;Distribution of 200 employee responses&quot;</span>,</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Number of Responses&quot;</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>,  <span class="co"># Remove legend as colors are self-explanatory</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">&quot;bold&quot;</span>),</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.major.y =</span> <span class="fu">element_blank</span>()  <span class="co"># Remove horizontal grid lines</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Ordinal_data_an_R_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
</section>
<section id="stacked-bar-charts" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Stacked Bar Charts</h3>
<p>Show multiple ordinal categories within a single bar, with each segment representing a different category stacked on top of another. They are useful for comparing the distribution of ordinal data across different groups or conditions. They can be displayed as counts or as percentages (where each bar totals 100%).</p>
<p>Stacked bar charts allow comparison of both total amounts within each group and the proportion of each ordinal category within those groups, providing insights into how distributions differ between categories.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode" id="cb3"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample semantic differential scale data</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># This represents evaluations of three different smartphones on five dimensions</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>semantic_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">product =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Smartphone A&quot;</span>, <span class="st">&quot;Smartphone B&quot;</span>, <span class="st">&quot;Smartphone C&quot;</span>), <span class="at">each =</span> <span class="dv">5</span>),</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">dimension =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Ineffective - Effective&quot;</span>,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;Complicated - Simple&quot;</span>,</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;Unreliable - Reliable&quot;</span>,</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;Outdated - Innovative&quot;</span>,</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;Unattractive - Attractive&quot;</span>), <span class="dv">3</span>),</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">rating_1 =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">8</span>, <span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">7</span>,       <span class="co"># Smartphone A</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>               <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>,        <span class="co"># Smartphone B</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>               <span class="dv">8</span>, <span class="dv">6</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">3</span>),       <span class="co"># Smartphone C</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">rating_2 =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">15</span>, <span class="dv">8</span>, <span class="dv">13</span>,    <span class="co"># Smartphone A</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>               <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">11</span>,      <span class="co"># Smartphone B</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>               <span class="dv">12</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">7</span>),     <span class="co"># Smartphone C</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">rating_3 =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">20</span>, <span class="dv">22</span>, <span class="dv">18</span>, <span class="dv">20</span>,   <span class="co"># Smartphone A</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>               <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">18</span>, <span class="dv">13</span>, <span class="dv">15</span>,   <span class="co"># Smartphone B</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>               <span class="dv">20</span>, <span class="dv">22</span>, <span class="dv">18</span>, <span class="dv">15</span>, <span class="dv">20</span>),  <span class="co"># Smartphone C</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">rating_4 =</span> <span class="fu">c</span>(<span class="dv">35</span>, <span class="dv">30</span>, <span class="dv">32</span>, <span class="dv">40</span>, <span class="dv">35</span>,   <span class="co"># Smartphone A</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>               <span class="dv">45</span>, <span class="dv">35</span>, <span class="dv">40</span>, <span class="dv">38</span>, <span class="dv">35</span>,   <span class="co"># Smartphone B</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>               <span class="dv">30</span>, <span class="dv">35</span>, <span class="dv">38</span>, <span class="dv">40</span>, <span class="dv">35</span>),  <span class="co"># Smartphone C</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">rating_5 =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">28</span>, <span class="dv">24</span>, <span class="dv">25</span>,   <span class="co"># Smartphone A</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>               <span class="dv">30</span>, <span class="dv">30</span>, <span class="dv">33</span>, <span class="dv">37</span>, <span class="dv">35</span>,   <span class="co"># Smartphone B</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>               <span class="dv">30</span>, <span class="dv">29</span>, <span class="dv">31</span>, <span class="dv">30</span>, <span class="dv">35</span>)   <span class="co"># Smartphone C</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape data for ggplot</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>semantic_long <span class="ot">&lt;-</span> semantic_data <span class="sc">%&gt;%</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">starts_with</span>(<span class="st">&quot;rating_&quot;</span>),</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">&quot;rating_level&quot;</span>,</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">&quot;count&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">rating_number =</span> <span class="fu">as.numeric</span>(<span class="fu">substr</span>(rating_level, <span class="dv">8</span>, <span class="dv">8</span>)),</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">rating_label =</span> <span class="fu">factor</span>(</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>      <span class="fu">case_when</span>(</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        rating_number <span class="sc">==</span> <span class="dv">1</span> <span class="sc">~</span> <span class="st">&quot;1 (Negative)&quot;</span>,</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>        rating_number <span class="sc">==</span> <span class="dv">2</span> <span class="sc">~</span> <span class="st">&quot;2&quot;</span>,</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>        rating_number <span class="sc">==</span> <span class="dv">3</span> <span class="sc">~</span> <span class="st">&quot;3 (Neutral)&quot;</span>,</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        rating_number <span class="sc">==</span> <span class="dv">4</span> <span class="sc">~</span> <span class="st">&quot;4&quot;</span>,</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>        rating_number <span class="sc">==</span> <span class="dv">5</span> <span class="sc">~</span> <span class="st">&quot;5 (Positive)&quot;</span></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>      <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;1 (Negative)&quot;</span>, <span class="st">&quot;2&quot;</span>, <span class="st">&quot;3 (Neutral)&quot;</span>, <span class="st">&quot;4&quot;</span>, <span class="st">&quot;5 (Positive)&quot;</span>)</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate percentages for each product-dimension combination</span></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>semantic_pct <span class="ot">&lt;-</span> semantic_long <span class="sc">%&gt;%</span></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(product, dimension) <span class="sc">%&gt;%</span></span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>    <span class="at">percentage =</span> count <span class="sc">/</span> <span class="fu">sum</span>(count) <span class="sc">*</span> <span class="dv">100</span>,</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>    <span class="at">total =</span> <span class="fu">sum</span>(count)</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Create stacked bar chart</span></span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(semantic_pct, <span class="fu">aes</span>(<span class="at">x =</span> dimension, <span class="at">y =</span> percentage, <span class="at">fill =</span> rating_label)) <span class="sc">+</span></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>) <span class="sc">+</span></span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> product) <span class="sc">+</span></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;1 (Negative)&quot;</span> <span class="ot">=</span> <span class="st">&quot;#d7191c&quot;</span>,</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;2&quot;</span> <span class="ot">=</span> <span class="st">&quot;#fdae61&quot;</span>,</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;3 (Neutral)&quot;</span> <span class="ot">=</span> <span class="st">&quot;#ffffbf&quot;</span>,</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;4&quot;</span> <span class="ot">=</span> <span class="st">&quot;#a6d96a&quot;</span>,</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;5 (Positive)&quot;</span> <span class="ot">=</span> <span class="st">&quot;#1a9641&quot;</span>)) <span class="sc">+</span></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Smartphone Evaluations using Semantic Differential Scales&quot;</span>,</span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">&quot;Distribution of ratings across five dimensions&quot;</span>,</span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Percentage of Responses&quot;</span>,</span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;Rating&quot;</span>) <span class="sc">+</span></span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>,</span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a>    <span class="at">strip.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">color =</span> <span class="cn">NA</span>),</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a>    <span class="at">strip.text =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">&quot;bold&quot;</span>)</span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Ordinal_data_an_R_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>This visualization effectively reveals patterns such as which smartphone is perceived as more innovative, which has the most consistent ratings across dimensions, and where the greatest differences between products exist. These insights would be difficult to discern from tables of raw data. The stacked bar format is particularly effective for semantic differential scales because it shows the full distribution of responses, not just averages, allowing you to see whether opinions are polarized or consistent across respondents.</p>
</section>
<section id="divergent-stacked-bar-charts" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Divergent Stacked Bar Charts</h3>
<p>Specifically designed to visualize ordinal data with a neutral central category or bipolar responses, such as Likert scales and semantic differentials. Segments representing responses on one side of the neutral point extend in one direction, while segments representing responses on the other side extend in the opposite direction from a central baseline. They effectively illustrate the balance between positive and negative responses and the distribution of opinions.</p>
<p>Divergent stacked bar charts are the recommended visualization for Likert-type scales as they clearly show the proportion of responses in each category and the overall tendency of agreement or disagreement.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode" id="cb4"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install and load required package</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;HH&quot;)</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(HH)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Frequency data for three items (rows) on a 5-point Likert scale</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>likert_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Easy&quot;</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">40</span>, <span class="dv">20</span>),</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Helpful&quot;</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">18</span>, <span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">17</span>),</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Recommend&quot;</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">8</span>, <span class="dv">12</span>, <span class="dv">15</span>, <span class="dv">35</span>, <span class="dv">30</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Set column names (Likert scale labels)</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(likert_data) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Strongly Disagree&quot;</span>, <span class="st">&quot;Disagree&quot;</span>, <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Agree&quot;</span>, <span class="st">&quot;Strongly Agree&quot;</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>likert_data <span class="ot">&lt;-</span> <span class="fu">t</span>(likert_data)  <span class="co"># Transpose: items as columns, scale points as rows</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the Likert plot</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>likert_plot <span class="ot">&lt;-</span> <span class="fu">likert</span>(likert_data,</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>                      <span class="at">main =</span> <span class="st">&quot;Customer Feedback on Product Experience&quot;</span>,</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>                      <span class="at">xlab =</span> <span class="st">&quot;Percentage of Responses&quot;</span>,</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>                      <span class="at">ylab =</span> <span class="cn">NULL</span>,</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>                      <span class="at">positive.order =</span> <span class="cn">TRUE</span>,</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>                      <span class="at">reference =</span> <span class="dv">0</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(likert_plot)</span></code></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Ordinal_data_an_R_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
</section>
<section id="other-possible-visualizations" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Other Possible Visualizations</h3>
<p>Depending on the specific analytical objective, these alternative visualizations can provide valuable perspectives on ordinal data, particularly when exploring relationships between variables or tracking changes in rankings.</p>
<p><strong>Mosaic plots</strong> show the relationship between two or more categorical variables, including ordinal ones, using tiled rectangles whose area is proportional to the frequency of each combination of categories.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode" id="cb5"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;ggmosaic&quot;)</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggmosaic)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample data for education level (ordinal) </span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">#and job satisfaction (ordinal)</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>education_levels <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;High School&quot;</span>, <span class="st">&quot;Associate&#39;s&quot;</span>, <span class="st">&quot;Bachelor&#39;s&quot;</span>,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;Master&#39;s&quot;</span>, <span class="st">&quot;Doctorate&quot;</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>satisfaction_levels <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Very Dissatisfied&quot;</span>, <span class="st">&quot;Dissatisfied&quot;</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>                         <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Satisfied&quot;</span>, <span class="st">&quot;Very Satisfied&quot;</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample data with a pattern </span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">#(higher education tends to correlate with higher satisfaction)</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>mosaic_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">education =</span> <span class="fu">factor</span>(<span class="fu">sample</span>(education_levels, n, <span class="at">replace =</span> <span class="cn">TRUE</span>,</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>                            <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.25</span>, <span class="fl">0.25</span>, <span class="fl">0.15</span>, <span class="fl">0.05</span>)),</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>                     <span class="at">levels =</span> education_levels),</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">satisfaction =</span> <span class="fu">factor</span>(<span class="cn">NA</span>, <span class="at">levels =</span> satisfaction_levels)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate satisfaction levels with </span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co">#some correlation to education</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n) {</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Higher education levels tend to have higher satisfaction probabilities</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>  edu_level <span class="ot">&lt;-</span> <span class="fu">which</span>(education_levels <span class="sc">==</span> mosaic_data<span class="sc">$</span>education[i])</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Adjust probabilities based on education level</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>  probs <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.25</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.1</span>)  <span class="co"># Base probabilities</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Shift probabilities based on education level</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>  shift <span class="ot">&lt;-</span> (edu_level <span class="sc">-</span> <span class="dv">3</span>) <span class="sc">*</span> <span class="fl">0.05</span>  <span class="co"># Shift factor based on education</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Adjust probabilities (higher education gets </span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>  <span class="co">#more weight for higher satisfaction)</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>  adjusted_probs <span class="ot">&lt;-</span> probs <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.1</span>, <span class="sc">-</span><span class="fl">0.05</span>, <span class="dv">0</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>) <span class="sc">*</span> edu_level</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Ensure probabilities are valid</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>  adjusted_probs <span class="ot">&lt;-</span> <span class="fu">pmax</span>(adjusted_probs, <span class="fl">0.01</span>)</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>  adjusted_probs <span class="ot">&lt;-</span> adjusted_probs <span class="sc">/</span> <span class="fu">sum</span>(adjusted_probs)</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>  mosaic_data<span class="sc">$</span>satisfaction[i] <span class="ot">&lt;-</span> <span class="fu">sample</span>(satisfaction_levels, <span class="dv">1</span>, <span class="at">prob =</span> adjusted_probs)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Create mosaic plot</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mosaic_data) <span class="sc">+</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_mosaic</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">product</span>(education), </span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>                  <span class="at">fill =</span> satisfaction)) <span class="sc">+</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_brewer</span>(<span class="at">palette =</span> <span class="st">&quot;RdYlGn&quot;</span>, <span class="at">direction =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Relationship Between </span></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a><span class="st">       Education Level and Job Satisfaction&quot;</span>,</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">&quot;Mosaic plot showing the </span></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a><span class="st">       distribution of satisfaction within </span></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a><span class="st">       each education level&quot;</span>,</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Education Level&quot;</span>,</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Job Satisfaction&quot;</span>,</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;Satisfaction Level&quot;</span>) <span class="sc">+</span></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>),</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>         <span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span></code></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Ordinal_data_an_R_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>This mosaic plot visualizes the relationship between two ordinal variables: education level and job satisfaction. The width of each column represents the proportion of respondents with that education level in the overall sample. Within each education level column, the height of each colored section represents the proportion of respondents reporting that satisfaction level.</p>
<p><strong>Line charts</strong> (bump charts) visualize the change in rank of different items over time or between categories, emphasizing movement in relative positions.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode" id="cb6"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample data for product rankings over time</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>rankings <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">product =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Product A&quot;</span>, <span class="st">&quot;Product B&quot;</span>, </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Product C&quot;</span>, <span class="st">&quot;Product D&quot;</span>, <span class="st">&quot;Product E&quot;</span>), <span class="dv">4</span>),</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">quarter =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Q1 2024&quot;</span>, <span class="st">&quot;Q2 2024&quot;</span>, </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Q3 2024&quot;</span>, <span class="st">&quot;Q4 2024&quot;</span>), <span class="at">each =</span> <span class="dv">5</span>),</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">rank =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>,       <span class="co"># Q1 rankings</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>           <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">4</span>,       <span class="co"># Q2 rankings</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>           <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">4</span>,       <span class="co"># Q3 rankings</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>           <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">5</span>)       <span class="co"># Q4 rankings</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create bump chart</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rankings, <span class="fu">aes</span>(<span class="at">x =</span> quarter, <span class="at">y =</span> rank, </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>                     <span class="at">group =</span> product, <span class="at">color =</span> product)) <span class="sc">+</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_reverse</span>(<span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>) <span class="sc">+</span>  <span class="co"># Reverse Y-axis so </span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>                                   <span class="co"># rank 1 is at the top</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Product Rankings by Quarter&quot;</span>,</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">&quot;Showing changes in ranking </span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="st">       position over time&quot;</span>,</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Quarter&quot;</span>,</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Rank (Lower is Better)&quot;</span>,</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">&quot;Product&quot;</span>) <span class="sc">+</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span></code></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Ordinal_data_an_R_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
</section>
</section>
</section>
<section id="classical-models-for-ordinal-data" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Classical Models for Ordinal Data</h1>
<div class="column-margin">
<!-- <p><a href="materials/Script_plots_examples.R" download style="margin-right: 5px;"> <i class="bi bi-file-earmark-code-fill" style="font-size: 0.9em; vertical-align: middle;"></i> [R Script]{style="margin-left: 2px; vertical-align: middle;"} </a></p> -->
<p>
<a href="materials/Ordinal Data Analysis in R - Module 2.pdf" download> <i class="bi bi-file-earmark-slides-fill" style="font-size: 0.9em; vertical-align: middle;"></i> <span style="margin-left: 2px; vertical-align: middle;">Slides</span> </a>
</p>
</div>
<section id="limitations-of-most-commonly-used-models" class="level2" data-number="2.1">
<h2 data-number="2.1"><span class="header-section-number">2.1</span> Limitations of most commonly used models</h2>
<section id="limitations-of-linear-regression" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Limitations of Linear Regression:</h3>
<p>Linear regression is designed for dependent variables that are continuous and can take any value within a range (or at least have a large number of distinct, equally-spaced values). Applying linear regression to ordinal data involves treating the ordered categories as if they were numerical scores with equal intervals between them.</p>
<ul>
<li><p><strong>Ignores Non-Interval Nature</strong>: The primary issue is that linear regression assumes that the difference between category 1 and 2 is the same as the difference between category 2 and 3, and so on. For ordinal data, this is often not true. The “distance” between “Very Dissatisfied” and “Dissatisfied” might not be the same in the minds of respondents as the distance between “Satisfied” and “Very Satisfied.” By assigning numerical scores (e.g., 1, 2, 3, 4, 5) and running linear regression, we impose an arbitrary interval structure that the data doesn’t necessarily possess. This can lead to inaccurate estimates of the effects of predictors.</p></li>
<li><p><strong>Violation of Assumptions</strong>: Linear regression assumes the dependent variable is continuous and errors are normally distributed with constant variance. For an ordinal variable with a limited number of categories, these assumptions are violated. The predicted values from a linear model can also fall outside the valid range of the ordinal scale (e.g., predicting a satisfaction level of 0.5 or 5.8 on a 1-5 scale).</p></li>
<li><p><strong>Misleading Interpretation</strong>: Interpreting coefficients in linear regression involves saying that a one-unit increase in a predictor is associated with a certain change in the mean score of the ordinal variable. This interpretation is based on the problematic assumption of equal intervals and might not accurately reflect the underlying process generating the ordinal response.</p></li>
</ul>
</section>
<section id="limitations-of-binary-logistic-regression" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Limitations of Binary Logistic Regression:</h3>
<p>Binary logistic regression is suitable for dependent variables with exactly two outcomes (e.g., Yes/No, Success/Failure). To use it with an ordinal variable, you have to collapse the multiple ordered categories into just two.</p>
<ul>
<li><p><strong>Loss of Information</strong>: The biggest drawback is the loss of valuable information about the granularity and ordering of the original categories. Forcing a 5-point scale into a binary outcome (e.g., “Satisfied/Very Satisfied” vs. “Dissatisfied/Neutral/Very Dissatisfied”) discards the nuances within the original categories. A model that can distinguish between “Dissatisfied” and “Very Dissatisfied” will likely be more informative than one that groups them.</p></li>
<li><p><strong>Arbitrary Threshold</strong>: The choice of where to split the ordinal scale into two groups is often arbitrary. Different researchers might choose different cut-off points, and this arbitrary choice can significantly influence the results and conclusions drawn from the analysis. The effect of a predictor might appear different depending on how the dichotomization is performed.</p></li>
<li><p><strong>Reduced Statistical Power</strong>: By reducing the number of outcomes, you potentially reduce the variability captured by the dependent variable, which can lead to a loss of statistical power to detect significant effects of your predictors compared to a model that utilizes the full ordinal scale.</p></li>
</ul>
</section>
<section id="limitations-of-multinomial-logistic-regression" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Limitations of Multinomial Logistic Regression:</h3>
<p>Multinomial (or polytomous) logistic regression is designed for dependent variables with three or more categories that have no natural order (e.g., choice of car color: red, blue, green). While it can handle multiple categories, its fundamental structure doesn’t account for ranking.</p>
<ul>
<li><p><strong>Ignores the Order</strong>: Multinomial logistic regression models the probability of being in each category relative to a chosen baseline category. It estimates a separate set of coefficients for each category comparison (e.g., Category 2 vs. Category 1, Category 3 vs. Category 1, etc.). It treats the categories as distinct nominal outcomes, completely ignoring the fact that category 3 falls between category 2 and category 4 in a meaningful way.</p></li>
<li><p><strong>Difficult Interpretation</strong> (in terms of Order): The coefficients in a multinomial logit model are interpreted in terms of the change in log-odds of being in a specific category versus the baseline category for a one-unit change in a predictor. While technically correct, relating these separate category-specific effects back to the overall ordered nature of the dependent variable can be cumbersome and less intuitive than the single cumulative odds ratio provided by the cumulative logit model (when the proportional odds assumption holds). It doesn’t directly answer questions like “how does this predictor affect the likelihood of being in a higher category?”</p></li>
</ul>
</section>
</section>
<section id="modeling-cumulative-probabilities" class="level2" data-number="2.2">
<h2 data-number="2.2"><span class="header-section-number">2.2</span> Modeling Cumulative Probabilities</h2>
<p>The primary methodology for modeling ordinal data revolves around the cumulative probabilities associated with the ordered categories. This approach respects the inherent order of the data, ensuring that these probabilities monotonically increase as we move up the ordinal scale.</p>
<!-- In the context of binary response variables, logistic regression is the standard model. -->
<!-- For multinomial variables, the Baseline-category Logit model, an extension of logistic regression, is used to form logits by comparing each category to a baseline category. However, this method is generally better suited for unordered categorical responses because it does not account for the crucial characteristic of ordinality. -->
<p>To more appropriately handle ordinality, the cumulative probabilities approach modifies logistic regression by applying transformations that consider the order of the categories. A common transformation is the logit transformation applied to the cumulative probabilities, which enhances the model’s ability to capture the ordered nature of the data. Other transformations, such as probit or log-log, can also be used depending on the specific data characteristics and analytical requirements.</p>
<!-- Furthermore, two additional transformations are noteworthy for ordinal data: the use of adjacent categories, and the use of the continuation ratio. -->
<!-- These methods refine the approach by focusing on the relationships between consecutive categories, providing a more detailed modeling of the ordinal data's structure. -->
<!-- To model the relationship between predictors and an ordinal response variable, the cumulative logit model doesn't directly model the probability of being in each specific category (P(Y=c  -->
<!-- j -->
<!-- ​ -->
<!--  )). Instead, it focuses on cumulative probabilities. -->
<p><strong>Definition</strong>: Given an ordinal variable <span class="math inline">\(R\)</span> with <span class="math inline">\(m\)</span> ordered categories, let’s denote these categories as <span class="math inline">\(r_1, r_2, \dots, r_m\)</span>, where <span class="math inline">\(r_1\)</span> is the “lowest” category and <span class="math inline">\(r_m\)</span> is the “highest”. The categories have a meaningful order: <span class="math inline">\(r_1 \leq r_2, \leq \dots, \leq r_m\)</span>.</p>
<p>A cumulative probability for a specific category <span class="math inline">\(r_j\)</span> is the probability that the observed response <span class="math inline">\(R\)</span> falls into category <span class="math inline">\(r_j\)</span>, or any category below it. Mathematically, this is expressed as <span class="math inline">\(P(R \leq r_j)\)</span>.</p>
<p>We can define <span class="math inline">\(m-1\)</span> such cumulative probabilities, corresponding to the thresholds between the categories:</p>
<ul>
<li><p>For the first category <span class="math inline">\(r_1\)</span>:<br />
<span class="math inline">\(P(R \leq r_1) = P(R = r_1)\)</span> is simply the probability of being in the lowest category.</p></li>
<li><p>For the first category <span class="math inline">\(r_2\)</span>:<br />
<span class="math inline">\(P(R \leq r_2) = P(R = r_1) + P(R = r_2)\)</span> is the probability of being in the second category or any category below it (which is just the first category).</p></li>
<li><p>For the third category <span class="math inline">\(r_3\)</span>:<br />
<span class="math inline">\(P(R \leq r_3) = P(R = r_1) + P(R = r_2) + P(R = r_3)\)</span> is the probability of being in the third category or any category below it.</p></li>
<li><p>…and so on, up to the <span class="math inline">\((m-1)\)</span>-th category <span class="math inline">\(r_{(m-1)}\)</span>:<br />
<span class="math inline">\(P(R \leq r_{(m-1)}) = P(R = r_1) + P(R = r_2) + P(R = r_3) + \dots + P(R = r_{(m-1)})\)</span> is the probability of being in the second-highest category or any category below it.</p></li>
<li><p>For the last category <span class="math inline">\(r_m\)</span> <span class="math inline">\(r_{(m-1)}\)</span>:<br />
<span class="math inline">\(P(R \leq r_m) = P(R = r_1) + P(R = r_2) + P(R = r_3) + \dots + P(R = r_{(m-1)})+ P(R = r_m)=1\)</span>, which is the cumulative probability is always 1 because it includes all possible outcomes. Since it carries no information about the differences between categories, it is not included in the modeling process; we only model the first <span class="math inline">\(m-1\)</span> cumulative probabilities.</p></li>
</ul>
<p>The use of cumulative probabilities is a clever way to turn the ordinal modeling problem into a series of binary comparisons, while respecting the order. Each cumulative probability <span class="math inline">\(P(R \leq r_j)\)</span> inherently creates a binary split at the threshold <span class="math inline">\(r_j\)</span>: - Outcome 1: the response is in category <span class="math inline">\(r_j\)</span> or lower <span class="math inline">\((R\leq r_j)\)</span>; - Outcome 2: The response is in category higher than <span class="math inline">\(r_j\)</span> <span class="math inline">\((R &gt; r_j)\)</span>.</p>
<p>By modeling the probability of this binary outcome for each threshold <span class="math inline">\(j=1,\dots,m−1\)</span>, we capture the transitions between categories along the ordered scale. The cumulative logit model then applies the logit transformation to these cumulative probabilities, allowing them to be related to a linear combination of predictors.</p>
<p><strong>Numerical Example</strong>: Let’s consider a simple ordinal variable, “Product Satisfaction,” with <span class="math inline">\(m = 4\)</span> ordered categories:</p>
<ul>
<li><span class="math inline">\(r_1\)</span>: Very Dissatisfied (VD)</li>
<li><span class="math inline">\(r_2\)</span>: Dissatisfied (D)</li>
<li><span class="math inline">\(r_3\)</span>: Satisfied (S)</li>
<li><span class="math inline">\(r_4\)</span>: Very Satisfied (VS)</li>
</ul>
<p>Suppose, for a particular group of individuals, the probabilities of being in each specific category are:</p>
<ul>
<li><span class="math inline">\(P(R=VD)=P(R=r_1)=0.10\)</span></li>
<li><span class="math inline">\(P(R=D)=P(R=r_2)=0.20\)</span></li>
<li><span class="math inline">\(P(R=S)=P(R=r_3)=0.40\)</span></li>
<li><span class="math inline">\(P(R=VS)=P(R=r_4)=0.30\)</span></li>
</ul>
<p>Now, let’s calculate the cumulative probabilities:</p>
<ol type="1">
<li><p>Cumulative Probability for <span class="math inline">\(r_1\)</span> (VD) <br> <span class="math inline">\(P(R \leq r_1) = P(R = VD) = 0.10\)</span> <br> This represents the probability of being in the “Very Dissatisfied” category or below (just VD). The implied binary split is <span class="math inline">\(\{VD\}\)</span> vs <span class="math inline">\(\{D, S, VS\}\)</span>.</p></li>
<li><p>Cumulative Probability for <span class="math inline">\(r_2\)</span> (D) <br> <span class="math inline">\(P(R \leq r_2) = P(R = VD) + P(R = D) = 0.10 + 0.20 = 0.30\)</span> <br> This represents the probability of being in the “Dissatisfied” category or below (VD or D). The implied binary split is <span class="math inline">\(\{VD, D\}\)</span> vs <span class="math inline">\(\{S, VS\}\)</span>.</p></li>
<li><p>Cumulative Probability for <span class="math inline">\(r_3\)</span> (S) <br> <span class="math inline">\(P(R \leq r_3) = P(R = VD) + P(R = D) + P(R = S) = 0.10 + 0.20 + 0.40 = 0.70\)</span> <br> This represents the probability of being in the “Satisfied” category or below (VD, D, or S). The implied binary split is <span class="math inline">\(\{VD, D, S\}\)</span> vs <span class="math inline">\(\{VS\}\)</span>.</p></li>
<li><p>Cumulative Probability for <span class="math inline">\(r_4\)</span> (VS) <br> <span class="math inline">\(P(R \leq r_4) = P(R = VD) + P(R = D) + P(R = S) + P(R = VS) = 0.10 + 0.20 + 0.40 + 0.3 = 1\)</span> As expected, the cumulative probability for the highest category is 1. We do not model this.</p></li>
</ol>
<p>So, for this 4-category variable, the cumulative logit model will focus on modeling the relationships between predictors and the first <span class="math inline">\(m−1=4−1=3\)</span> cumulative probabilities. Each of these represents a different threshold or cut-point on the ordered scale.</p>
</section>
<section id="the-cumulative-logit-with-proportional-odds-assumption" class="level2" data-number="2.3">
<h2 data-number="2.3"><span class="header-section-number">2.3</span> The Cumulative Logit with Proportional Odds Assumption</h2>
<p>To be able to model the relationship between the cumulative probabilities and the explanatory variables, a function is needed and, as in the binary logistic regression, we use the logit to model the probability of success. In the case of ordinal data, we apply the logit not to the probability of a single category, but to the cumulative probabilities.</p>
<p>The cumulative logit transformation for the <span class="math inline">\(j\)</span>-th threshold (where <span class="math inline">\(j\)</span> goes from <span class="math inline">\(1\)</span> to <span class="math inline">\(m−1\)</span>) is defined as the natural logarithm of the cumulative odds:</p>
<p><span id="eq-cumlogit1"><span class="math display">\[
\text{logit} [ P (R \leq r_j)] = \log \Bigg( \frac{P(R \leq r_j)}{1-P(R \leq r_j)}\Bigg)
\tag{1}\]</span></span></p>
<p>Since <span class="math inline">\(1-P(R \leq r_j)\)</span> is the probability that the outcome <span class="math inline">\(R\)</span> is greather than the category <span class="math inline">\(r_j\)</span>. So, the cumulative logit can be rewritten as:</p>
<p><span id="eq-cumlogit2"><span class="math display">\[
\text{logit} [ P (R \leq r_j)] = \log \Bigg( \frac{P(R \leq r_j)}{P(R &gt; r_j)}\Bigg)
\tag{2}\]</span></span></p>
<p>This expression represents the natural logarithm of the odds of being in category <span class="math inline">\(r_j\)</span> or any category below it, versus being in any category above <span class="math inline">\(r_j\)</span>. This transformation, as in the case of the binary logistic regression, maps probabilities (which are between 0 and 1) onto the entire real number line <span class="math inline">\((-\infty, + \infty)\)</span>. This allows us to equate the logit of this cumulative probability to a linear combination of our predictors, which can take any real value.</p>
<p>The resulting statistical model, and the most common one for ordinal data with a cumulative logit link, is known as the Cumulative Logit Proportional Odds Model. Its basic structure assumes that the cumulative logit for each threshold is a linear function of the predictor variables:</p>
<p><span id="eq-cumlogit3"><span class="math display">\[
\text{logit}[P(R\leq r_j | X_1, \dots, X_k)] = \alpha_j + \beta_1X_1 + \beta_2X_2 + \dots + \beta_kX_k
\tag{3}\]</span></span></p>
<p>This equation is estimated simultaneously for each of the <span class="math inline">\(m-1\)</span> cumulative thresholds. in this equation:</p>
<ul>
<li><p><span class="math inline">\(P(R \leq r_j | \boldsymbol{X})\)</span> is the cumulative probability of being in category <span class="math inline">\(r_j\)</span> or lower, conditional on the values of the predictor variables <span class="math inline">\(X_1 ,X_2, \dots, X_k\)</span>.</p></li>
<li><p><span class="math inline">\(\alpha_j\)</span> are the intercepts of the model. A crucial aspect of the cumulative logit model is that there is a different intercept for each of the <span class="math inline">\(m-1\)</span> cumulative logits we are modeling.<br />
<span class="math inline">\(\alpha_1\)</span> is the intercept for <span class="math inline">\(\text{logit}[P(R\leq r_1)]\)</span>, <span class="math inline">\(\alpha_2\)</span> is the intercept for <span class="math inline">\(\text{logit}[P(R\leq r_2)]\)</span>, and <span class="math inline">\(\alpha_{(m-1)}\)</span> is the intercept for <span class="math inline">\(\text{logit}[P(R\leq r_{(m-1)})]\)</span>.<br />
These intercepts represent the baseline cumulative log-odds for their respective threshold when all the predictor variables X are zero.<br />
It is necessary that these intercepts are ordered: <span class="math inline">\(\alpha_1 \leq \alpha_2 \leq \dots \leq \alpha_{(m-1)}\)</span>.<br />
This ensures that the resulting cumulative probabilities are non-decreasing as j increases.</p></li>
<li><p><span class="math inline">\(\beta_1, \beta_2, \dots, \beta_k\)</span> are the coefficients associated to each predictor variables <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, <span class="math inline">\(\dots, X_k\)</span>.<br />
Since we are operating under proportional odds assumption, in this model these is only one set of <span class="math inline">\(\beta\)</span> coefficients that applies across all <span class="math inline">\(m-1\)</span> cumulative logit equations.<br />
This implies that the effect of each predictor on the cumulative log-odds is the same.</p></li>
</ul>
<p>To demonstrate the proportional odds assumption, let’s consider the cumulative odds for two distinct sets of predictor values: <span class="math inline">\(\boldsymbol{X}^{(1)} = (X_1^{(1)}, \dots, X_k^{(1)})\)</span> and <span class="math inline">\(\boldsymbol{X}^{(2)} = (X_1^{(2)}, \dots, X_k^{(2)})\)</span>.</p>
<p>The cumulative odds at threshold <span class="math inline">\(r_j\)</span> for the first set of predictors <span class="math inline">\(\boldsymbol{X}^{(1)}\)</span> are: <span class="math display">\[
\text{Odds}(R \leq r_j | \boldsymbol{X}^{(1)}) =\exp \Bigg( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(1)} \Bigg)
\]</span> Similarly, for the second set of predictors <span class="math inline">\(\boldsymbol{X}^{(2)}\)</span>:</p>
<p><span class="math display">\[
\text{Odds}(R \leq r_j | \boldsymbol{X}^{(2)}) = \exp \Bigg( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(2)} \Bigg)
\]</span> The Odds Ratio (OR) comparing the cumulative odds at <span class="math inline">\(\boldsymbol{X}^{(2)}\)</span> to those at <span class="math inline">\(\boldsymbol{X}^{(1)}\)</span> for the event <span class="math inline">\(R \leq r_j\)</span> is: <span class="math display">\[
\text{OR}_j = \frac{\text{Odds}(R \leq r_j | \boldsymbol{X}^{(2)})}{\text{Odds}(R \leq r_j | \boldsymbol{X}^{(1)})}
\]</span> Substituting the exponential expressions for the odds: <span class="math display">\[
\text{OR}_j = \frac{\exp \Big( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(2)} \Big)}{\exp \Big( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(1)} \Big)}
\]</span> Using the property <span class="math inline">\(e^a / e^b = e^{a-b}\)</span>, we can simplify the expression: <span class="math display">\[
\text{OR}_j = \exp \Bigg( \Big( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(2)} \Big) - \Big( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(1)} \Big) \Bigg)
\]</span></p>
<p>Crucially, the intercept term <span class="math inline">\(\alpha_j\)</span> cancels out:</p>
<p><span class="math display">\[
\text{OR}_j = \exp \Bigg( \sum_{i=1}^{k} \beta_iX_i^{(2)} - \sum_{i=1}^{k} \beta_iX_i^{(1)} \Bigg)
\]</span></p>
<p>This can be further condensed:</p>
<p><span class="math display">\[
\text{OR}_j = \exp \Bigg( \sum_{i=1}^{k} \beta_i(X_i^{(2)} - X_i^{(1)}) \Bigg)
\]</span></p>
<p>As evident from this final formula, the Odds Ratio (<span class="math inline">\(\text{OR}_j\)</span>) does not contain the subscript <span class="math inline">\(j\)</span>. This signifies that the odds ratio associated with a change in the predictor variables is constant across all <span class="math inline">\(m-1\)</span> cumulative thresholds. This inherent consistency in the effect of predictors across the ordinal categories is precisely what defines the proportional odds assumption. It means that while the baseline odds change for each category, the multiplicative effect of the predictors on these odds remains the same.</p>
<p>Graphically, this translates to parallelism on the log-odds scale. If you were to plot the cumulative log-odds for different levels of a predictor, you would see a set of parallel lines. For example, imagine an ordinal outcome with four categories (e.g., ‘Low’, ‘Medium’, ‘High’, ‘Very High’). There would be three cumulative probabilities: <span class="math inline">\(P(R\leq Low)\)</span>, <span class="math inline">\(P(R \leq Medium)\)</span>, and <span class="math inline">\(P(R \leq High)\)</span>. If the Proportional Odds assumption holds for a continuous predictor, then the log-odds for each of these cumulative probabilities would change by the same amount for a one-unit increase in that predictor.</p>
<p>You would visualize three separate curves, one for each cumulative probability, plotted against the predictor on the x-axis, with the y-axis representing the logit of these probabilities. If the Proportional Odds assumption holds, these three curves would run parallel to each other across the entire range of the predictor. They would be shifted vertically relative to each other (due to the different <span class="math inline">\(\alpha_j\)</span>, but their slopes (the <span class="math inline">\(\beta\)</span> coefficients) would be identical.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="Ordinal_data_an_R_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>The Proportional Odds assumption is useful for two main reason:</p>
<ul>
<li><p><strong>Parsimony and Simplicity</strong>: This is a major advantage. If the assumption holds, the <span class="math inline">\(\beta\)</span> coefficients are estimated for each predictor, regardless of the number of categories <span class="math inline">\(m\)</span>. Fewer parameters make the model easier to estimate, interpret, and potentially more stable, especially with smaller sample sizes.</p></li>
<li><p><strong>Clear and Consistent Interpretation</strong>: A single Odds Ratio per predictor provides a clear, concise summary of its effect across the entire ordinal scale.</p></li>
</ul>
<!-- For instance, if $$\text{exp}(\beta_{temp})=0.75$$, we confidently say that increasing temperature by one unit multiplies the odds of being in a lower rating category by 0.75, regardless the categories we are comparing.  -->
<section id="latent-variable-motivation" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Latent Variable Motivation</h3>
<p>To better understand this model we can think about an underlying, unobserved latent continuous variable, called <span class="math inline">\(R^*\)</span>. Let’s imagine that the ordinal response <span class="math inline">\(R\)</span> that we observe is actually a categorized version of the continuous unobserved variable <span class="math inline">\(R^*\)</span>. We can assume that <span class="math inline">\(R^*\)</span> is linearly related to our predictors plus some error, similar to a standard linear regression model:</p>
<p><span class="math display">\[
R^* = \beta_0^* + \beta_1^*X_1 + \dots + \beta_k^*X_k + \epsilon
\]</span></p>
<p>We can set some fixed thresholds, <span class="math inline">\(\gamma_0 = -\infty, \gamma_1\)</span>, <span class="math inline">\(\gamma_2\)</span>, <span class="math inline">\(\dots, \gamma_{(m-1)}\)</span>, <span class="math inline">\(\gamma_m = +\infty\)</span> on the <span class="math inline">\(R^*\)</span> scale, such that if <span class="math inline">\(R^*\)</span> falls between two thresholds, the observed ordinal variable <span class="math inline">\(R\)</span> falls into the corresponding category. The thresholds are set such that <span class="math inline">\(\gamma_0 &lt; \gamma_1\)</span> &lt; <span class="math inline">\(\gamma_2\)</span> &lt; <span class="math inline">\(\dots &lt; \gamma_{(m-1)}\)</span> <span class="math inline">\(&lt;\gamma_m\)</span>.</p>
<p>The ordinal category is determined by <span class="math inline">\(R^*\)</span> based on the thresholds:</p>
<ul>
<li><span class="math inline">\(R = r_1\)</span> if <span class="math inline">\(R^* \leq \gamma_1\)</span></li>
<li><span class="math inline">\(R = r_2\)</span> if <span class="math inline">\(\gamma_1 &lt; R^* \leq \gamma_2\)</span></li>
<li><span class="math inline">\(R = r_j\)</span> if <span class="math inline">\(\gamma_{(j-1)} &lt; R^* \leq \gamma_j\)</span></li>
<li><span class="math inline">\(R = r_m\)</span> if <span class="math inline">\(R^* &gt; \gamma_{(m-1)}\)</span></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<p><img src="Ordinal_data_an_R_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>If we assume that the error <span class="math inline">\(\epsilon\)</span> follows a standard logistic distribution, it can be shown that this structure leads directly to the form of the cumulative logit model:</p>
<p><span class="math display">\[
\text{logit}[P \leq r_j | \boldsymbol{X})] = (\gamma_j - \beta_0^*) - \beta_1^*X_1 - \dots - \beta_k^*X_k,
\]</span></p>
<p>which clearly matches the cumulative logit model form given in <a href="#eq-cumlogit3">Equation 3</a> if we define the model intercept <span class="math inline">\(\alpha_j = \gamma_j - \beta_0^*\)</span> and the model’s coefficients <span class="math inline">\(\beta_i = -\beta_i^*\)</span>.</p>
<p>In this latent variable framework, the Proportional Odds assumption means two things:</p>
<ol type="1">
<li><p>The thresholds on the <span class="math inline">\(R^*\)</span> scale are fixed and do not depend on the predictor variables <span class="math inline">\(X\)</span>.</p></li>
<li><p>The effect of each predictor <span class="math inline">\(X_i\)</span>(represented by is simply to shift the entire distribution of the latent variable <span class="math inline">\(R^*\)</span> along the continuous scale. This shift is the same magnitude regardless of where the fixed thresholds <span class="math inline">\(\gamma_j\)</span> are located.</p></li>
</ol>
<p>This parallel shif” of the latent distribution is the reason why the odds ratios for cumulative probabilities are proportional across all thresholds.</p>
</section>
<section id="testing-the-proportional-odds-assumption" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Testing the Proportional Odds Assumption</h3>
<p>Violating the Proportional Odds assumption can lead to inaccurate conclusions about the effects of the predictors. The most robust and commonly recommended way to test the Proportional Odds assumption with is by using a Likelihood Ratio Test to compare a constrained model (the PO model) with a more flexible, unconstrained model (where the PO assumption is relaxed for a specific predictor).</p>
<p>The <code>clm()</code> function from the ordinal package allows you to relax the PO assumption for specific predictors using the <code>nominal = ~ predictor</code> argument. This creates a “partial proportional odds” model (also known as a generalized ordinal logit model). We then compare this more complex model (where the assumption is relaxed) to our original, simpler proportional odds model using <code>anova()</code>, which performs a Likelihood Ratio Test.</p>
<ul>
<li><p><strong>Null Hypothesis (<span class="math inline">\(H_0\)</span>)</strong>: The Proportional Odds assumption holds for the specified predictor (i.e., its coefficient is constant across all thresholds).</p></li>
<li><p><strong>Alternative Hypothesis (<span class="math inline">\(h_1\)</span>)</strong>: The Proportional Odds assumption does not hold for the specified predictor (i.e., its coefficient varies across thresholds).</p></li>
</ul>
<p>Imagine we have an ordinal outcome Response (e.g., ‘Low’, ‘Medium’, ‘High’) and a continuous predictor Experience.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode" id="cb7"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ordinal) </span></code></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: il pacchetto &#39;ordinal&#39; è stato creato con R versione 4.4.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Caricamento pacchetto: &#39;ordinal&#39;</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Il seguente oggetto è mascherato da &#39;package:dplyr&#39;:

    slice</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode" id="cb11"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2) </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)   </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">Response =</span> <span class="fu">factor</span>(<span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&quot;Low&quot;</span>, <span class="st">&quot;Medium&quot;</span>, <span class="st">&quot;High&quot;</span>), <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>),</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>                    <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;Low&quot;</span>, <span class="st">&quot;Medium&quot;</span>, <span class="st">&quot;High&quot;</span>), <span class="at">ordered =</span> <span class="cn">TRUE</span>),</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">Experience =</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">5</span>, <span class="dv">2</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a standard Proportional Odds model</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>po_model_hypo <span class="ot">&lt;-</span> <span class="fu">clm</span>(Response <span class="sc">~</span> Experience, <span class="at">data =</span> data)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(po_model_hypo)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>formula: Response ~ Experience
data:    data

 link  threshold nobs logLik  AIC    niter max.grad cond.H 
 logit flexible  100  -109.55 225.10 3(0)  1.49e-10 4.6e+02

Coefficients:
           Estimate Std. Error z value Pr(&gt;|z|)
Experience -0.08062    0.10394  -0.776    0.438

Threshold coefficients:
            Estimate Std. Error z value
Low|Medium   -1.0554     0.5491  -1.922
Medium|High   0.3228     0.5390   0.599</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode" id="cb13"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a model where the PO assumption is relaxed for &#39;Experience&#39;</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>non_po_model_hypo <span class="ot">&lt;-</span> <span class="fu">clm</span>(Response <span class="sc">~</span> Experience, <span class="at">nominal =</span> <span class="sc">~</span> Experience, <span class="at">data =</span> data)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(non_po_model_hypo) </span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>formula: Response ~ Experience
nominal: ~Experience
data:    data

 link  threshold nobs logLik  AIC    niter max.grad cond.H 
 logit flexible  100  -109.55 227.09 3(0)  1.87e-09 7.0e+02

Coefficients: (1 not defined because of singularities)
           Estimate Std. Error z value Pr(&gt;|z|)
Experience       NA         NA      NA       NA

Threshold coefficients:
                        Estimate Std. Error z value
Low|Medium.(Intercept)  -1.03724    0.64650  -1.604
Medium|High.(Intercept)  0.30635    0.62133   0.493
Low|Medium.Experience    0.07697    0.12457   0.618
Medium|High.Experience   0.08416    0.12352   0.681</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode" id="cb15"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the models using anova()</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(po_model_hypo, non_po_model_hypo)</span></code></pre></div>
</details>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["no.par"],"name":[1],"type":["int"],"align":["right"]},{"label":["AIC"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["logLik"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["LR.stat"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[5],"type":["int"],"align":["right"]},{"label":["Pr(>Chisq)"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"3","2":"225.0978","3":"-109.5489","4":"NA","5":"NA","6":"NA","_rn_":"po_model_hypo"},{"1":"4","2":"227.0950","3":"-109.5475","4":"0.002821524","5":"1","6":"0.9576379","_rn_":"non_po_model_hypo"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p><strong>Interpretation of the results</strong></p>
<p><code>po_model_hypo</code> is the Proportional Odds model, where the effect of <code>Experience</code> is assumed to be constant across all thresholds. <code>non_po_model_hypo</code> is the generalized ordinal logit model (or partial proportional odds model), where the effect of <code>Experience</code> is allowed to vary across the thresholds.</p>
<p>The AIC is 225.10 for <code>po_model_hypo</code> and 227.09 for <code>non_po_model_hypo</code>, this already suggest that the simpler model should be preferred.</p>
<p><code>LR.stat</code> (Likelihood Ratio Statistic) is the test statistic for comparing the two nested models. It’s calculated as <span class="math inline">\(2 \cdot (logLik_{unconstrained} −logLik_{constrained})\)</span>.</p>
<p>In this example, <code>LR.stat</code> = 0.0028. This indicates that the unconstrained model doesn’t provide a much better fit than the constrained model.</p>
<p><code>Pr(&gt;Chisq)</code> (p-value) is the p-value associated with the LR.stat.</p>
<p>Based on this Likelihood Ratio Test, there is no statistically significant evidence to suggest that the Proportional Odds assumption is violated for the Experience predictor in the data. The effect of Experience on the log-odds of cumulative probabilities does not appear to vary significantly across the different thresholds.</p>
</section>
<section id="graphical-inspection" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Graphical Inspection</h3>
<p>While statistically rigorous, formal tests can be overly sensitive, especially in large datasets. A statistically significant p-value might indicate a violation that is numerically very small and practically insignificant. This is where graphical inspection becomes invaluable.</p>
<p>Graphical inspection provides a visual assessment of whether the coefficients for a given predictor truly remain constant across thresholds. This involves fitting a more flexible model and then plotting the estimated coefficients for each predictor across the different thresholds.</p>
<!-- ```{r} -->
<!-- # Ensure necessary packages are loaded -->
<!-- library(ordinal) -->
<!-- library(ggplot2) -->
<!-- library(tidyr) # For pivot_longer -->
<!-- # Re-create hypothetical data and models for a clean run -->
<!-- set.seed(456) -->
<!-- hypothetical_data <- data.frame( -->
<!--   Response = factor(sample(c("Low", "Medium", "High"), 100, replace = TRUE), -->
<!--                     levels = c("Low", "Medium", "High"), ordered = TRUE), -->
<!--   Experience = rnorm(100, 5, 2) -->
<!-- ) -->
<!-- po_model_hypo <- clm(Response ~ Experience, data = hypothetical_data) -->
<!-- non_po_model_hypo <- clm(Response ~ Experience, nominal = ~ Experience, data = hypothetical_data) -->
<!-- # Extract coefficients and SEs from the non-PO model -->
<!-- coef_values <- coef(non_po_model_hypo) -->
<!-- vcov_matrix <- vcov(non_po_model_hypo) -->
<!-- # Identify the coefficients related to 'Experience' that vary by threshold. -->
<!-- # These typically have names like 'Experience:1|2', 'Experience:2|3', etc. -->
<!-- # We'll explicitly filter for these nominal coefficients. -->
<!-- nominal_coeffs_names <- names(coef_values)[grep("Experience:", names(coef_values))] -->
<!-- exp_coeffs <- coef_values[nominal_coeffs_names] -->
<!-- exp_ses <- sqrt(diag(vcov_matrix))[nominal_coeffs_names] -->
<!-- # Create a data frame for plotting -->
<!-- plot_data_coeffs <- data.frame( -->
<!--   Threshold = nominal_coeffs_names, # Use the actual names like Experience:1|2 -->
<!--   Estimate = exp_coeffs, -->
<!--   SE = exp_ses -->
<!-- ) -->
<!-- # Add 95% confidence intervals -->
<!-- plot_data_coeffs$Lower <- plot_data_coeffs$Estimate - 1.96 * plot_data_coeffs$SE -->
<!-- plot_data_coeffs$Upper <- plot_data_coeffs$Estimate + 1.96 * plot_data_coeffs$SE -->
<!-- # Add the single PO coefficient for comparison (from po_model_hypo) -->
<!-- po_estimate_x <- coef(po_model_hypo)["Experience"] -->
<!-- # Ensure Threshold is a factor for correct ordering on the plot -->
<!-- plot_data_coeffs$Threshold <- factor(plot_data_coeffs$Threshold, -->
<!--                                      levels = rev(nominal_coeffs_names)) # Reverse for typical plot order -->
<!-- # --- Plotting the coefficients across thresholds --- -->
<!-- ggplot(plot_data_coeffs, aes(x = Threshold, y = Estimate)) + -->
<!--   geom_point(size = 3) + -->
<!--   geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2) + -->
<!--   geom_hline(yintercept = po_estimate_x, linetype = "dashed", color = "blue", size = 0.8) + -->
<!--   labs( -->
<!--     title = "Estimated Coefficients for 'Experience' Across Thresholds", -->
<!--     subtitle = "Dashed line is the PO model estimate (assuming constant effect)", -->
<!--     y = "Coefficient Estimate", -->
<!--     x = "Cumulative Threshold" -->
<!--   ) + -->
<!--   theme_minimal() + -->
<!--   coord_flip() # Flip coordinates for better readability -->
<!-- ``` -->
</section>
<section id="violation-of-the-proportional-odds-assumption" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Violation of the Proportional Odds Assumption</h3>
<p>When the Proportional Odds assumption is violated for a predictor, the effect of that predictor on the cumulative log-odds is not constant across thresholds. Graphically, this means the lines for different cumulative probabilities would not be parallel. Their slopes would differ, meaning the <span class="math inline">\(\beta\)</span> coefficients are not the same for each threshold.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="Ordinal_data_an_R_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>When the formal tests and especially the graphical inspection indicate a statistically and practically significant violation, it is not possible to proceed with the standard Proportional Odds model, as the coefficient estimates would be biased and their interpretation misleading.</p>
<p>There are two main alternative models to handle this problem:</p>
<ol type="1">
<li><strong>Generalized Ordinal Logit Models</strong> (or Partial Proportional Odds Models): are a flexible extension of the proportional odds model. They allow the coefficients of specific predictor variables to vary across the cumulative logit equations (i.e., across the thresholds), while still forcing other predictors (those that do satisfy the Proportional Odds assumption) to have constant effects. When only a subset of coefficients is allowed to vary, it’s specifically called a Partial Proportional Odds (PPO) model. Instead of estimating a single <span class="math inline">\(\beta_i\)</span> for a predictor <span class="math inline">\(X_i\)</span>, a PPO model estimates a separate <span class="math inline">\(\beta_{ij}\)</span> for each cumulative logit <span class="math inline">\(r_j\)</span>.<br />
The advantages are:</li>
</ol>
<ul>
<li><em>Flexibility</em>: It directly addresses the violation by allowing coefficients to differ where necessary.</li>
<li><em>Parsimony</em> (relative to Multinomial): It retains some of the efficiency of the ordinal model. If only a few predictors violate the Proportional Odds assumption, it is possible to estimate fewer parameters than a full multinomial logit model, making it more parsimonious and potentially more stable.</li>
<li><em>Maintains Ordinality</em>: Crucially, it still respects the inherent ordering of the outcome categories. This means that the interpretations are still about “moving up or down” the ordered scale, but the strength of that effect can differ at various points along the scale.</li>
<li><em>Interpretation</em>: While more complex than the Proportional Odds model, the interpretation of varying coefficients provides a richer understanding. You might find that a predictor has a strong effect in distinguishing “Low” from “Medium/High” but a much weaker effect in distinguishing “Medium” from “High”.</li>
</ul>
<ol start="2" type="1">
<li><strong>Multinomial Logit Model</strong>: A multinomial (or polytomous) logit model treats the outcome categories as purely nominal (unordered), even if they are inherently ordinal. It fits a separate binary logistic regression model for each category, comparing it to a chosen reference category. Advantages are:</li>
</ol>
<ul>
<li><em>No PO Assumption</em>: It makes no assumption about the effects of predictors being constant across categories; therefore, it automatically handles any PO violation.</li>
<li><em>Maximum Flexibility</em>: It is the most flexible approach for categorical outcomes, as it allows for completely different effects for each category comparison.</li>
</ul>
<p>However, thre are some disadvantages: - <em>Loss of Ordinal Information</em>: This can lead to less precise estimates and interpretations that don’t fully reflect the nature of your outcome. - <em>Increased Complexity and Reduced Parsimony</em>: <span class="math inline">\((m−1)\cdot k\)</span> coefficients (where <span class="math inline">\(k\)</span> is the number of predictors), which is more than a Proportional Odds model (<span class="math inline">\(k\)</span> predictors) or even a PPO model. This increased number of parameters can lead to: - <em>Larger standard errors</em>: Less statistical power. - <em>Difficulty in interpretation</em>: Interpreting multiple sets of coefficients and odds ratios can be cumbersome. - <em>Overfitting</em>: Especially with smaller sample sizes, estimating too many parameters can lead to models that fit the current data well but generalize poorly.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-body-container">
<p>It is crucial to recognize that a statistically significant p-value from a formal test, such as the Likelihood Ratio Test, does not always signify a practically meaningful violation of the Proportional Odds assumption, especially in large datasets where even trivial deviations can be flagged. Therefore, graphical inspection becomes invaluable: if the estimated coefficients for a predictor across thresholds are very similar and their confidence intervals largely overlap (indicating near-parallelism), then despite a statistical rejection, the practical implication of the violation might be minimal, allowing one to retain the more parsimonious standard PO model. Conversely, if coefficients vary widely with little to no overlap in their confidence intervals, indicating both statistical and practical significance, then adopting a more flexible model like a Partial Proportional Odds model or, as a last resort, a Multinomial Logit model, becomes necessary to accurately reflect the data.</p>
</div>
</div>
</div>
</section>
</section>
<section id="coefficients-interpretation" class="level2" data-number="2.4">
<h2 data-number="2.4"><span class="header-section-number">2.4</span> Coefficients interpretation</h2>
<p>Consider the effect of changing a single predictor, <span class="math inline">\(X_i\)</span>, by one unit, while holding all other predictors constant. The change in the cumulative log-odds for a one-unit increase in <span class="math inline">\(X_i\)</span> is simply the coefficient <span class="math inline">\(\beta_i\)</span>.</p>
<p>So, <span class="math inline">\(\beta_i\)</span> is the change in the cumulative log-odds for a one-unit increase in <span class="math inline">\(X_i\)</span>, holding other predictors constant.</p>
<p>To get the Odds Ratio, we exponentiate the coefficient: <span class="math inline">\(OR_i = \text{exp}(\beta_i)\)</span>.</p>
<p>This <span class="math inline">\(OR_i\)</span> is the multiplicative change in the cumulative odds for a one-unit increase in <span class="math inline">\(X_i\)</span>.</p>
<p>For a one-unit increase in the predictor <span class="math inline">\(X_i\)</span>, while holding all other predictors constant, the odds of being in category <span class="math inline">\(r_j\)</span> or any category below it, versus being in a category above <span class="math inline">\(r_j\)</span>, are multiplied by <span class="math inline">\(\text{exp}(\beta_i)\)</span>.</p>
<p><strong>Note</strong> Due to the Proportional Odds assumption, this multiplicative effect, <span class="math inline">\(\text{exp}(\beta_i)\)</span>, is the same for all <span class="math inline">\(m-1\)</span> thresholds.</p>
<ul>
<li><p>If <span class="math inline">\(\beta_i &gt; 0\)</span> (and thus <span class="math inline">\(\text{exp}(\beta_i)&gt;1\)</span>): A one-unit increase in <span class="math inline">\(X_i\)</span> increases the cumulative log-odds. This means it increases the odds of being in category <span class="math inline">\(r_j\)</span> or below.<br />
Therefore, a positive <span class="math inline">\(\beta_i\)</span> indicates that higher values of <span class="math inline">\(X_i\)</span> are associated with a greater likelihood of being in the lower (or earlier) categories of the ordinal variable <span class="math inline">\(R\)</span>. Equivalently, it’s associated with a lower likelihood of being in the higher categories.</p></li>
<li><p>If <span class="math inline">\(\beta_i &lt;0\)</span> (and thus <span class="math inline">\(\text{exp}(\beta_i)&lt;1\)</span>): A one-unit increase in <span class="math inline">\(X_i\)</span> decreases the cumulative log-odds. This means it decreases the odds of being in category <span class="math inline">\(r_j\)</span> or below.<br />
Therefore, a negative <span class="math inline">\(\beta_i\)</span> indicates that higher values of <span class="math inline">\(X_i\)</span> are associated with a greater likelihood of being in the higher (or later) categories of the ordinal variable Y. Equivalently, it’s associated with a lower likelihood of being in the lower categories.</p></li>
</ul>
<section id="connection-with-the-latent-variable-interpretation" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Connection with the Latent Variable interpretation</h3>
<p>In the latent variable model <span class="math inline">\(R^* = \beta_0^* + \beta_1^*X_1 + \dots + \beta_k^*X_k + \epsilon\)</span>, a positive <span class="math inline">\(\beta_i^*\)</span> means that increasing <span class="math inline">\(X_i\)</span> increases the value of the latent variable <span class="math inline">\(R^*\)</span>. Since higher values of <span class="math inline">\(R^*\)</span> correspond to higher ordinal categories, <span class="math inline">\(\beta_i&gt;0\)</span> implies a shift towards higher categories. As we saw in the derivation, the cumulative logit model coefficient <span class="math inline">\(\beta_I\)</span> (for <span class="math inline">\(P(Y \leq r_j)\)</span>) is typically <span class="math inline">\(-\beta_i^*\)</span>. So, if <span class="math inline">\(\beta_i^*&gt;0\)</span>, then <span class="math inline">\(\beta_i&lt;0\)</span> in the cumulative logit model, which is associated with higher ordinal categories. This confirms the consistency between the two interpretations, although the sign convention can be tricky.</p>
<p>To avoid confusion, it is generally easiest and most standard to interpret the results directly from the estimated coefficients (<span class="math inline">\(\beta_i\)</span>) and Odds Ratios (<span class="math inline">\(\text{exp}(\beta_i)\)</span>) from the cumulative logit model output:</p>
<ul>
<li><p><span class="math inline">\(\text{exp}(\beta_i)&gt;1\)</span>: Higher values of <span class="math inline">\(X_i\)</span> are associated with increased odds of being in a lower category (or equivalently, decreased odds of being in a higher category). The shift is towards the beginning of the ordered scale.</p></li>
<li><p><span class="math inline">\(\text{exp}(\beta_i)&lt;1\)</span>: Higher values of <span class="math inline">\(X_i\)</span> are associated with decreased odds of being in a lower category (or equivalently, increased odds of being in a higher category). The shift is towards the end of the ordered scale.</p></li>
</ul>
<section id="including-and-interpreting-qualitative-predictors" class="level4 unnumbered toc-ignore">
<h4 class="unnumbered toc-ignore">Including and Interpreting Qualitative Predictors</h4>
<p>Categorical predictors (nominal or ordinal, when used as predictors) cannot be entered directly into the model as single numbers. Instead, we use dummy variables. For a categorical predictor with <span class="math inline">\(m\)</span> categories, <span class="math inline">\(m−1\)</span> dummy variables will be created. One category is designated as the “reference category”. This category does not get its own dummy variable; its effect is absorbed into the intercept (<span class="math inline">\(\alpha_j\)</span>). All other categories are then compared to this reference category.</p>
<p>Choice Considerations:</p>
<ul>
<li><p>Clinical/Logical Baseline: a naturally occurring baseline (e.g., “No exposure,” “Placebo group,” “Male gender” if female is the group of interest).</p></li>
<li><p>Largest Category: often chosen for statistical stability, as there’s more data for comparison.</p></li>
<li><p>First or Last Category: convenient for software defaults. Category of Primary Interest: if you want to compare all other groups to a specific group. Example: Gender Predictor (Male, Female)</p></li>
</ul>
<p>Let’s assume “Female” is the reference category, and the ordinal dependent variable is “Self-Rated Health” (1=Poor to 5=Excellent). We create one dummy variable for “Male”.</p>
<p><span class="math inline">\(X_{\text{male}}=1\)</span> if Gender = Male</p>
<p><span class="math inline">\(X_{\text{male}}=0\)</span> if Gender = Female</p>
<p>The proportional odds model incorporating Gender would look like:</p>
<p><span class="math display">\[\text{logit}[P(R\leq r_j∣Gender,Other Predictors)] = \alpha_j + \beta_{male}X_{male} + \beta_{OthPred}X_{OthPred} \]</span></p>
<p>The coefficient for a dummy variable represents the difference in the cumulative log-odds between the category represented by the dummy variable and the reference category, holding all other predictors constant.</p>
<p>The Odds Ratio for a dummy variable is <span class="math inline">\(e^{\beta_{\text{dummy}}}\)</span>. This Odds Ratio represents the ratio of the odds of being in a lower outcome category for the dummy variable group compared to the reference group, holding other predictors constant.</p>
<p>Example: Gender Predictor (Male, Female) for Self-Rated Health</p>
<p>Let’s continue with “Self-Rated Health” (1=Poor to 5=Excellent). Assume “Female” is the reference category.</p>
<p>In our example, keeping Female as the reference category, if the estimated <span class="math inline">\(\beta_{male}\)</span> is 0.4, the Odds Ratio for Male would be <span class="math inline">\(e^{0.4}\approx 1.49\)</span>.</p>
<p>Interpretation:</p>
<ul>
<li><p>Coefficient (<span class="math inline">\(\beta_{male}=0.4\)</span>): Males have, on average, 0.4 units higher cumulative log-odds of being in a lower self-rated health category (e.g., Poor, Fair, Good, Very Good) compared to females, holding other predictors constant.</p></li>
<li><p>Odds Ratio ($OR_{male}=1.49): The odds of a male reporting “Poor or Fair or Good or Very Good Health” vs. “Excellent Health” are 1.49 times the odds for a female, holding all other predictors constant. Similarly, the odds of a male reporting “Poor or Fair or Good Health” vs. “Very Good or Excellent Health” are 1.49 times the odds for a female, and so on, across all cumulative splits.</p></li>
</ul>
<p>In simpler terms, males have a higher odds of being in the less healthy (lower) categories of self-rated health compared to females. This effect is assumed to be consistent across the entire range of health categories.</p>
</section>
</section>
<section id="inference-on-parameters" class="level3 unnumbered toc-ignore">
<h3 class="unnumbered toc-ignore">Inference on Parameters</h3>
<p>Once the model is fitted using Maximum Likelihood Estimation, it is necessary to understand the statistical significance and precision of the parameter estimates.</p>
<section id="significance-tests-for-individual-predictors" class="level4 unnumbered toc-ignore">
<h4 class="unnumbered toc-ignore">Significance Tests for Individual Predictors</h4>
<p>To determine if an individual predictor variable has a statistically significant effect on the ordinal outcome, most statistical software packages provide a Wald Test for each predictor. The Wald test calculates a z-statistic for each coefficient: <span class="math inline">\(Z= \frac{Estimate}{Std Error}\)</span>. This z-statistic is then squared to get <span class="math inline">\(\chi^2\)</span> statistic with 1 degree of freedom: <span class="math inline">\(Wald\chi^2 = Z^2\)</span>.<br />
A p-value is then calculated based on this <span class="math inline">\(\chi^2\)</span> statistic. The <em>Null Hypothesis</em> (<span class="math inline">\(H_0\)</span>) is that the coefficient for this predictor is zero (i.e., the predictor has no effect on the cumulative log-odds). The <em>Alternative Hypothesis</em> (<span class="math inline">\(H_1\)</span>) is that the coefficient for this predictor is not zero (i.e., the predictor has a significant effect).<br />
If the p-value <span class="math inline">\((Pr(&gt;|z|))\)</span> is small (typically less than 0.05), the null hypothesis is rejected. This suggests that the predictor has a statistically significant effect on the ordinal outcome. If the p-value is large, we fail to reject the null hypothesis. There’s insufficient evidence to conclude that the predictor has a significant effect.</p>
</section>
<section id="confidence-intervals-for-the-coefficients-and-the-odds-ratios" class="level4 unnumbered toc-ignore">
<h4 class="unnumbered toc-ignore">Confidence Intervals for the coefficients and the Odds Ratios</h4>
<p>While p-values give about statistical significance, confidence intervals (CIs) provide a range of plausible values for the true population parameter, giving information about the precision of our estimates.<br />
Interpretation for coefficients (<span class="math inline">\(\beta\)</span>): A 95% CI for a coefficient means that if we were to repeat the study many times, 95% of the calculated CIs would contain the true population coefficient. If a CI for <span class="math inline">\(\beta\)</span> does not include 0, then the coefficient is statistically significant at the corresponding alpha level (e.g., 0.05 for a 95% CI).<br />
Interpretation for Odds Ratios (<span class="math inline">\(exp^\beta\)</span>)): A 95% CI for an OR means that we are 95% confident that the true population OR lies within this range. If a CI for an OR does not include 1, then the effect is statistically significant.<br />
If the CI is entirely above 1, the predictor significantly increases the odds of a lower outcome.<br />
If the CI is entirely below 1, the predictor significantly decreases the odds of a lower outcome (i.e., increases the odds of a higher outcome).</p>
</section>
<section id="evaluating-model-fit-and-performance" class="level4 unnumbered toc-ignore">
<h4 class="unnumbered toc-ignore">Evaluating Model Fit and Performance</h4>
<p>There are several statistics to evaluate the Goodness of Fit of a Proportional Odds Model.</p>
<p>In linear regression, the <span class="math inline">\(R^2\)</span> is commonly used to describe the proportion of variance in the dependent variable explained by the independent variables. However, for ordinal logistic regression (and other generalized linear models), the concept of explained variance is more complex, and the traditional <span class="math inline">\(R^2\)</span> is not appropriate because the model relies on a non-linear link function.<br />
Instead, <strong>Pseudo R-squared</strong> measures are commonly used and they attempt to provide an analogous quantification of how well the model fits the data, or how much variance it “explains”, relative to a null model.<br />
They typically compare the log-likelihood of the fitted model (<span class="math inline">\(L_{model}\)</span>) to the log-likelihood of a null (intercept-only) model (<span class="math inline">\(L_{null}\)</span>).<br />
Common types of Pseudo R-squared include: * McFadden’s <span class="math inline">\(R^2\)</span>: <span class="math inline">\(1−\Big(\frac{L_{model}}{L_{null}}\Big)\)</span></p>
<pre><code>* Cox &amp; Snell&#39;s $R^2$: $1−\Big(\frac{L_{model}}{L_{null}}\Big)^{\frac{2}{n}}$</code></pre>
<div class="callout callout-style-simple callout-warning">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-body-container">
<p>Do NOT compare directly to linear regression <span class="math inline">\(R^2\)</span>: Pseudo R-squared values are typically much lower than <span class="math inline">\(R^2\)</span> values from linear regression models, even for models that fit the data very well. A McFadden’s <span class="math inline">\(R^2\)</span> of 0.20 might be considered very good in an ordinal logistic regression context, whereas a linear <span class="math inline">\(R^2\)</span> of 0.20 would often be considered weak.</p>
</div>
</div>
</div>
<p>Another widely used statistics is the <strong>Likelihood Ratio Test</strong>, which is used for comparing two nested models: the likelihood of a simpler model (the null hypothesis model) to the likelihood of a more complex model (the alternative hypothesis model) that contains all the parameters of the simpler model plus some additional parameters. If the more complex model significantly improves the likelihood, it suggests that the additional parameters are meaningful.</p>
<p>Let <span class="math inline">\(L_{restricted}\)</span> be the maximum likelihood of the simpler (nested) model, and L <span class="math inline">\(L_{full}\)</span> be the maximum likelihood of the more complex (full) model. The likelihood ratio test statistic (<span class="math inline">\(\Lambda\)</span>) is:</p>
<p><span class="math display">\[
\Lambda = - 2 \cdot \log \Bigg(\frac{L_{restricted}}{L_{full}}\Bigg)
\]</span></p>
<p>Which simplifies to (due to properties of logarithms):</p>
<p><span class="math display">\[
\Lambda = -2 \cdot [\log(L_{restricted})-\log(L_{full})]
\]</span></p>
<p>The Null Hypothesis (<span class="math inline">\(H_0\)</span>) of this test is that the additional parameters in the full model do not significantly improve the fit, so the simpler model is enough. The Alternative Hypothesis (<span class="math inline">\(H_1\)</span>) is that the more complex model provides a significantly better fit. Under the null hypothesis, <span class="math inline">\(\Lambda\)</span> asymptotically follows a chi-squared distribution with degrees of freedom equal to the difference in the number of parameters between the two models.<br />
A large <span class="math inline">\(\Lambda\)</span> value (and small p-value) indicates that the more complex model fits the data significantly better than the simpler model, leading to rejection of <span class="math inline">\(H_0\)</span>.</p>
<p><strong>Information criteria</strong> provide a way to balance model fit with model complexity. They are particularly useful for comparing non-nested models or when there are multiple competing models. Lower values generally indicate a better model. The goal is to find a model that explains the data well without being overly complex.</p>
<ul>
<li>AIC = <span class="math inline">\(-2 \log(L_{model})+2k\)</span><br />
where
<ul>
<li><span class="math inline">\(L_{model}\)</span> is the maximum likelihood of the fitted model</li>
<li><span class="math inline">\(k\)</span> is the is the number of parameters in the model,including the intercept and any cut-points in ordinal regression</li>
</ul></li>
<li>BIC = <span class="math inline">\(-2 \log(L_{model})+k\log(n)\)</span><br />
where
<ul>
<li><span class="math inline">\(L_{model}\)</span> is the maximum likelihood of the fitted model</li>
<li><span class="math inline">\(k\)</span> is the is the number of parameters in the model,including the intercept and any cut-points in ordinal regression</li>
<li><span class="math inline">\(n\)</span> is the sample size</li>
</ul></li>
</ul>
<p>AIC tends to favor more complex models and is generally better for prediction accuracy. BIC tends to favor simpler, more parsimonious models and is often preferred for model selection when the goal is to identify the “true” underlying model.</p>
</section>
</section>
</section>
<section id="beyond-the-proportional-odds-logit-model" class="level2" data-number="2.5">
<h2 data-number="2.5"><span class="header-section-number">2.5</span> Beyond the Proportional Odds Logit Model</h2>
<p>The Proportional Odds Model using the logit link function is the most common and often the default choice for analyzing ordinal data due to its interpretability (log-odds) and computational stability. However, the Proportional Odds Model is just one member of a broader family of models for ordinal outcomes. The specific choice of model can influence the interpretation and the fit to the data. Several alternatives exist.</p>
<section id="alternative-link-functions-for-cumulative-models" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1"><span class="header-section-number">2.5.1</span> Alternative Link Functions for Cumulative Models</h3>
<p>In a Proportional Odds Model, the “link function” transforms the cumulative probabilities to a linear scale, where they are modeled by your predictors.</p>
<p>The general form of a cumulative model is:</p>
<p><span class="math display">\[
g[P(R \leq r_j)] = \alpha_j - \boldsymbol{\beta}^T\boldsymbol{X}
\]</span> where - <span class="math inline">\(P(R \leq r_j)\)</span> is the cumulative probability of being in category <span class="math inline">\(j\)</span> or lower - <span class="math inline">\(g(\cdot)\)</span> is the link function - <span class="math inline">\(\alpha_j\)</span> are the category-specific intercepts - <span class="math inline">\(\boldsymbol{\beta}\)</span> is the vector of regression coefficients for the predictors - <span class="math inline">\(\boldsymbol{X}\)</span> is the vector of predictor variables</p>
<p>The link function can be a logit function, as shown previously, but it may be another function.</p>
<p><strong>Probit Link</strong></p>
<p>The probit link uses the inverse of the standard normal cumulative distribution function (<span class="math inline">\(\Phi^{-1}\)</span>) and it models the cumulative probabilities on a scale that corresponds to the normal distribution</p>
<p><span class="math display">\[
\text{probit}[P(R\leq r_j)] = \Phi^{-1}[P(R\leq r_j)] =  \alpha_j - \boldsymbol{\beta}^T\boldsymbol{X}
\]</span> The coefficients are interpreted in terms of standard deviation units of the underlying latent normal variable. A one-unit increase in <span class="math inline">\(X_k\)</span> leads to a <span class="math inline">\(\beta_k\)</span> standard deviation change in the latent variable. They don’t have the direct odds ratio interpretation of the logit model.</p>
<p>This link function is often preferred when there’s a theoretical belief that the underlying continuous variable driving the ordinal outcome is normally distributed.</p>
<p><strong>Log-log Link</strong></p>
<p>The Log-Log link is defined as follows:</p>
<p><span class="math display">\[
\text{loglog}[P(R\leq r_j)] =  \log(-\log(P(R\leq r_j))) =  \alpha_j - \boldsymbol{\beta}^T\boldsymbol{X}
\]</span></p>
<p>This link is used when the probability of the lowest category is expected to decrease very quickly, or when the process leading to higher categories accelerates rapidly.</p>
<p>The interpretation is less straightforward than logit. It’s more sensitive to changes in the upper tail of the probability distribution. It implies that the probability of being in a lower category decreases rapidly.</p>
</section>
</section>
<section id="alternative-model-structures" class="level2" data-number="2.6">
<h2 data-number="2.6"><span class="header-section-number">2.6</span> Alternative Model Structures</h2>
<p>Beyond altering the link function for cumulative probabilities, it is possible to change what probabilities the model is trying to explain.</p>
<p><strong>Adjacent Categories Logit Model</strong></p>
<p>Instead of modeling cumulative probabilities, the adjacent categories model focuses on the log-odds of being in category <span class="math inline">\(r_j\)</span> versus the next adjacent category <span class="math inline">\(r_{j+1}\)</span>:</p>
<p><span class="math display">\[
\log \Bigg(\frac{P(R = r_j)}{P(R = r_{j+1})}\Bigg) = \alpha_j - \boldsymbol{\beta}^T\boldsymbol{X} \qquad \text{for} \qquad j = 1,\dots,m-1
\]</span> In this model, the coefficients are not constrained to be the same across all adjacent log-odds comparisons. This means it does not assume the proportional odds assumption. Each <span class="math inline">\(\alpha_j\)</span> is a separate intercept for that specific adjacent comparison, and each <span class="math inline">\(\beta_j\)</span> is a separate vector of coefficients. So, for each pair of adjacent categories <span class="math inline">\(j\)</span> and <span class="math inline">\(j+1\)</span>, <span class="math inline">\(\text{exp}(\beta_k)\)</span> is the odds ratio of being in category <span class="math inline">\(j\)</span> versus <span class="math inline">\(j+1\)</span> for a one-unit change in <span class="math inline">\(X_k\)</span>.</p>
<p>The advantage of this model is that it does not impose the proportional odds assumption, so it is more flexible compared to the Proportional Odds Model. However, it leads to the estimation of <span class="math inline">\(m-1\)</span> sets of predictors which are many more parameters compared to the Proportional Odds Model; this can lead ot larger standard errors and require larger sample sizes.</p>
<p><strong>Continuation Ratio Logit Model</strong></p>
<p>This model focuses on the log-odds of being in category <span class="math inline">\(j\)</span> versus being in a higher category, given that the outcome is at least <span class="math inline">\(j\)</span>. It’s a sequential modeling approach. The model is expressed as: <span class="math display">\[
\log\left(\frac{P(R = r_j \mid R \ge r_j)}{P(R &gt; r_j \mid R \ge r_j)}\right) = \alpha_j - \boldsymbol{\beta}_j^T \mathbf{X} \quad \text{for } j=1, \dots, m-1
\]</span> Where:</p>
<ul>
<li><span class="math inline">\(P(Y = j \mid Y \ge j)\)</span> is the conditional probability of observing outcome category <span class="math inline">\(j\)</span>, given that the outcome is in category <span class="math inline">\(j\)</span> or higher.</li>
<li><span class="math inline">\(P(Y &gt; j \mid Y \ge j)\)</span> is the conditional probability of observing an outcome category higher than <span class="math inline">\(j\)</span>, given that the outcome is in category <span class="math inline">\(j\)</span> or higher.</li>
<li><span class="math inline">\(\alpha_j\)</span> is the category-specific intercept for the <span class="math inline">\(j\)</span>-th comparison.</li>
<li><span class="math inline">\(\boldsymbol{\beta}_j\)</span> is the vector of regression coefficients for the predictors <span class="math inline">\(\mathbf{x}\)</span> for the <span class="math inline">\(j\)</span>-th comparison.</li>
</ul>
<p>The exponential of a coefficient, <span class="math inline">\(\exp(\beta_{jk})\)</span>, represents the odds ratio of observing category <span class="math inline">\(j\)</span> versus observing a category higher than <span class="math inline">\(j\)</span>, given that the outcome is at least <span class="math inline">\(j\)</span>, for a one-unit increase in predictor <span class="math inline">\(x_k\)</span>. Crucially, the coefficients <span class="math inline">\(\boldsymbol{\beta}_j\)</span> can vary across these sequential comparisons (i.e., for different values of <span class="math inline">\(j\)</span>). This means the effect of a predictor might differ depending on which step of the ordinal scale is examined.</p>
<p>Similar to the adjacent categories model, the continuation ratio model typically does not assume proportional odds. This means it does not constrain the <span class="math inline">\(\boldsymbol{\beta}\)</span> coefficients to be constant across all sequential comparisons. However, a “proportional odds” variant can be imposed on the continuation ratios by forcing <span class="math inline">\(\boldsymbol{\beta}\)</span> to be constant across all <span class="math inline">\(j\)</span>.</p>
<p>This model is especially suited for situations where the ordinal categories represent a natural progression or a series of choices. Common applications include:</p>
<ul>
<li><p><strong>Educational Attainment</strong>: Modeling the odds of graduating from high school versus continuing to college, then the odds of completing college versus pursuing graduate studies, and so on.</p></li>
<li><p><strong>Disease Progression</strong>: Analyzing the odds of a patient staying at their current disease stage versus progressing to the next, more severe stage.</p></li>
<li><p><strong>Consumer Behavior</strong>: Understanding the odds of a customer making a basic purchase versus upgrading to a premium version.</p></li>
</ul>
</section>
</section>
<section id="beyond-standard-approaches-modeling-ordinal-data-with-cub-models" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Beyond Standard Approaches: Modeling Ordinal Data with CUB Models</h1>
<div class="column-margin">
<!-- <p><a href="materials/Script_plots_examples.R" download style="margin-right: 5px;"> <i class="bi bi-file-earmark-code-fill" style="font-size: 0.9em; vertical-align: middle;"></i> [R Script]{style="margin-left: 2px; vertical-align: middle;"} </a></p> -->
<p>
<a href="materials/Ordinal Data Analysis in R - Module 3.pdf" download> <i class="bi bi-file-earmark-slides-fill" style="font-size: 0.9em; vertical-align: middle;"></i> <span style="margin-left: 2px; vertical-align: middle;">Slides</span> </a>
</p>
</div>
<p>While powerful and widely used, Ordered logit models operate under specific assumptions:</p>
<ul>
<li><p><strong>Proportional Odds Assumption</strong>: This assumption can be restrictive and, if violated, can lead to misleading conclusions.</p></li>
<li><p><strong>Latent Variable Interpretation</strong>: While mathematically convenient, the interpretation of the latent variable might not always align perfectly with the psychological process of how an individual actually chooses an ordered category. The continuous latent variable often represents an underlying “utility” or “propensity,” but it doesn’t explicitly account for aspects like uncertainty or indecision in the response process.</p></li>
</ul>
<p>These limitations highlight a need for alternative modeling frameworks that can capture the nuanced complexities inherent in how individuals respond to ordinal scales.</p>
<p>There is a clear and compelling need for specialized statistical models designed to capture the unique characteristics of ordinal data and, importantly, to reflect the underlying cognitive and psychological processes through which individuals select a particular ordered category. This is where CUB models (Combination of a Uniform and a shifted Binomial random variable) come into play.</p>
<p>CUB models, primarily developed by Domenico Piccolo and collaborators starting in the early 2000s, offer a distinct and innovative approach to modeling ordinal data. They stand apart from traditional methods by explicitly incorporating psychological interpretations into their statistical structure.</p>
<p>At their core, CUB models are mixture models specifically tailored for ordinal data. The fundamental idea is that a respondent’s observed rating is not solely a direct and deterministic mapping of their true “feeling” or “utility.” Instead, it is also significantly affected by an element of “uncertainty” or “indecision” that can influence the final choice. This acknowledgment of psychological complexity in the response process is what makes CUB models particularly insightful for rating data.</p>
<section id="the-psychological-reasons-behind-the-cub-model" class="level2" data-number="3.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> The Psychological Reasons Behind the CUB Model</h2>
<p>The innovation of the CUB model lies in its attempt to statistically represent two fundamental psychological components that influence a respondent’s choice on an ordinal scale. The model posits that an observed rating <span class="math inline">\(R\)</span> is a probabilistic outcome of a decision process that weighs two components.</p>
<p><strong>1. Feeling (or Attraction/Preference)</strong></p>
<p>This component represents the conscious, rational, and deliberative aspect of the decision-making process. It reflects the respondent’s genuine evaluation, opinion, or perception regarding the item being rated. The “feeling” directs the respondent towards a specific category on the scale that best aligns with their internal assessment. This is the component that captures the respondent’s true position or stance on the matter at hand.</p>
<p>Depending on the specific context of the rating, “feeling” can be interpreted as:</p>
<ul>
<li><p><strong>Agreement/Disagreement</strong>: How much a person agrees or disagrees with a statement.</p></li>
<li><p><strong>Satisfaction/Dissatisfaction</strong>: The level of contentment or discontent with a product, service, or experience.</p></li>
<li><p><strong>Liking/Disliking</strong>: The degree of preference or aversion towards an item.</p></li>
<li><p><strong>Perceived quality, importance, risk, etc.</strong>: The subjective assessment of various attributes.</p></li>
</ul>
<p>In essence, the feeling component drives the respondent towards a particular region of the ordinal scale, reflecting their underlying preference or “attraction” to certain categories.</p>
<p><strong>2. Uncertainty (or Indecision/Fuzziness)</strong></p>
<p>This component captures the hesitation, randomness, or lack of decisiveness that can accompany the choice process. It acknowledges a crucial psychological reality: respondents may not always have a perfectly clear and precise mapping of their internal feeling onto the provided scale categories. This can introduce a degree of randomness or “noise” into the selection process.</p>
<p>Sources of this uncertainty can be varied and include:</p>
<ul>
<li><p><strong>Lack of Information or Knowledge</strong>: The respondent might not have sufficient information to form a strong opinion about the item being rated.</p></li>
<li><p><strong>Ambiguity</strong>: The question wording or the definition of the scale categories might be unclear, leading to confusion.</p></li>
<li><p><strong>Personal Tendencies</strong>: Some individuals may inherently be more indecisive or tend to use certain parts of a scale (e.g., sticking to the middle categories).</p></li>
<li><p><strong>Cognitive Effort/Satisficing</strong>: In long surveys or under time pressure, respondents might engage in “satisficing” behavior. Instead of expending full mental energy to find the optimal category, they might pick a plausible but not necessarily precise one to save cognitive effort.</p></li>
<li><p><strong>Time Pressure or Fatigue</strong>: Being rushed or tired can reduce the ability to make a precise decision.</p></li>
<li><p><strong>Emotional State or Mood</strong>: A respondent’s transient emotional state can also introduce variability into their choices.</p></li>
</ul>
<p>The uncertainty component effectively describes the probability that the respondent’s choice is influenced by random factors rather than a specific preference.</p>
</section>
<section id="the-cub-model-statistical-formulation" class="level2" data-number="3.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> The CUB Model: Statistical Formulation</h2>
<p>The basic CUB model, designed for m ordered categories (typically <span class="math inline">\(r=1,2,\dots,m\)</span>), is a finite mixture of two discrete probability distributions:</p>
<ul>
<li>A shifted Binomial distribution to model the feeling (or attraction/preference) component.</li>
<li>A discrete Uniform distribution to model the uncertainty (or indecision/fuzziness) component.</li>
</ul>
<p>The Probability Mass Function (PMF) for an observed rating <span class="math inline">\(R=r\)</span> is given by:</p>
<p><span class="math display">\[
P(R = r \mid \pi,\xi) = \pi B(r \mid\xi) + (1-\pi)U(r)
\]</span> where the elements of the mixture are:</p>
<ul>
<li><p><span class="math inline">\(m\)</span>: This is the number of ordered categories on the scale. For instance, if a scale ranges from “1 = Strongly Disagree” to “5 = Strongly Agree,” then <span class="math inline">\(m=5\)</span>.</p></li>
<li><p><span class="math inline">\(r\)</span>: This denotes the selected category by a respondent, where <span class="math inline">\(r\in \{ 1,2,…,m\}\)</span>.</p></li>
<li><p><span class="math inline">\(\pi \in (0,1]\)</span>, acts as a mixture weight. <span class="math inline">\(\pi\)</span> represents the probability that the observed choice is driven by the feeling component (i.e., the shifted Binomial distribution).<br />
Consequently, <span class="math inline">\((1−\pi)\)</span> is called <strong>Uncertainty parameter</strong> and represents the probability that the observed choice is driven by the uncertainty component (i.e., the discrete Uniform distribution). A higher value of <span class="math inline">\((1−\pi)\)</span> means greater indecision or randomness in the response, indicating that the uniform component has a stronger influence.</p></li>
<li><p><span class="math inline">\(\xi \in [0,1]\)</span>, is directly related to the shifted Binomial distribution and determines the location of the “feeling”.<br />
More intuitively, <span class="math inline">\((1−\xi)\)</span> is often considered the direct measure of “feeling”, indeed it is called <strong>Feeling parameter</strong>.</p>
<ul>
<li>If <span class="math inline">\((1−\xi)\)</span> is high (e.g., close to 1, meaning <span class="math inline">\(\xi\)</span> is close to 0), there’s a strong underlying feeling towards the higher end of the scale.</li>
<li>If <span class="math inline">\((1−\xi)\)</span> is low (e.g., close to 0, meaning <span class="math inline">\(\xi\)</span> is close to 1), there’s a strong underlying feeling towards the lower end of the scale.</li>
<li>If <span class="math inline">\((1−\xi) = 0.5\)</span> (meaning <span class="math inline">\(\xi=0.5\)</span>), the feeling component is neutral or centered, implying a symmetric preference if not for the influence of uncertainty.</li>
</ul></li>
<li><p><span class="math inline">\(U(r)\)</span>: This is the probability of choosing category <span class="math inline">\(r\)</span> according to a discrete Uniform distribution.<br />
For any category <span class="math inline">\(r\in\{1,2,…,m\}\)</span>, <span class="math inline">\(U(r)= \frac{1}{m}\)</span>.<br />
This component represents complete randomness or a lack of specific preference among the <span class="math inline">\(m\)</span> categories. If a respondent is entirely uncertain or indecisive, their response is essentially a random pick from the available options.</p></li>
<li><p><span class="math inline">\(B(r∣\xi)\)</span>: This is the probability of choosing category <span class="math inline">\(r\)</span> according to a shifted Binomial distribution.<br />
Specifically, this refers to <span class="math inline">\(P(X=r−1)\)</span> where <span class="math inline">\(X\sim Bin(m−1,1−\xi)\)</span>. The “shifted” aspect arises because the rating scale typically starts from 1, while a standard Binomial distribution’s trials start from 0. Thus, to model a choice of <span class="math inline">\(r\)</span> on a scale <span class="math inline">\(1,…,m\)</span>, we consider <span class="math inline">\(r−1\)</span> successes out of <span class="math inline">\(m−1\)</span> trials.<br />
So, the PMF is:</p></li>
</ul>
<p><span class="math display">\[
B(r\mid\xi)=\binom{m-1}{r-1}(1-\xi)^{r-1}\xi^{m-r}
\]</span></p>
<p>This component models the feeling towards a particular category, allowing for various shapes (unimodal, skewed left/right, or even U-shaped if <span class="math inline">\((1−\xi)\)</span> is extremely close to 0 or 1, though the latter is less common in direct “feeling” interpretation). It captures where the respondent’s underlying preference lies on the scale.</p>
<p>Finally, the CUB model can be written as: <span class="math display">\[
P(R = r \mid \pi,\xi) = \pi \binom{m-1}{r-1}(1-\xi)^{r-1}\xi^{m-r} + (1-\pi) \frac{1}{m}
\]</span></p>
<section id="interpretation-of-parameters" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1"><span class="header-section-number">3.2.1</span> Interpretation of Parameters</h3>
<p>The feeling <span class="math inline">\((1-\xi)\)</span> and the uncertainty <span class="math inline">\((1-\pi)\)</span> parameters are not merely statistical quantities; they have direct psychological meanings related to the respondent’s decision process.</p>
<p><strong>The Uncertainty Parameter</strong></p>
<p>It directly quantifies the level of uncertainty or indecision in the respondent’s choice.</p>
<ul>
<li><p>If <span class="math inline">\((1-\pi = 0)\)</span> (i.e., <span class="math inline">\(\pi = 1\)</span>) it means that the observed choice is entirely determined by the feeling, modeled by the binomial component. There is no uncertainty. The distribution of responses will reflect the shape of the Binomial.</p></li>
<li><p>If <span class="math inline">\((1−\pi)=1\)</span> (i.e., <span class="math inline">\(\pi=0\)</span>) it means that the observed choice is entirely determined by “uncertainty” (Uniform component). The respondent’s feeling plays no role. The distribution of responses will be perfectly flat, meaning each category is chosen with equal probability.</p></li>
<li><p>Values between 0 and 1 indicate a mix of the two components. A higher value of <span class="math inline">\((1−\pi)\)</span> effectively “flattens” the observed distribution of responses towards a uniform shape, as the random component gains more influence.</p></li>
</ul>
<p><strong>The Feeling Parameter</strong></p>
<p>The quantity <span class="math inline">\((1−\xi)\)</span> measures the underlying “feeling”, “preference”, or “attraction” of the respondent. It dictates the skewness and location of the Binomial component.</p>
<ul>
<li><p>If <span class="math inline">\((1−\xi)\)</span> is high (close to 1, so <span class="math inline">\(\xi\)</span> is close to 0), it means that there’s a strong attraction towards higher-valued categories. The Binomial component will be skewed to the right, with its mode (most frequent value) located at or near the maximum category <span class="math inline">\(m\)</span>.</p></li>
<li><p>If <span class="math inline">\((1−\xi)\)</span> is low (close to 0, so <span class="math inline">\(\xi\)</span> is close to 1) it means that there’s a strong attraction towards lower-valued categories. The Binomial component will be skewed to the left, with its mode located at or near the minimum category 1.</p></li>
<li><p>If <span class="math inline">\((1−\xi)=0.5\)</span> (so <span class="math inline">\(\xi=0.5\)</span>), the Binomial component is symmetric around the center of the scale, indicating a neutral or balanced feeling.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="images\CUBgrid.jpg" class="img-fluid" style="width:80.0%" /></p>
<figcaption>Probability distribution functions of the CUB model, for <span class="math inline">\(m = 7\)</span> and 9 combinations of feeling and uncertainty.</figcaption>
</figure>
</div>
</section>
<section id="model-identifiability-and-estimation" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2"><span class="header-section-number">3.2.2</span> Model identifiability and Estimation</h3>
<p>The CUB model is identifiable (i.e., different sets of parameter values lead to different probability distributions for the observed data) if the number of categories <span class="math inline">\(m &gt; 3\)</span>.</p>
<p>The parameters <span class="math inline">\((\pi, \xi)\)</span> of the CUB model are typically estimated using the Maximum Likelihood Estimation (MLE) method. MLE search for the parameter values that maximize the likelihood of observing the given data.</p>
<p>Since the CUB model is a mixture model, direct maximization of this log-likelihood function can be complex due to its non-linear nature. Therefore, the Expectation-Maximization (EM) algorithm is a common and robust iterative method for finding the MLEs.</p>
</section>
<section id="assessing-the-goodness-of-fit" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3"><span class="header-section-number">3.2.3</span> Assessing the Goodness of Fit</h3>
<p>A particularly common and intuitive measure for assessing how well a CUB model fits the observed data is the Dissimilarity (<span class="math inline">\(Diss\)</span>) Index. It quantifies the absolute difference between the observed and fitted proportions for each category. The <span class="math inline">\(Diss\)</span> index is defined as follows:</p>
<p><span class="math display">\[
Diss = \frac{1}{2}\sum_{r = 1}^{m} \mid f_r - p_r(\hat{\boldsymbol{\theta}})\mid
\]</span> where <span class="math inline">\(f_r\)</span> are the observed relative frequencies and <span class="math inline">\(p_r(\hat{\boldsymbol{\theta}})\)</span> are the estimated probabilities for the response categories.</p>
<ul>
<li>Values of <span class="math inline">\(Diss\)</span> closer to 0 indicate a better fit, with a perfect fit yielding <span class="math inline">\(Diss = 0\)</span>.</li>
<li>The maximum value of <span class="math inline">\(Diss\)</span> is 1 when there is no overlap between observed and fitted distributions.</li>
</ul>
<p>The Dissimilarity Index is popular because it provides a direct and easily interpretable measure of the overall discrepancy between the observed data distribution and the distribution predicted by the CUB model. In other words, it measures the proportion of responses to be changed to achieve a perfect fit.<br />
It is less sensitive to low expected frequencies than the Pearson Chi-squared test and gives a clear indication of prediction accuracy.</p>
</section>
<section id="parameter-space-visualization" class="level3" data-number="3.2.4">
<h3 data-number="3.2.4"><span class="header-section-number">3.2.4</span> Parameter Space Visualization</h3>
<p>CUB models offer a highly intuitive way to visualize the joint interpretation of their parameters: the parameter space visualization. This is typically represented on a unit square where:</p>
<p>The x-axis represents <span class="math inline">\((1−\pi)\)</span>, the uncertainty level. The y-axis represents <span class="math inline">\((1−\xi)\)</span>, the feeling or attraction level. This “CUB plot” is incredibly helpful for comparing different datasets, subgroups, or even changes within a single group over time. Key regions of this plot offer immediate insights:</p>
<ul>
<li><p><strong>Bottom-left corner</strong> (<span class="math inline">\((1−\pi)\approx0,(1−\xi)\approx0\)</span>): This indicates very low uncertainty (respondents are very certain in their choices) and a strong feeling towards low scores (e.g., strong disagreement, high dissatisfaction).</p></li>
<li><p><strong>Top-left corner</strong> (<span class="math inline">\((1−\pi)\approx0,(1−\xi)\approx1\)</span>): This signifies very low uncertainty and a strong feeling towards high scores (e.g., strong agreement, high satisfaction).</p></li>
<li><p><strong>Right side</strong> (<span class="math inline">\((1−\pi)\approx1\)</span>): This region represents very high uncertainty. In this scenario, the feeling component becomes less influential, and responses tend to be closer to a uniform distribution, indicating a significant degree of randomness in the choices.</p></li>
</ul>
<p>This graphical representation provides a powerful diagnostic tool for understanding the underlying psychological processes at play in rating data.</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="images\cartesian_agg.jpg" class="img-fluid" style="width:100.0%" /></p>
<figcaption>Graphical representation of the parameter space of the CUB model</figcaption>
</figure>
</div>
</section>
</section>
<section id="extensions-of-the-cub-model-incorporating-covariates" class="level2" data-number="3.3">
<h2 data-number="3.3"><span class="header-section-number">3.3</span> Extensions of the CUB Model: Incorporating Covariates</h2>
<p>The basic CUB model, as discussed in Chapter 2, provides a powerful framework for understanding the underlying feeling and uncertainty in rating data. However, the basic formulation assumes a homogeneity in the population, meaning that the parameters are constant for all individuals. While useful for initial descriptive analysis, this assumption often oversimplifies the complex reality of human responses.</p>
<p>In real-world applications, it is almost always more realistic to assume that the psychological components driving responses (the feeling and uncertainty components) vary across different individuals or groups. These variations are often systematically related to observable characteristics of the respondents or the context in which the ratings are collected.</p>
<p>The introduction of covariates into the CUB model allows us to move beyond a simple description of the overall population’s feeling and uncertainty, enabling a much more nuanced and insightful analysis. Specifically, introducing covariates allows us to:</p>
<ul>
<li><p><strong>Explain heterogeneity in response patterns</strong>: Instead of treating differences in responses as random noise, covariates enable us to identify systematic factors that explain why different individuals or groups exhibit different levels of feeling and uncertainty.</p></li>
<li><p><strong>Understand how specific characteristics influence feeling and uncertainty</strong>: This is perhaps the most powerful advantage. We can quantify the impact of a 10-year age increase on the probability of certainty (π) or the effect of a higher education level on the tendency to rate highly (1−ξ). This moves from mere description to explanation and inference.</p></li>
</ul>
<section id="statistical-formulation-of-cub-model-with-covariates" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1"><span class="header-section-number">3.3.1</span> Statistical Formulation of CUB Model with Covariates</h3>
<p>Formulation of CUB with Covariates In a CUB model with covariates, the core idea is that the parameters <span class="math inline">\(\pi\)</span> and <span class="math inline">\(\xi\)</span> are no longer fixed constants across all individuals. Instead, they are modeled as functions of a set of explanatory variables. Let <span class="math inline">\(y_i\)</span> be a vector of covariates for subject <span class="math inline">\(i\)</span> specifically influencing their uncertainty, and <span class="math inline">\(w_i\)</span> be a vector of covariates for subject <span class="math inline">\(i\)</span> influencing their feeling. These covariate vectors can be the same, overlap, or be entirely different.</p>
<p>To ensure that the parameters <span class="math inline">\(\pi_i\)</span> and <span class="math inline">\(\xi_i\)</span> remain within their valid range of <span class="math inline">\([0,1]\)</span>, a link function is employed, typically a logistic (logit) function, which is standard practice for modeling probabilities in generalized linear models.</p>
<p><strong>Modeling the uncertainty</strong></p>
<p>Since <span class="math inline">\(\pi_i\in [0,1]\)</span>, we model it using a logistic link. It’s often more intuitive to model <span class="math inline">\((1-\pi_i)\)</span>, which represents the probability that the choice is driven by the uniform component.</p>
<p>The log-odds of uncertainty are linked to the covariates <span class="math inline">\(y_i\)</span>:</p>
<p><span class="math display">\[
\text{logit}(1-\pi_i) = \log \Bigg(\frac{1-\pi_i}{\pi_i}\Bigg) = \boldsymbol{y}^{T}_i\boldsymbol{\beta}
\]</span> where <span class="math inline">\(\boldsymbol{\beta}\)</span> is a vector of coefficients corresponding to the covariates <span class="math inline">\(\boldsymbol{y}_i\)</span>.</p>
<p>From this, we can derive the direct relationships for <span class="math inline">\((1−\pi_i)\)</span> and <span class="math inline">\(\pi_i\)</span></p>
<p><span class="math display">\[
(1-\pi_i)=\frac{\exp(\boldsymbol{y}^{T}_i\boldsymbol{\beta})}{1+\exp(\boldsymbol{y}^{T}_i\boldsymbol{\beta})}
\]</span></p>
<p>And consequently, for <span class="math inline">\(\pi_i\)</span>:</p>
<p><span class="math display">\[
\pi_i = 1-(1-\pi_i) = 1- \frac{\exp(\boldsymbol{y}^{T}_i\boldsymbol{\beta})}{1+\exp(\boldsymbol{y}^{T}_i\boldsymbol{\beta})} = \frac{1}{1+\exp(\boldsymbol{y}^{T}_i\boldsymbol{\beta})}
\]</span></p>
<p><strong>Modeling the feeling</strong></p>
<p>Similarly, for <span class="math inline">\(\xi_i\in [0,1]\)</span>, a logit link is applied. It’s often more insightful to directly model <span class="math inline">\((1-\xi_i)\)</span>, which represents the feeling towards higher scores on the scale.</p>
<p>The log-odds of feeling for higher scores are linked to the covariates <span class="math inline">\(w_i\)</span> :</p>
<p><span class="math display">\[
\text{logit}(1-\xi_i) = \log \Bigg(\frac{1-\xi_i}{\xi_i}\Bigg) = \boldsymbol{w}^{T}_i\boldsymbol{\gamma}
\]</span> where <span class="math inline">\(\boldsymbol{\gamma}\)</span> is a vector of coefficients corresponding to the covariates <span class="math inline">\(\boldsymbol{w}_i\)</span>.</p>
<p>This implies the following fo <span class="math inline">\((1−\xi_i)\)</span>:</p>
<p><span class="math display">\[
(1-\xi_i)=\frac{\exp(\boldsymbol{w}^{T}_i\boldsymbol{\gamma})}{1+\exp(\boldsymbol{w}^{T}_i\boldsymbol{\gamma})}
\]</span></p>
<p>And for <span class="math inline">\(\xi_i\)</span>:</p>
<p><span class="math display">\[
\xi_i = 1-(1-\xi_i) = 1- \frac{\exp(\boldsymbol{w}^{T}_i\boldsymbol{\gamma})}{1+\exp(\boldsymbol{w}^{T}_i\boldsymbol{\gamma})} = \frac{1}{1+\exp(\boldsymbol{w}^{T}_i\boldsymbol{\gamma})}
\]</span></p>
<p>With these formulations, the overall probability mass function for an observed rating R=r for subject i becomes:</p>
<p><span class="math display">\[
P(R_i = r \mid \pi_i,\xi_i) = \pi_i \binom{m-1}{r-1}(1-\xi_i)^{r-1}\xi_i^{m-r} + (1-\pi_i) \frac{1}{m}
\]</span></p>
<p>where <span class="math inline">\(\pi_i\)</span> and <span class="math inline">\(\xi_i\)</span> are determined by the covariates as defined above.</p>
</section>
<section id="interpretation-of-covariate-effects" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2"><span class="header-section-number">3.3.2</span> Interpretation of Covariate Effects</h3>
<p>Interpreting the coefficients (<span class="math inline">\(\beta\)</span> and <span class="math inline">\(\gamma\)</span>) in a CUB model with covariates is crucial for understanding how specific characteristics influence the psychological components of rating. Remember that these coefficients operate on the log-odds scale due to the logistic link.</p>
<p><strong>Coefficients <span class="math inline">\(\beta\)</span></strong></p>
<p>These coefficients describe the impact of covariates on the log-odds of uncertainty.</p>
<p>A positive coefficient <span class="math inline">\(\beta_k\)</span> implies that an increase in the <span class="math inline">\(k\)</span>-th covariate <span class="math inline">\(y_{ik}\)</span>, holding other covariates constant, increases the log-odds of uncertainty. Therefore <span class="math inline">\((1−\pi_i)\)</span> increases and makes the respondent’s choice more driven by the uniform component. This suggests that as <span class="math inline">\(y_{ik}\)</span> increases, the individual is more indecisive or random in their rating.</p>
<p>A negative <span class="math inline">\(\beta_k\)</span> implies that an increase in <span class="math inline">\(y_{ik}\)</span> decreases the log-odds of uncertainty, thus decreasing <span class="math inline">\((1−\pi_i)\)</span> and making the respondent’s choice more driven by their underlying feeling. This suggests that as <span class="math inline">\(y_{ik}\)</span> increases, the individual becomes more certain in their rating.</p>
<p><strong>Coefficients <span class="math inline">\(\gamma\)</span></strong></p>
<p>These coefficients describe the impact of covariates <span class="math inline">\(w_i\)</span> on the log-odds of feeling towards higher scores.</p>
<p>A positive <span class="math inline">\(\gamma_k\)</span> implies that an increase in the <span class="math inline">\(k\)</span>-th covariate <span class="math inline">\(w_{ik}\)</span>, holding other covariates constant, increases the log-odds of feeling for higher scores, thus increasing <span class="math inline">\((1-\xi_i)\)</span>. This means that as <span class="math inline">\(w_{ik}\)</span> increases, the individual’s underlying preference shifts towards the higher end of the rating scale.</p>
<p>A negative <span class="math inline">\(\gamma_k\)</span> implies that an increase in <span class="math inline">\(w_{ik}\)</span> decreases the log-odds of feeling for higher scores, thus decreasing <span class="math inline">\((1-\xi_i)\)</span>. This means that as <span class="math inline">\(w_{ik}\)</span> increases, the individual’s underlying preference shifts towards the lower end of the rating scale.</p>
<p><strong>Important Note</strong>: CUB models with covariates are not Generalized Linear Models (GLMs) in the strict sense. While the parameters <span class="math inline">\(\pi_i\)</span> and <span class="math inline">\(\xi_i\)</span> are linked to covariates using GLM-like structures (specifically, logistic regressions), the response variable itself (the mixture of Binomial and Uniform distributions) does not belong to the exponential family.</p>
</section>
</section>
<section id="cub-model-with-shelter-option" class="level2" data-number="3.4">
<h2 data-number="3.4"><span class="header-section-number">3.4</span> CUB Model with Shelter Option</h2>
<p>While the basic CUB model effectively captures the feeling and uncertainty in ordinal responses, real-world rating data often exhibit additional complexities.</p>
<p>One such common phenomenon is the tendency for respondents to disproportionately select a specific category, not entirely explained by their true underlying feeling or by simple random guessing. This over-selection of a particular category suggests it acts as a “shelter” or “refuge” for some respondents.</p>
<p>The shelter effect describes a situation where a specific category on an ordinal scale receives an “extra” probability mass, beyond what would be predicted solely by the respondent’s underlying feeling or by pure random uncertainty. This happens because some respondents might gravitate towards this category for reasons unrelated to their precise preference or indecision.</p>
<p>Reasons for this “shelter-seeking” behavior have been extensively discussed in the literature (e.g., Iannario, 2012; Piccolo &amp; Simone, 2019):</p>
<ul>
<li><p><strong>Cognitive Simplification</strong>: Respondents may choose an easy, or cognitively less demanding option to reduce mental effort. This could be the middle category (e.g., “Neutral”), a neutral option specifically provided, or even the first/last option if it serves as an easy default.</p></li>
<li><p><strong>Fatigue or Boredom</strong>: Especially prevalent in long questionnaires or surveys, fatigue can lead respondents to disengage and simply pick a convenient category rather than carefully considering their true response.</p></li>
<li><p><strong>Social Desirability or Privacy Concerns</strong>: Individuals might select a “safe”, non-committal, or socially acceptable answer to avoid expressing a strong or controversial opinion, or to protect their privacy. The neutral option often serves this purpose.</p></li>
<li><p><strong>Questionnaire Design</strong>: Poorly worded questions, ambiguous scale anchors, or an overwhelming number of options might inadvertently guide respondents towards a default or ambiguous middle ground.</p></li>
<li><p><strong>Satisficing</strong>: This refers to the tendency to select a minimally acceptable response rather than the optimal one, often to save cognitive resources. The shelter option becomes the “good enough” answer.</p></li>
</ul>
<p>The critical implication of the shelter effect is that the chosen category <span class="math inline">\(c\)</span> has an “extra” probability mass. This means the observed frequency for category <span class="math inline">\(c\)</span> is higher than what a standard two-component CUB model would predict. Effectively, a subset of respondents might be selecting <span class="math inline">\(c\)</span> directly, bypassing the usual feeling-uncertainty decision process.</p>
<section id="defining-the-shelter-category" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1"><span class="header-section-number">3.4.1</span> Defining the shelter category</h3>
<p>The shelter category, denoted by <span class="math inline">\(c\)</span> (where <span class="math inline">\(c \in \{1,2,…,m\}\)</span>), is a specific category on the ordinal scale that exhibits this inflated probability mass. Identifying this category is a crucial preliminary step. It can be:</p>
<ul>
<li><strong>Hypothesized a priori</strong>: In many cases, the shelter category can be hypothesized beforehand based on the scale’s design. For instance, on a 5-point Likert scale (1=Strongly Disagree, 5=Strongly Agree), the central category <span class="math inline">\(c=3\)</span> (“Neutral” or “Neither agree nor disagree”) is a very common candidate for a shelter option. Other possibilities could be the minimum (<span class="math inline">\(c=1\)</span>) or maximum (<span class="math inline">\(c=m\)</span>) category if they function as easy “opt-out” or default choices.</li>
<li><strong>Identified Empirically</strong>: If no a priori hypothesis exists, the shelter category can be identified empirically. This involves observing an unusually high frequency for a particular category that is not well explained by a simple CUB model. A large positive residual for a specific category from a basic CUB fit can point towards a potential shelter effect.</li>
</ul>
<p>Once identified, the shelter category <span class="math inline">\(c\)</span> is treated as fixed in the model estimation.</p>
</section>
<section id="statistical-formulation-of-cub-model-with-shelter-option" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2"><span class="header-section-number">3.4.2</span> Statistical Formulation of CUB Model with Shelter Option</h3>
<p>To account for the shelter effect, the basic CUB model is extended into a three-component mixture model. A common and highly interpretable approach is the CUB with Shelter (CUSH) model. This model introduces a third component: a degenerate distribution that assigns all probability mass exclusively to the shelter category <span class="math inline">\(c\)</span>.</p>
<p>The probability mass function (PMF) for the CUSH model for a rating <span class="math inline">\(R=r\)</span> is given by:</p>
<p><span class="math display">\[
P(R = r\mid \pi, \xi, \delta) = \delta \Big[D_c(r)\Big] + (1-\delta)\Big[\pi B(r \mid \xi) + (1-\pi)U(r)\Big]
\]</span></p>
<p>where there is an additional component, compared to the basic CUB model: the degenerate distribution fir the shelter category <span class="math inline">\(c\)</span>, <span class="math inline">\(D_c(r)\)</span>:</p>
<p><span class="math display">\[
D_c(r) =
\begin{cases}
    1, &amp; \text{if } r = s; \\
    0, &amp; \text{otherwise;}
\end{cases}
\qquad r = 1, \dots, m.
\]</span></p>
<p>The parameter <span class="math inline">\(\delta \in [0,1]\)</span> represents the probability of choosing the shelter category <span class="math inline">\(c\)</span> directly. This is the weight assigned to the degenerate distribution. A higher <span class="math inline">\(\delta\)</span> indicates a stronger tendency for respondents to opt for the designated shelter category, irrespective of their true feeling or general uncertainty.</p>
<p><strong>Model selection</strong></p>
<p>Model selection is crucial when deciding whether a CUSH model offers a significantly better fit than a simpler CUB model. Standard statistical criteria can be used:</p>
<p>Information criteria like Akaike Information Criterion and Bayesian information Criterion are widely used to balance model fit with model complexity.</p>
<p>Lower values for AIC and BIC indicate a better-fitting model. BIC is often preferred in model selection for CUB models as it penalizes model complexity more heavily, which can help in choosing more parsimonious models.</p>
<p>After fitting a basic CUB model, it’s good practice to examine the residuals, which are the differences between observed and fitted probabilities/frequencies. If a simple CUB model shows a large positive residual for a specific category, it strongly suggests the presence of a shelter effect for that category. The Dissimilarity Index (<span class="math inline">\(Diss\)</span>) can also be used to compare the overall fit improvement when a shelter component is added.</p>
</section>
</section>
<section id="treatment-of-dont-know-dk-options-within-the-cub-framework" class="level2" data-number="3.5">
<h2 data-number="3.5"><span class="header-section-number">3.5</span> Treatment of “Don’t Know” (DK) Options within the CUB Framework</h2>
<p>Beyond the core rating scale, surveys often include an option for respondents to indicate “Don’t Know” (DK), “No Opinion”, “Not Applicable”, or similar non-substantive responses. While seemingly innocuous, the handling of these responses presents a significant challenge for traditional statistical modeling, as they often don’t fit neatly into standard analytical frameworks.</p>
<p>The CUB framework, however, offers a theoretically robust and psychologically insightful approach to incorporating information from DK responses.</p>
<p>“Don’t Know” responses are common in surveys, and their treatment is critical for valid statistical inference. They are not merely missing data points; rather, they represent an active choice that reflects a specific cognitive or attitudinal state of the respondent.</p>
<p>DK responses are problematic for several reasons:</p>
<ul>
<li><p><strong>Not Simply Missing Data</strong>: Treating DKs as simple missing values and discarding them (listwise deletion) can lead to biased samples and results. If respondents who choose DK differ systematically from those who provide substantive ratings, removing them can distort the representativeness of the remaining sample, affecting parameter estimates and generalizability.</p></li>
<li><p><strong>Imputation Issues</strong>: Imputing a value for a DK response is inherently difficult and often relies on strong, untestable assumptions. Assigning a central value (e.g., the mean or median of the substantive responses) might mask genuine uncertainty, while more complex imputation methods (e.g., multiple imputation) can be challenging to implement and interpret accurately in the context of ordinal data.</p></li>
<li><p><strong>Adding DK as a Category</strong>: A seemingly straightforward approach is to include DK as just another category on the ordinal scale. However, this fundamentally breaks the ordinal nature of the scale. For example, a sequence like “Strongly Disagree, Disagree, DK, Agree, Strongly Agree” is conceptually problematic. The DK option is not naturally ordered between “Disagree” and “Agree”; it represents a different type of response altogether. Its inclusion disrupts the monotonic relationship implied by ordinal categories.</p></li>
</ul>
<p>To properly handle DK responses, it is essential to understand their underlying meanings. Research suggests that “Don’t Know” can have several psychological interpretations:</p>
<ul>
<li><em>True Lack of Knowledge/Opinion</em>: The respondent genuinely has no information, experience, or hasn’t formed an opinion on the topic. Unwillingness to Answer: The respondent might have an opinion but chooses not to express it due to a sensitive topic, privacy concerns, or wanting to appear socially desirable (e.g., not wanting to seem extreme or uninformed).</li>
<li><em>Inability to Map Opinion to Scale</em>: The respondent might have an opinion but feels the provided scale categories are inadequate, too vague, or don’t quite fit their nuanced view. They might feel their true sentiment falls “between” categories or doesn’t align with any.</li>
<li><em>Question Ambiguity</em>: The respondent simply might not understand the question, its underlying assumptions, or the terms used, leading them to pick DK as a way out.</li>
</ul>
<p>The varied meanings of DK emphasize that it’s a rich source of information, not just data to be thrown away or arbitrarily filled in.</p>
<p>The approach for handling DK responses in the CUB framework is to think of the total population as having two unobserved (latent) groups:</p>
<ul>
<li><p>Group A=0: Those who can give a substantive rating on the m-point scale. These people have a genuine underlying feeling or are able to make a choice, even if that choice has some general uncertainty.</p></li>
<li><p>Group A=1: Those who cannot (or would not) and would genuinely choose DK if it were an option. This group essentially represents the “true” non-responders when it comes to having a substantive opinion.</p></li>
</ul>
<p>We’ll use <span class="math inline">\(p_{DK}\)</span> to represent the proportion of individuals in the population who would choose DK.</p>
<section id="modeling-assumptions-for-latent-groups" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1"><span class="header-section-number">3.5.1</span> Modeling Assumptions for Latent Groups</h3>
<p>This approach makes specific assumptions about how each latent group generates responses:</p>
<p>For those who can answer (Group A=0, proportion <span class="math inline">\((1-p_{DK})\)</span>): When these individuals provide a substantive rating (<span class="math inline">\(R=r\)</span>), their responses are assumed to follow a standard CUB model. This CUB model has its own parameters, <span class="math inline">\(\pi_0\)</span> (for uncertainty within this group) and <span class="math inline">\(\xi_0\)</span> (for feeling within this group), which describe the feeling and uncertainty among those capable of providing an opinion.</p>
<p><span class="math display">\[
P(R = r \mid A = 0, \pi_0, \xi_0) = \pi_0B(r\mid\xi_0) + (1-\pi_0)U(r)
\]</span></p>
<p>For those who would choose DK (Group A=1, proportion <span class="math inline">\(p_{DK}\)</span>), if these individuals are forced to pick a category from the m-point scale (e.g., if the DK option isn’t available, or if their preference for DK is part of their general uncertainty), their choice isn’t based on a genuine “feeling”. Instead, their responses are driven purely by randomness or uncertainty across the available options. So, their responses are modeled by a discrete Uniform distribution.</p>
<p><span class="math display">\[
P(R = r\mid A =1) =U(r)= \frac{1}{m}
\]</span></p>
<p>The overall observed distribution of ratings, if all respondents are forced to choose from the m-point scale (meaning no explicit DK option is given, or if we consider the hypothetical responses of those who would pick DK if it were there), is a mix of the CUB model for “knowers” and the Uniform distribution for those “forced” to choose.</p>
</section>
<section id="adjusting-cub-parameters-using-observed-dks" class="level3" data-number="3.5.2">
<h3 data-number="3.5.2"><span class="header-section-number">3.5.2</span> Adjusting CUB Parameters using Observed DKs</h3>
<p>The method proposed in this framework uses the presence of DKs to adjust the fundamental uncertainty in the main CUB model.</p>
<p>When DK responses are explicitly allowed in a survey and are present in the data the approach proceeds as follows:</p>
<ol type="1">
<li>Estimate <span class="math inline">\(p_{DK}\)</span>: This is simply the observed proportion of DK responses in the sample.</li>
</ol>
<p><span class="math display">\[
\hat{p}_{DK} = \frac{Total\, number\, of\, DK\, responses}{Total\, number\, of\, responses}
\]</span></p>
<ol start="2" type="1">
<li><p>Focus on <strong>Substantive Responders</strong>: The remaining <span class="math inline">\((1- \hat{p}_{DK})\)</span> proportion of the sample consists of individuals who gave a rating on the m-point ordinal scale (i.e., they picked a category from <span class="math inline">\(1,…,m\)</span>). Let <span class="math inline">\(N_{sub}\)</span> be the number of these substantive responders.</p></li>
<li><p><strong>Model for Substantive Responses</strong>: A standard CUB model is then fitted only to these <span class="math inline">\(N_{sub}\)</span> substantive responses. This fitting process gives us estimates for their underlying parameters, called <span class="math inline">\(\pi_S\)</span> and <span class="math inline">\(\xi_S\)</span>. This model describes the probability distribution of ratings given that a substantive response was provided: <span class="math display">\[
P(R = r \mid Substantive) = \pi_SB(r\mid\xi_S) + (1-\pi_S)U(r)
\]</span></p></li>
<li><p><strong>Relating to the Overall Population Parameters</strong>: The crucial step is to link these parameters <span class="math inline">\((\pi_S, \xi_S)\)</span> back to the overall population’s true feeling and uncertainty, taking into account the proportion of DKs.</p>
<ul>
<li><p>The feeling parameter for the overall population, <span class="math inline">\((1-\xi)\)</span>, is considered to be best represented by the feeling of those who actually gave a substantive rating. This is based on the idea that people who genuinely say “Don’t Know” don’t contribute to the “feeling” aspect of the scale. So: <span class="math display">\[
(1-\xi) = (1-\xi_S)
\]</span></p></li>
<li><p>The overall uncertainty parameter for the population, <span class="math inline">\((1-\pi)\)</span>, comes from two sources:</p>
<ul>
<li>The inherent uncertainty among those who could answer (captured by <span class="math inline">\(1-\pi_S\)</span>).</li>
<li>The complete uncertainty of those who chose DK (who are considered 100% uncertain regarding the m-point scale). The overall <span class="math inline">\(\pi\)</span> for the population (the probability that a response is driven by feeling) is then calculated as:</li>
</ul></li>
</ul></li>
</ol>
<p><span class="math display">\[
\pi = (1-\hat{p}_{DK})\cdot\pi_S
\]</span></p>
<p>This means the overall probability that a response is based on feeling (<span class="math inline">\(\pi\)</span>) is the probability that a respondent isn’t a DK type <span class="math inline">\((1-\hat{p}_{DK})\)</span> multiplied by the probability that, given they aren’t a DK type, they respond based on feeling <span class="math inline">\((\pi_S)\)</span>.</p>
<p>Consequently, the overall uncertainty for the population is:</p>
<p><span class="math display">\[
(1-\pi) = 1-(1-\hat{p}_{DK})\cdot\pi_S
\]</span></p>
<p>This can be rewritten as:</p>
<p><span class="math display">\[
(1-\pi) = \hat{p}_{DK} + (1-\hat{p}_{DK})\cdot(1-\pi_S)
\]</span></p>
<p>This last equation shows that the overall uncertainty in the population is the sum of the proportion of individuals who selected DK <span class="math inline">\((\hat{p}_{DK})\)</span> and the proportion of uncertainty among those who provided a substantive response <span class="math inline">\((1-\pi_S)\)</span>, weighted by their share of the total population <span class="math inline">\((1-\hat{p}_{DK})\)</span>.</p>
<div id="quarto-navigation-envelope" class="hidden">
<p><span class="hidden" data-render-id="quarto-int-sidebar-title">Matteo Ventura</span> <span class="hidden" data-render-id="quarto-int-navbar-title">Matteo Ventura</span> <span class="hidden" data-render-id="quarto-int-navbar:About">About</span> <span class="hidden" data-render-id="quarto-int-navbar:/about.html">/about.html</span> <span class="hidden" data-render-id="quarto-int-navbar:Publications">Publications</span> <span class="hidden" data-render-id="quarto-int-navbar:/publications.html">/publications.html</span> <span class="hidden" data-render-id="quarto-int-navbar:Courses">Courses</span> <span class="hidden" data-render-id="quarto-int-navbar:/courses.html">/courses.html</span> <span class="hidden" data-render-id="quarto-int-navbar:Contacts">Contacts</span> <span class="hidden" data-render-id="quarto-int-navbar:/contacts.html">/contacts.html</span></p>
</div>
<div id="quarto-listing-pipeline" class="hidden">
<p><span class="hidden" data-render-id="quarto-enable-math-inline"><span class="math inline">\(e = mC^2\)</span></span></p>
<div class="hidden" data-render-id="pipeline-listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
</div>
<div id="quarto-meta-markdown" class="hidden">
<p><span class="hidden" data-render-id="quarto-metatitle">Matteo Ventura - Ordinal Data Analysis in R</span> <span class="hidden" data-render-id="quarto-twittercardtitle">Matteo Ventura - Ordinal Data Analysis in R</span> <span class="hidden" data-render-id="quarto-ogcardtitle">Matteo Ventura - Ordinal Data Analysis in R</span> <span class="hidden" data-render-id="quarto-metasitename">Matteo Ventura</span> <span class="hidden" data-render-id="quarto-twittercarddesc">Measuring Human Perceptions from Surveys</span> <span class="hidden" data-render-id="quarto-ogcardddesc">Measuring Human Perceptions from Surveys</span></p>
</div>
<!-- -->
<div class="quarto-embedded-source-code">
<div class="sourceCode" id="cb17" data-shortcodes="false"><pre class="sourceCode markdown"><code class="sourceCode markdown"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> &quot;Ordinal Data Analysis in R&quot;</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> &quot;Measuring Human Perceptions from Surveys&quot;</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> &quot;Matteo Ventura&quot;</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> &quot;06/09/2025&quot;</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> false</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="an">listing:</span><span class="co"> true</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [ordinal data, CUB, survey]</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 2</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-location: left</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co">    number-sections: true</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: spacelab</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co">    highlight-style: tango</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co">    df-print: paged</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co">    css: styles.css</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co">    callout-appearance: simple</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co">    grid:</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="co">      margin-width: 300px</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="co">      body-width: 1000px </span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true         </span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true          # &lt;-- AGGIUNGI QUESTA RIGA per supporto formule in HTML</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="co">  pdf:</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="co">    latex-distribution: miktex</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="co">    documentclass: scrartcl</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co">    engine: lualatex</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="co">    number-sections: true</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="co">    keep-tex: true          # &lt;-- OPZIONALE: utile per debug</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a><span class="co">  echo: true</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> </span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a><span class="co">  markdown: </span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a><span class="co">    wrap: sentence</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &lt;p&gt; --&gt;</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   &lt;a href=&quot;materials/CUM7vsCUB.r&quot; download style=&quot;margin-right: 15px;&quot;&gt; --&gt;</span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     &lt;i class=&quot;bi bi-file-earmark-code-fill&quot; style=&quot;font-size: 1.2em; vertical-align: middle;&quot;&gt;&lt;/i&gt; --&gt;</span></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     &lt;span style=&quot;margin-left: 5px; vertical-align: middle;&quot;&gt;R Script&lt;/span&gt; --&gt;</span></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   &lt;/a&gt; --&gt;</span></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   &lt;a href=&quot;materials/CV_VENTURA_ITA_nodata.pdf&quot; download&gt; --&gt;</span></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     &lt;i class=&quot;bi bi-file-earmark-slides-fill&quot; style=&quot;font-size: 1.2em; vertical-align: middle;&quot;&gt;&lt;/i&gt; --&gt;</span></span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     &lt;span style=&quot;margin-left: 5px; vertical-align: middle;&quot;&gt;Slides&lt;/span&gt; --&gt;</span></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   &lt;/a&gt; --&gt;</span></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &lt;/p&gt; --&gt;</span></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a>::: cell</span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;style&gt; p { text-align: justify; } &lt;/style&gt;</span></span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;h1&gt;</span>Description of the course<span class="kw">&lt;/h1&gt;</span></span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a>Surveys are key tools for measuring human perceptions, capturing latent traits through structured responses.</span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a>Among the data they generate, ordinal and rating data are particularly important yet often less studied, requiring specialized statistical techniques.</span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a>Ordinal data appears frequently in real-world applications, such as customer satisfaction surveys, psychological assessments, and medical research, making its correct analysis crucial for obtaining reliable insights.</span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a>This short course provides instructor-led, hands-on training in the analysis of ordinal data.</span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a>It begins with an overview of survey design and the validation of results, focusing on building effective surveys and ensuring the reliability of the data obtained.</span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a>The course then covers the most commonly used statistical models for analyzing ordinal data, with an emphasis on discovering latent patterns and traits.</span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a>Both theoretical foundations and practical applications will be explored, using real-world case studies from domains such as marketing, social sciences, tourism and culture.</span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a>A common approach to analyzing ordinal data is to treat it as numerical, but this can lead to a loss of statistical power.</span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a>In this course, participants will learn how to apply specialized methods designed for ordinal data, allowing them to draw more effective and reliable conclusions.</span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;h1&gt;</span>Objectives of the course<span class="kw">&lt;/h1&gt;</span></span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a>By the end of the course, participants will have both theoretical knowledge and practical skills to analyze ordinal data in research and professional settings.</span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a>Specifically, they will be able to:</span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-82"><a href="#cb17-82" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Understand what ordinal data is, how it differs from other types of data, and the challenges involved in its analysis</span>
<span id="cb17-83"><a href="#cb17-83" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Compute and interpret reliability and validity measures</span>
<span id="cb17-84"><a href="#cb17-84" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Fit proportional odds models in R and interpret the results</span>
<span id="cb17-85"><a href="#cb17-85" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Analyse rating data by applying CUB models</span>
<span id="cb17-86"><a href="#cb17-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-87"><a href="#cb17-87" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction to Ordinal Data and Survey Design</span></span>
<span id="cb17-88"><a href="#cb17-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-89"><a href="#cb17-89" aria-hidden="true" tabindex="-1"></a>::: {.content-visible when-format=&quot;html&quot;}</span>
<span id="cb17-90"><a href="#cb17-90" aria-hidden="true" tabindex="-1"></a>::: column-margin</span>
<span id="cb17-91"><a href="#cb17-91" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;p&gt;&lt;a</span> <span class="er">href</span><span class="ot">=</span><span class="st">&quot;materials/Script_plots_examples.R&quot;</span> <span class="er">download</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;margin-right: 5px;&quot;</span><span class="kw">&gt;</span> <span class="kw">&lt;i</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;bi bi-file-earmark-code-fill&quot;</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;font-size: 0.9em; vertical-align: middle;&quot;</span><span class="kw">&gt;&lt;/i&gt;</span> <span class="co">[</span><span class="ot">R Script</span><span class="co">]</span>{style=&quot;margin-left: 2px; vertical-align: middle;&quot;} <span class="kw">&lt;/a&gt;&lt;/p&gt;</span></span>
<span id="cb17-92"><a href="#cb17-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-93"><a href="#cb17-93" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;p&gt;&lt;a</span> <span class="er">href</span><span class="ot">=</span><span class="st">&quot;materials/Ordinal Data Analysis in R - Module 1.pdf&quot;</span> <span class="er">download</span><span class="kw">&gt;</span> <span class="kw">&lt;i</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;bi bi-file-earmark-slides-fill&quot;</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;font-size: 0.9em; vertical-align: middle;&quot;</span><span class="kw">&gt;&lt;/i&gt;</span> <span class="co">[</span><span class="ot">Slides</span><span class="co">]</span>{style=&quot;margin-left: 2px; vertical-align: middle;&quot;} <span class="kw">&lt;/a&gt;&lt;/p&gt;</span></span>
<span id="cb17-94"><a href="#cb17-94" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-95"><a href="#cb17-95" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-96"><a href="#cb17-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-97"><a href="#cb17-97" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Role of Measurement in Science</span></span>
<span id="cb17-98"><a href="#cb17-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-99"><a href="#cb17-99" aria-hidden="true" tabindex="-1"></a>Measurement is a fundamental activity in science, indeed we acquire knowledge about the world around us by observing it, and we usually quantify to give a sense to what we observe.</span>
<span id="cb17-100"><a href="#cb17-100" aria-hidden="true" tabindex="-1"></a>Therefore, measurement is essential in a wide range of research contexts.</span>
<span id="cb17-101"><a href="#cb17-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-102"><a href="#cb17-102" aria-hidden="true" tabindex="-1"></a>There exist several situations in which scientists come up with measurement problems, even though they are not interested primary in measurement.</span>
<span id="cb17-103"><a href="#cb17-103" aria-hidden="true" tabindex="-1"></a>For instance:</span>
<span id="cb17-104"><a href="#cb17-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-105"><a href="#cb17-105" aria-hidden="true" tabindex="-1"></a>1)  A health psychologist needs a measurement scale which doesn&#39;t seem to exist.</span>
<span id="cb17-106"><a href="#cb17-106" aria-hidden="true" tabindex="-1"></a>    The study depends on a tool that can clearly distinguish between what individuals want to happen and what they expect to happen when visiting a physician.</span>
<span id="cb17-107"><a href="#cb17-107" aria-hidden="true" tabindex="-1"></a>    However, the review of previous research reveals that existing scales often blur this distinction, unintentionally mixing the two concepts.</span>
<span id="cb17-108"><a href="#cb17-108" aria-hidden="true" tabindex="-1"></a>    None of the available instruments capture the separation in the specific way her study requires.</span>
<span id="cb17-109"><a href="#cb17-109" aria-hidden="true" tabindex="-1"></a>    While the psychologist could create a few items that appear to address the difference between wants and expectations, she/he is concerned that these improvised questions may lack the reliability and validity necessary to serve as accurate measures.</span>
<span id="cb17-110"><a href="#cb17-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-111"><a href="#cb17-111" aria-hidden="true" tabindex="-1"></a>2)  An epidemiologist is conducting secondary analyses on data from a national health survey.</span>
<span id="cb17-112"><a href="#cb17-112" aria-hidden="true" tabindex="-1"></a>    They wish to investigate the link between perceived psychological stress and health status.</span>
<span id="cb17-113"><a href="#cb17-113" aria-hidden="true" tabindex="-1"></a>    Unfortunately, the survey did not include a validated stress measure.</span>
<span id="cb17-114"><a href="#cb17-114" aria-hidden="true" tabindex="-1"></a>    While it may be possible to construct one using existing items, a poorly constructed scale could lead to misleading conclusions.</span>
<span id="cb17-115"><a href="#cb17-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-116"><a href="#cb17-116" aria-hidden="true" tabindex="-1"></a>3)  A marketing team is struggling to design a campaign for a new line of high-end infant toys.</span>
<span id="cb17-117"><a href="#cb17-117" aria-hidden="true" tabindex="-1"></a>    Focus groups suggest that parents are heavily influenced by a toy&#39;s perceived educational value.</span>
<span id="cb17-118"><a href="#cb17-118" aria-hidden="true" tabindex="-1"></a>    The team hypothesizes that parents with strong educational and career aspirations for their children are more likely to be interested in the product.</span>
<span id="cb17-119"><a href="#cb17-119" aria-hidden="true" tabindex="-1"></a>    To test this idea across a broad, geographically diverse sample, the team needs a way to reliably measure parental aspirations.</span>
<span id="cb17-120"><a href="#cb17-120" aria-hidden="true" tabindex="-1"></a>    Something that additional focus groups can&#39;t easily provide.</span>
<span id="cb17-121"><a href="#cb17-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-122"><a href="#cb17-122" aria-hidden="true" tabindex="-1"></a>Despite coming from different disciplines, these researchers share a common understanding: using arbitrary or poorly designed measurement tools increases the risk of collecting inaccurate data.</span>
<span id="cb17-123"><a href="#cb17-123" aria-hidden="true" tabindex="-1"></a>As a result, developing their own carefully constructed measurement instruments appears to be the most reliable solution.</span>
<span id="cb17-124"><a href="#cb17-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-125"><a href="#cb17-125" aria-hidden="true" tabindex="-1"></a>Historically, measurement problems were well-known in natural sciences such as physics and astronomy, even concerning figures like Isaac Newton.</span>
<span id="cb17-126"><a href="#cb17-126" aria-hidden="true" tabindex="-1"></a>However, among social scientists, a debate arose regarding the measurability of psychological variables.</span>
<span id="cb17-127"><a href="#cb17-127" aria-hidden="true" tabindex="-1"></a>While physical attributes like mass and length seem to possess an intrinsic mathematical structure similar to positive real numbers, the measurement of psychological variables was considered impossible by the Commission of the British Association for the Advancement of Science.</span>
<span id="cb17-128"><a href="#cb17-128" aria-hidden="true" tabindex="-1"></a>The primary reason was the difficulty in objectively ordering or summing sensory perceptions, as well illustrated by the question: how can one establish that a sensation of &quot;a little warm&quot; plus another similar sensation equals &quot;twice as warm&quot;?</span>
<span id="cb17-129"><a href="#cb17-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-130"><a href="#cb17-130" aria-hidden="true" tabindex="-1"></a><span class="fu">### Measurement classification {.unnumbered .toc-ignore}</span></span>
<span id="cb17-131"><a href="#cb17-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-132"><a href="#cb17-132" aria-hidden="true" tabindex="-1"></a>The americal psychologist Stevens (1946) disagreed with this perspective.</span>
<span id="cb17-133"><a href="#cb17-133" aria-hidden="true" tabindex="-1"></a>He contended that the rigid requirement of &quot;strict additivity,&quot; as seen in measurements of length or mass, was not essential for measuring sensations.</span>
<span id="cb17-134"><a href="#cb17-134" aria-hidden="true" tabindex="-1"></a>He pointed out that individuals could make reasonably consistent ratio judgments regarding the loudness of sounds.</span>
<span id="cb17-135"><a href="#cb17-135" aria-hidden="true" tabindex="-1"></a>For instance, they could determine if one sound was twice as loud as another.</span>
<span id="cb17-136"><a href="#cb17-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-137"><a href="#cb17-137" aria-hidden="true" tabindex="-1"></a>Stevens further argued that this &quot;ratio&quot; characteristic enabled the data derived from such measurements to be mathematically analyzed.</span>
<span id="cb17-138"><a href="#cb17-138" aria-hidden="true" tabindex="-1"></a>He is known for categorizing measurements into nominal, ordinal, interval, and ratio scales.</span>
<span id="cb17-139"><a href="#cb17-139" aria-hidden="true" tabindex="-1"></a>In his view, judgments about sound &quot;loudness&quot; belonged to the ratio scale.</span>
<span id="cb17-140"><a href="#cb17-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-141"><a href="#cb17-141" aria-hidden="true" tabindex="-1"></a>Despite the classification proposed by Stevens has been criticized by several authors and new classifications has been proposed, it is the most commonly accepted and used internationally.</span>
<span id="cb17-142"><a href="#cb17-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-143"><a href="#cb17-143" aria-hidden="true" tabindex="-1"></a>Stevens identified four properties for describing the scales of measurement:</span>
<span id="cb17-144"><a href="#cb17-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-145"><a href="#cb17-145" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Identity**: each value has a unique meaning.</span>
<span id="cb17-146"><a href="#cb17-146" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Magnitude**: the values of the variable have an ordered relationship to one another, so there is a specific order to the variables.</span>
<span id="cb17-147"><a href="#cb17-147" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Equal intervals**: the data points along the scale are equally spaced, so the difference between data points one and two, is the same as data points three and four.</span>
<span id="cb17-148"><a href="#cb17-148" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**A minimum value of zero**: the scale has a true zero point.</span>
<span id="cb17-149"><a href="#cb17-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-150"><a href="#cb17-150" aria-hidden="true" tabindex="-1"></a>As previously said, Stevens identified four scales of measurement, that is how variables are defined and categorised:</span>
<span id="cb17-151"><a href="#cb17-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-152"><a href="#cb17-152" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Nominal scale of measurement**: This scale has certain characteristics, but doesn’t have any form of numerical meaning.</span>
<span id="cb17-153"><a href="#cb17-153" aria-hidden="true" tabindex="-1"></a>    The data can be placed into categories but can’t be multiplied, divided, added or subtracted from one another.</span>
<span id="cb17-154"><a href="#cb17-154" aria-hidden="true" tabindex="-1"></a>    It’s also not possible to measure the difference between data points.</span>
<span id="cb17-155"><a href="#cb17-155" aria-hidden="true" tabindex="-1"></a>    It defines only the identity property of data.\</span>
<span id="cb17-156"><a href="#cb17-156" aria-hidden="true" tabindex="-1"></a>    Examples: Gender, Etnicity, Eye colour...</span>
<span id="cb17-157"><a href="#cb17-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-158"><a href="#cb17-158" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Ordinal scale of measurement**: It defines data that is placed in a specific order.</span>
<span id="cb17-159"><a href="#cb17-159" aria-hidden="true" tabindex="-1"></a>    While each value is ranked, there’s no information that specifies what differentiates the categories from each other.</span>
<span id="cb17-160"><a href="#cb17-160" aria-hidden="true" tabindex="-1"></a>    These values can’t be added to or subtracted from.\</span>
<span id="cb17-161"><a href="#cb17-161" aria-hidden="true" tabindex="-1"></a>    Examples: satisfaction data points in a survey, where ‘one = happy, two = neutral and three = unhappy.’</span>
<span id="cb17-162"><a href="#cb17-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-163"><a href="#cb17-163" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Interval scale of measurement**: The interval scale contains properties of nominal and ordered data, but the difference between data points can be quantified.</span>
<span id="cb17-164"><a href="#cb17-164" aria-hidden="true" tabindex="-1"></a>    This type of data shows both the order of the variables and the exact differences between the variables.</span>
<span id="cb17-165"><a href="#cb17-165" aria-hidden="true" tabindex="-1"></a>    They can be added to or subtracted from each other, but not multiplied or divided (For example, 40 degrees is not 20 degrees multiplied by two.).\</span>
<span id="cb17-166"><a href="#cb17-166" aria-hidden="true" tabindex="-1"></a>    In this scale of measurement the zero is just a convention and not absolute, it is an existing value of the variable itself.</span>
<span id="cb17-167"><a href="#cb17-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-168"><a href="#cb17-168" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Ratio scale of measurement**: This scale include properties from all four scales of measurement.</span>
<span id="cb17-169"><a href="#cb17-169" aria-hidden="true" tabindex="-1"></a>    The data is nominal and defined by an identity, can be classified in order, contains intervals and can be broken down into exact value.</span>
<span id="cb17-170"><a href="#cb17-170" aria-hidden="true" tabindex="-1"></a>    Weight, height and distance are all examples of ratio variables.</span>
<span id="cb17-171"><a href="#cb17-171" aria-hidden="true" tabindex="-1"></a>    Data in the ratio scale can be added, subtracted, divided and multiplied.</span>
<span id="cb17-172"><a href="#cb17-172" aria-hidden="true" tabindex="-1"></a>    Ratio scales also differ from interval scales in that the scale has a ‘true zero’.</span>
<span id="cb17-173"><a href="#cb17-173" aria-hidden="true" tabindex="-1"></a>    The number zero means that the data has no value point.\</span>
<span id="cb17-174"><a href="#cb17-174" aria-hidden="true" tabindex="-1"></a>    An example of this is height or weight, as someone cannot be zero centimetres tall or weigh zero kilos.</span>
<span id="cb17-175"><a href="#cb17-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-176"><a href="#cb17-176" aria-hidden="true" tabindex="-1"></a><span class="fu">## Scales and Questionnaires development</span></span>
<span id="cb17-177"><a href="#cb17-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-178"><a href="#cb17-178" aria-hidden="true" tabindex="-1"></a>Measurement plays a vital role across scientific disciplines, with each field creating specialized methods and tools tailored to its unique subjects of study.</span>
<span id="cb17-179"><a href="#cb17-179" aria-hidden="true" tabindex="-1"></a>In the behavioral and social sciences, the area devoted to measurement is called psychometrics.</span>
<span id="cb17-180"><a href="#cb17-180" aria-hidden="true" tabindex="-1"></a>This subfield concentrates on evaluating psychological and social constructs, which are most often assessed using questionnaires.</span>
<span id="cb17-181"><a href="#cb17-181" aria-hidden="true" tabindex="-1"></a>Theaching how to build effective questionnaires would require a specific course, but this is out of the scope of this course.</span>
<span id="cb17-182"><a href="#cb17-182" aria-hidden="true" tabindex="-1"></a>The following are some practical guidelines that researchers can use to develop measurement scales and questionnaires.</span>
<span id="cb17-183"><a href="#cb17-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-184"><a href="#cb17-184" aria-hidden="true" tabindex="-1"></a><span class="fu">### Determine Clearly What You Want to Measure {.unnumbered .toc-ignore}</span></span>
<span id="cb17-185"><a href="#cb17-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-186"><a href="#cb17-186" aria-hidden="true" tabindex="-1"></a>Researchers often discover their initial ideas about what they want to measure are vague, which can lead to costly changes later.</span>
<span id="cb17-187"><a href="#cb17-187" aria-hidden="true" tabindex="-1"></a>Key questions include whether the scale should be theory-based or explore new directions, its level of specificity, and which aspects of the phenomenon to emphasize.</span>
<span id="cb17-188"><a href="#cb17-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-189"><a href="#cb17-189" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Define the theory**: Basing scale development on relevant substantive theories is essential for clearly defining the construct being measured, particularly when dealing with abstract or non-observable phenomena.</span>
<span id="cb17-190"><a href="#cb17-190" aria-hidden="true" tabindex="-1"></a>    A theoretical basis helps establish the construct’s boundaries, reducing the risk of the scale extending into unrelated areas.</span>
<span id="cb17-191"><a href="#cb17-191" aria-hidden="true" tabindex="-1"></a>    In the absence of an existing theory, developers should create a conceptual framework of their own—beginning with a precise definition and linking the new construct to related, established ones.</span>
<span id="cb17-192"><a href="#cb17-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-193"><a href="#cb17-193" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Determine the level of specificity**: In psychometric scale development, it’s important to consider how general or specific the measurement should be.</span>
<span id="cb17-194"><a href="#cb17-194" aria-hidden="true" tabindex="-1"></a>    This decision affects how well the scale works in predicting or relating to other variables.</span>
<span id="cb17-195"><a href="#cb17-195" aria-hidden="true" tabindex="-1"></a>    For example, if you&#39;re interested in general attitudes about personal control, a broad scale scale works well.</span>
<span id="cb17-196"><a href="#cb17-196" aria-hidden="true" tabindex="-1"></a>    But if you&#39;re studying beliefs about controlling a specific health issue, a focused scale is more appropriate.</span>
<span id="cb17-197"><a href="#cb17-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-198"><a href="#cb17-198" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Define which aspects are enphasised**: Scale developers must clearly distinguish the target construct from related ones.</span>
<span id="cb17-199"><a href="#cb17-199" aria-hidden="true" tabindex="-1"></a>    Scales can be broad (e.g., general anxiety) or narrow (e.g., test anxiety).</span>
<span id="cb17-200"><a href="#cb17-200" aria-hidden="true" tabindex="-1"></a>    Including items outside the intended focus can lead to confusion or inaccurate measurement.</span>
<span id="cb17-201"><a href="#cb17-201" aria-hidden="true" tabindex="-1"></a>    For example, in health contexts, physical symptoms caused by an illness might be mistaken for psychological symptoms (like depression), leading to misleading results.</span>
<span id="cb17-202"><a href="#cb17-202" aria-hidden="true" tabindex="-1"></a>    Therefore, item selection should match the specific research purpose and avoid overlap with unrelated constructs.</span>
<span id="cb17-203"><a href="#cb17-203" aria-hidden="true" tabindex="-1"></a>    <span class="co">&lt;!-- When building a scale, it&#39;s important to make sure it measures only the construct of interest—not other, similar ones. For instance, if you&#39;re interested in measuring test anxiety, including items about social anxiety would muddy the results. Similarly, if a depression scale includes physical symptoms like fatigue, it might confuse illness-related issues (like arthritis-related tiredness) with depression. This can distort results, especially in clinical or medical research. So, researchers need to be deliberate about item selection, ensuring the scale reflects exactly what they want to measure—and nothing else. --&gt;</span></span>
<span id="cb17-204"><a href="#cb17-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-205"><a href="#cb17-205" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ::: {.callout-tip} --&gt;</span></span>
<span id="cb17-206"><a href="#cb17-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-207"><a href="#cb17-207" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- If a depression scale includes physical symptoms like fatigue, it might confuse illness-related issues (like arthritis-related tiredness) with depression. This can distort results, especially in clinical or medical research.  --&gt;</span></span>
<span id="cb17-208"><a href="#cb17-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-209"><a href="#cb17-209" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ::: --&gt;</span></span>
<span id="cb17-210"><a href="#cb17-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-211"><a href="#cb17-211" aria-hidden="true" tabindex="-1"></a><span class="fu">### Generate an Item Pool {.unnumbered .toc-ignore}</span></span>
<span id="cb17-212"><a href="#cb17-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-213"><a href="#cb17-213" aria-hidden="true" tabindex="-1"></a>When developing a psychometric scale, items should be **carefully selected** or created to match the specific construct you aim to measure.</span>
<span id="cb17-214"><a href="#cb17-214" aria-hidden="true" tabindex="-1"></a>That means you need a clear idea of what the scale is supposed to do, and every item on the scale should reflect that goal.</span>
<span id="cb17-215"><a href="#cb17-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-216"><a href="#cb17-216" aria-hidden="true" tabindex="-1"></a>Imagine the construct (like anxiety, motivation, or trust) as something hidden or latent, which can&#39;t be observed directly.</span>
<span id="cb17-217"><a href="#cb17-217" aria-hidden="true" tabindex="-1"></a>The items on your scale are the visible signs or behaviors that reflect this hidden thing.</span>
<span id="cb17-218"><a href="#cb17-218" aria-hidden="true" tabindex="-1"></a>So, each item acts like a small &quot;test&quot; of how much of that construct a person has.</span>
<span id="cb17-219"><a href="#cb17-219" aria-hidden="true" tabindex="-1"></a>If your items truly measure the construct, then someone with a high level of the trait should tend to score higher on all of them.</span>
<span id="cb17-220"><a href="#cb17-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-221"><a href="#cb17-221" aria-hidden="true" tabindex="-1"></a>When constructing the item pool, it is important to consider the following aspects:</span>
<span id="cb17-222"><a href="#cb17-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-223"><a href="#cb17-223" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**The latent construct** A good scale includes multiple items to improve reliability, but every single item must still be strongly connected to the latent construct.</span>
<span id="cb17-224"><a href="#cb17-224" aria-hidden="true" tabindex="-1"></a>    You should think broadly and creatively when writing items to make sure they cover all the different ways the construct can be expressed—but without straying into measuring something else.\</span>
<span id="cb17-225"><a href="#cb17-225" aria-hidden="true" tabindex="-1"></a>    A construct is a single, unified idea (like “attitudes toward punishing drug abusers”) that can be thought of as causing how someone responds to related items.</span>
<span id="cb17-226"><a href="#cb17-226" aria-hidden="true" tabindex="-1"></a>    A category, on the other hand, is just a grouping of different constructs (like “attitudes” in general, or “barriers to compliance”).\</span>
<span id="cb17-227"><a href="#cb17-227" aria-hidden="true" tabindex="-1"></a>    Just because several items relate to the same category doesn’t mean they measure the same underlying construct.</span>
<span id="cb17-228"><a href="#cb17-228" aria-hidden="true" tabindex="-1"></a>    For instance, &quot;Barriers to compliance” is a category that can include many distinct things (fear of symptoms, cost concerns, distance to treatment, etc.). Each of these could be a separate construct with its own latent variable, so a scale that mixes these up wouldn&#39;t truly be unidimensional (i.e., measuring just one thing).</span>
<span id="cb17-229"><a href="#cb17-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-230"><a href="#cb17-230" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Redundancy** is crucial for reliability: multiple items allow common content to summate while idiosyncrasies cancel out.</span>
<span id="cb17-231"><a href="#cb17-231" aria-hidden="true" tabindex="-1"></a>    However, avoid superficial redundancy (e.g., minor wording changes, identical grammatical structures) which can inflate reliability estimates.</span>
<span id="cb17-232"><a href="#cb17-232" aria-hidden="true" tabindex="-1"></a>    Useful redundancy involves expressing the same core idea differently.</span>
<span id="cb17-233"><a href="#cb17-233" aria-hidden="true" tabindex="-1"></a>    Overly specific or redundant items within a broader scale can create subclusters (e.g., multiple specific anxiety items in a general emotion scale), potentially undermining unidimensionality and biasing the scale.</span>
<span id="cb17-234"><a href="#cb17-234" aria-hidden="true" tabindex="-1"></a>    This is less of a problem if the items match the scale&#39;s intended specificity.</span>
<span id="cb17-235"><a href="#cb17-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-236"><a href="#cb17-236" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**The number of items** Start with more items than planned for the final scale (e.g., 3-4 times as many) to allow for careful selection and ensure good internal consistency.</span>
<span id="cb17-237"><a href="#cb17-237" aria-hidden="true" tabindex="-1"></a>    An initial pool 50% larger might suffice if items are hard to generate or fewer are needed for reliability.</span>
<span id="cb17-238"><a href="#cb17-238" aria-hidden="true" tabindex="-1"></a>    If the pool is too large, eliminate items based on criteria like lack of clarity or relevance.</span>
<span id="cb17-239"><a href="#cb17-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-240"><a href="#cb17-240" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**The wording** Including both positively worded items (indicating the presence of the construct) and negatively worded items (indicating its absence or low levels) is a common strategy to reduce acquiescence bias—the tendency of respondents to agree with statements regardless of their content.</span>
<span id="cb17-241"><a href="#cb17-241" aria-hidden="true" tabindex="-1"></a>    However, reversing the wording can sometimes confuse participants, particularly in general population or community samples, and this confusion may reduce the scale&#39;s reliability.</span>
<span id="cb17-242"><a href="#cb17-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-243"><a href="#cb17-243" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Explanation: --&gt;</span></span>
<span id="cb17-244"><a href="#cb17-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-245"><a href="#cb17-245" aria-hidden="true" tabindex="-1"></a>::: callout-caution</span>
<span id="cb17-246"><a href="#cb17-246" aria-hidden="true" tabindex="-1"></a>Reversing the wording of items (also known as reversed polarity) can confuse respondents, especially if the items are complex or abstract, ot if the respondents have lower reading comprehension or aren’t used to taking surveys.\</span>
<span id="cb17-247"><a href="#cb17-247" aria-hidden="true" tabindex="-1"></a>This confusion can lead to inconsistent or inaccurate responses, which lowers the reliability of the scale (i.e., how consistently it measures the construct).</span>
<span id="cb17-248"><a href="#cb17-248" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-249"><a href="#cb17-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-250"><a href="#cb17-250" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- When people respond to surveys, some tend to just agree with statements out of habit—this is called acquiescence bias. To prevent this, researchers often mix in negatively worded items (e.g., “I rarely feel confident” alongside “I feel confident”) to check whether the respondent is paying attention and to balance out response patterns. --&gt;</span></span>
<span id="cb17-251"><a href="#cb17-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-252"><a href="#cb17-252" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- However, this technique can backfire. Reversing the wording of items (also known as reversed polarity) can confuse respondents, especially if: --&gt;</span></span>
<span id="cb17-253"><a href="#cb17-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-254"><a href="#cb17-254" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- The items are complex or abstract. --&gt;</span></span>
<span id="cb17-255"><a href="#cb17-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-256"><a href="#cb17-256" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- The respondents have lower reading comprehension or aren’t used to taking surveys (as is sometimes the case in community or general population samples). --&gt;</span></span>
<span id="cb17-257"><a href="#cb17-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-258"><a href="#cb17-258" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- This confusion can lead to inconsistent or inaccurate responses, which lowers the reliability of the scale (i.e., how consistently it measures the construct). So, while including both types of items has its benefits, it should be done carefully, with attention to clarity and the characteristics of the target population. --&gt;</span></span>
<span id="cb17-259"><a href="#cb17-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-260"><a href="#cb17-260" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Conclusion (Item Pool): The item pool should be large, relevant, and contain useful redundancy. Items should be grammatically sound, avoid ambiguity, and not force respondents into &quot;package deals&quot;.  --&gt;</span></span>
<span id="cb17-261"><a href="#cb17-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-262"><a href="#cb17-262" aria-hidden="true" tabindex="-1"></a><span class="fu">### Determine the Format for Measurement {.unnumbered .toc-ignore}</span></span>
<span id="cb17-263"><a href="#cb17-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-264"><a href="#cb17-264" aria-hidden="true" tabindex="-1"></a>Defining the measurement format is a critical step in designing data collection instruments like questionnaires and scales.</span>
<span id="cb17-265"><a href="#cb17-265" aria-hidden="true" tabindex="-1"></a>This decision, ideally made concurrently with item generation, impacts data quality, variability, instrument sensitivity, and ultimately, research conclusions.</span>
<span id="cb17-266"><a href="#cb17-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-267"><a href="#cb17-267" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Thurstone Scaling: Aims to create items that respond (&quot;resonate&quot;) to specific levels of an attribute, like tuning forks. Judges typically sort items into piles representing equal intervals of the construct. Respondents&#39; agreement patterns theoretically pinpoint their level of the attribute. Elegant but difficult to implement effectively.  --&gt;</span></span>
<span id="cb17-268"><a href="#cb17-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-269"><a href="#cb17-269" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Guttman Scaling: Items tap progressively higher levels of an attribute, so endorsing one implies endorsing all lower-level items. The score is the highest item endorsed. Works well for objective, hierarchical data (e.g., smoking frequency) but less so for subjective constructs where the order might vary across individuals.  --&gt;</span></span>
<span id="cb17-270"><a href="#cb17-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-271"><a href="#cb17-271" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Scales With Equally Weighted Items: Fit well with models where items are roughly equivalent indicators of a common phenomenon. Allows flexibility in response formats.  --&gt;</span></span>
<span id="cb17-272"><a href="#cb17-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-273"><a href="#cb17-273" aria-hidden="true" tabindex="-1"></a>Most scale items consist of two parts: a stem and a series of response options.</span>
<span id="cb17-274"><a href="#cb17-274" aria-hidden="true" tabindex="-1"></a>A kew aspect of the scale items is the number of response options.</span>
<span id="cb17-275"><a href="#cb17-275" aria-hidden="true" tabindex="-1"></a>A desiderable quality of a measurement scale is variability.</span>
<span id="cb17-276"><a href="#cb17-276" aria-hidden="true" tabindex="-1"></a>One way to increase opportunities for variability is to include lots of scale items.</span>
<span id="cb17-277"><a href="#cb17-277" aria-hidden="true" tabindex="-1"></a>Another way is to provide numerous respose options within each item, especially with fewer items.</span>
<span id="cb17-278"><a href="#cb17-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-279"><a href="#cb17-279" aria-hidden="true" tabindex="-1"></a>In this view, continuous formats (e.g., thermometer scales) offer many gradations, and so increase the opportunities for variability.</span>
<span id="cb17-280"><a href="#cb17-280" aria-hidden="true" tabindex="-1"></a>However, too many options can exceed respondents&#39; ability to meaningfully discriminate, leading to &quot;false precision&quot; and increased error variance.</span>
<span id="cb17-281"><a href="#cb17-281" aria-hidden="true" tabindex="-1"></a>Researchers must balance the need for variability with respondents&#39; cognitive limitations.</span>
<span id="cb17-282"><a href="#cb17-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-283"><a href="#cb17-283" aria-hidden="true" tabindex="-1"></a>Another issue the investigator has to concern with, is whether the number of options should be even or odd.</span>
<span id="cb17-284"><a href="#cb17-284" aria-hidden="true" tabindex="-1"></a>This choice depends on the type of question.</span>
<span id="cb17-285"><a href="#cb17-285" aria-hidden="true" tabindex="-1"></a>the type of response option, and the objectives of the investigator.</span>
<span id="cb17-286"><a href="#cb17-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-287"><a href="#cb17-287" aria-hidden="true" tabindex="-1"></a>An odd number of categories usually allows to express neutrality, while an even number of categories forces a choice from the respondent.</span>
<span id="cb17-288"><a href="#cb17-288" aria-hidden="true" tabindex="-1"></a>The choice depends on whether allowing neutrality is desirable or should be avoided.</span>
<span id="cb17-289"><a href="#cb17-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-290"><a href="#cb17-290" aria-hidden="true" tabindex="-1"></a>There exist several ways to present items that are commonly used:</span>
<span id="cb17-291"><a href="#cb17-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-292"><a href="#cb17-292" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Likert scales**: are widely used psychometric tools designed to measure attitudes, opinions, and perceptions by assessing the degree of agreement or disagreement with a statement. These scales typically present a statement (called a Likert item) followed by an ordered series of response options, generally consisting of five or seven points. However, scales with four, nine, or ten points can also be employed.</span>
<span id="cb17-293"><a href="#cb17-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-294"><a href="#cb17-294" aria-hidden="true" tabindex="-1"></a>Response anchors are the labels that define each point on the scale (for example, &quot;Strongly disagree,&quot; &quot;Disagree,&quot; &quot;Neutral,&quot; &quot;Agree,&quot; &quot;Strongly agree&quot;).</span>
<span id="cb17-295"><a href="#cb17-295" aria-hidden="true" tabindex="-1"></a>Scales with an odd number of points often include a neutral midpoint, while scales with an even number of points force the respondent to express a direction (agreement or disagreement).</span>
<span id="cb17-296"><a href="#cb17-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-297"><a href="#cb17-297" aria-hidden="true" tabindex="-1"></a>Likert scales are extensively applied in surveys to assess employee engagement, customer satisfaction, product feedback, and clinical evaluations.</span>
<span id="cb17-298"><a href="#cb17-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-299"><a href="#cb17-299" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Key Insight: The structure of a Likert scale, including the number of points and the wording of the anchors, significantly influences the data collected. Researchers must carefully consider these factors to ensure the scale accurately measures the desired construct. --&gt;</span></span>
<span id="cb17-300"><a href="#cb17-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-301"><a href="#cb17-301" aria-hidden="true" tabindex="-1"></a>::: callout-warning</span>
<span id="cb17-302"><a href="#cb17-302" aria-hidden="true" tabindex="-1"></a>Although Likert scale data is often numerically coded to facilitate analysis, it&#39;s essential to remember their ordinal nature and approach the calculation of means with caution.</span>
<span id="cb17-303"><a href="#cb17-303" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-304"><a href="#cb17-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-305"><a href="#cb17-305" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Median and mode represent more robust measures of central tendency for this type of data.  --&gt;</span></span>
<span id="cb17-306"><a href="#cb17-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-307"><a href="#cb17-307" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span></span>
<span id="cb17-308"><a href="#cb17-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-309"><a href="#cb17-309" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>**Semantic Differential scales**: are assessment tools used to measure attitudes and opinions toward an object, person, event, or idea through pairs of bipolar adjectives. Developed by psychologist Charles E. Osgood, these scales present a concept followed by several rows of opposite adjective pairs placed at the extremes of a continuum, typically with five to seven intermediate points. Respondents evaluate the concept on each adjectival scale by selecting the point that best represents their attitude. Examples of bipolar adjective pairs include &quot;Good - Bad,&quot; &quot;Happy - Sad,&quot; &quot;Strong - Weak,&quot; and &quot;Pleasant - Unpleasant.&quot; These scales are commonly used in market research, branding, and customer satisfaction assessments to understand perceptions and associations.</span>
<span id="cb17-310"><a href="#cb17-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-311"><a href="#cb17-311" aria-hidden="true" tabindex="-1"></a>Semantic differential scales explore the connotative meaning of a concept, revealing the emotional and evaluative dimensions of attitudes, unlike Likert scales which primarily focus on the degree of agreement.</span>
<span id="cb17-312"><a href="#cb17-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-313"><a href="#cb17-313" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Data visualization for semantic differential scales can be accomplished through semantic differential graphs (often resembling line profiles connecting the average ratings for each adjective pair) or by treating each scale as an ordinal variable and using divergent stacked bar charts. --&gt;</span></span>
<span id="cb17-314"><a href="#cb17-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-315"><a href="#cb17-315" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Visualization Considerations: When visualizing semantic differential scale data, it&#39;s crucial to clearly represent the bipolar nature of the scales, allowing for easy comparison of responses across different adjective pairs for the same concept or between different groups for the same adjective pair. --&gt;</span></span>
<span id="cb17-316"><a href="#cb17-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-317"><a href="#cb17-317" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Rankings**: represent data where items are ordered according to a specific criterion or preference. Respondents arrange items in a sequence based on their preference, importance, or another defined attribute. Examples include ranking favorite movies, product features by importance, or job candidates. Ranking data indicates relative order but not the magnitude of difference between positions. The difference between the first and second positions might be substantial, while the difference between lower positions might be negligible.</span>
<span id="cb17-318"><a href="#cb17-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-319"><a href="#cb17-319" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Key Insight: Analysis of ranking data focuses on the position of items within the ordered sequence. Visualizations should emphasize the distribution of positions for each item and facilitate comparisons regarding how frequently items appear in different positions. --&gt;</span></span>
<span id="cb17-320"><a href="#cb17-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-321"><a href="#cb17-321" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Visual Analog Scale** (VAS): Presents a continuous line between two descriptors and the respondents mark a point on the line. Therefore, it is clear that this scale allows continuous scoring but it has to be noted that interpretation can be subjective, and comparisons across individuals may be difficult. An advantage of this type of scale is that it is shghly sensitive, so it useful for detecting subtle changes within individuals over time; moreover they may reduce reduce bias from recalling previous discrete responses.</span>
<span id="cb17-322"><a href="#cb17-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-323"><a href="#cb17-323" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - **Numerical Response Formats**: Research suggests linear arrays of numbers may align with fundamental neural processing of quantity, potentially giving formats like Likert scales special merit.  --&gt;</span></span>
<span id="cb17-324"><a href="#cb17-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-325"><a href="#cb17-325" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Binary Options**: Offer two choices (e.g., agree/disagree, yes/no, check if applies). This type of option is simple for respondents but yields to minimal variability per item, therefore more items are required for obtaining an adequate scale variance. However, the ease of response may allow for more items to be administered.</span>
<span id="cb17-326"><a href="#cb17-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-327"><a href="#cb17-327" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Item Time Frames: Consider the temporal aspect. Some scales imply an enduring trait (e.g., locus of control), while others assess transient states (e.g., depression &quot;in the past week&quot;) or have separate state/trait forms (e.g., anxiety). The choice should be active and theory-driven, matching the nature of the phenomenon and the scale&#39;s intended use.  --&gt;</span></span>
<span id="cb17-328"><a href="#cb17-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-329"><a href="#cb17-329" aria-hidden="true" tabindex="-1"></a><span class="fu">### Experts&#39; review {.unnumbered .toc-ignore}</span></span>
<span id="cb17-330"><a href="#cb17-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-331"><a href="#cb17-331" aria-hidden="true" tabindex="-1"></a>Expert review plays a key role in strengthening content validity during scale development.</span>
<span id="cb17-332"><a href="#cb17-332" aria-hidden="true" tabindex="-1"></a>By drawing on their subject-matter expertise, reviewers help ensure that the items meaningfully represent the construct.</span>
<span id="cb17-333"><a href="#cb17-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-334"><a href="#cb17-334" aria-hidden="true" tabindex="-1"></a>Experts are typically asked to assess how well each item reflects the construct definition, providing feedback that can confirm or refine the conceptual framework.</span>
<span id="cb17-335"><a href="#cb17-335" aria-hidden="true" tabindex="-1"></a>They also evaluate the clarity and precision of item wording, offering suggestions to reduce ambiguity.</span>
<span id="cb17-336"><a href="#cb17-336" aria-hidden="true" tabindex="-1"></a>In addition, experts may highlight important aspects of the construct that have been overlooked.</span>
<span id="cb17-337"><a href="#cb17-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-338"><a href="#cb17-338" aria-hidden="true" tabindex="-1"></a>However, it&#39;s important to note that content experts may not be familiar with psychometric principles.</span>
<span id="cb17-339"><a href="#cb17-339" aria-hidden="true" tabindex="-1"></a>For instance, they might recommend eliminating seemingly redundant items, not realizing that some redundancy is intentional and necessary for reliability.</span>
<span id="cb17-340"><a href="#cb17-340" aria-hidden="true" tabindex="-1"></a>While expert input is highly valuable, final decisions should rest with the scale developer, who must balance expert judgment with methodological rigor.</span>
<span id="cb17-341"><a href="#cb17-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-342"><a href="#cb17-342" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">###</span><span class="co"> Step 5: Include Validation Items {.unnumbered .toc-ignore} --&gt;</span></span>
<span id="cb17-343"><a href="#cb17-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-344"><a href="#cb17-344" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Rationale: Including additional items during development can aid later validation efforts. --&gt;</span></span>
<span id="cb17-345"><a href="#cb17-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-346"><a href="#cb17-346" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Types of Items: --&gt;</span></span>
<span id="cb17-347"><a href="#cb17-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-348"><a href="#cb17-348" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Detecting Problems: Items to assess response biases like social desirability. Items correlating highly with social desirability may need exclusion. Standard scales (e.g., Strahan &amp; Gerbasi; MMPI bias scales) can be included. --&gt;</span></span>
<span id="cb17-349"><a href="#cb17-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-350"><a href="#cb17-350" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Construct Validity: Measures of theoretically related (or unrelated) constructs can be included to examine convergent and discriminant validity early on. --&gt;</span></span>
<span id="cb17-351"><a href="#cb17-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-352"><a href="#cb17-352" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">###</span><span class="co"> Step 6: Administer Items to a Development Sample {.unnumbered .toc-ignore}  --&gt;</span></span>
<span id="cb17-353"><a href="#cb17-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-354"><a href="#cb17-354" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Sample Size: Needs to be large enough to minimize subject variance as a concern and ensure stable item covariation patterns. Nunnally suggests 300, but smaller samples are sometimes used, depending on the number of items/scales. Risks of small samples include unstable results (e.g., inflated alpha estimates) and poor representation of the target population. --&gt;</span></span>
<span id="cb17-355"><a href="#cb17-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-356"><a href="#cb17-356" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Sample Representativeness: The sample should resemble the intended population. Non-representativeness can be quantitative (different mean level or range of the attribute) or qualitative (different relationships among items/constructs). Quantitative differences may be less problematic for assessing internal consistency. Qualitative differences, where items have different meanings or underlying structures in the sample versus the population (e.g., due to language/cultural differences), are more serious and can undermine the development effort.  --&gt;</span></span>
<span id="cb17-357"><a href="#cb17-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-358"><a href="#cb17-358" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">###</span><span class="co"> Step 7: Evaluate the Items {.unnumbered .toc-ignore} --&gt;</span></span>
<span id="cb17-359"><a href="#cb17-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-360"><a href="#cb17-360" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Goal: Identify the best-performing items from the pool to form the final scale, assessing their relationship with the latent variable&#39;s true score.  --&gt;</span></span>
<span id="cb17-361"><a href="#cb17-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-362"><a href="#cb17-362" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Key Qualities &amp; Analyses: --&gt;</span></span>
<span id="cb17-363"><a href="#cb17-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-364"><a href="#cb17-364" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- High Intercorrelations: Items should correlate highly with each other, indicating they share a common latent variable and have higher individual reliability. Inspect the correlation matrix.  --&gt;</span></span>
<span id="cb17-365"><a href="#cb17-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-366"><a href="#cb17-366" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Reverse Scoring: Address negatively correlated items, potentially by reverse scoring them if they reflect the opposite pole of the construct. Reverse scoring can be done during administration (potentially confusing), data coding (tedious/error-prone), or electronically (easiest) using formulas like NEW = (k + 1) - OLD. If reverse scoring doesn&#39;t resolve inconsistent correlations, the item likely doesn&#39;t belong.  --&gt;</span></span>
<span id="cb17-367"><a href="#cb17-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-368"><a href="#cb17-368" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Item-Scale Correlations: Each item should correlate substantially with the sum of the other items (corrected item-scale correlation is preferred over uncorrected to avoid inflation). --&gt;</span></span>
<span id="cb17-369"><a href="#cb17-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-370"><a href="#cb17-370" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Item Variances: Items should have relatively high variance, indicating they discriminate between individuals. Very low variance suggests poor discrimination. Markedly different variances might signal inconsistent error or violation of model assumptions (like essential tau equivalence). --&gt;</span></span>
<span id="cb17-371"><a href="#cb17-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-372"><a href="#cb17-372" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Item Means: Means should be close to the center of the possible score range. Extreme means often lead to low variance and poor correlations. Check means/variances after initial selection based on correlations. --&gt;</span></span>
<span id="cb17-373"><a href="#cb17-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-374"><a href="#cb17-374" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Dimensionality: Use factor analysis to determine if the items form a single, unidimensional set, which is an assumption for coefficient alpha. --&gt;</span></span>
<span id="cb17-375"><a href="#cb17-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-376"><a href="#cb17-376" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Reliability (Alpha): Calculate coefficient alpha (or alternatives like omega if assumptions aren&#39;t met) to assess internal consistency – the proportion of variance due to the true score. Can be computed using statistical software (SPSS RELIABILITY, SAS PROC CORR ALPHA) or by hand using variance-based formulas (preferred) or correlation-based Spearman-Brown. Alpha ranges from 0 to 1 (negative alpha indicates problems like negative inter-item correlations). Common (subjective) benchmarks for research scales: &lt;.60 unacceptable, .60-.65 undesirable, .65-.70 minimal, .70-.80 respectable, .80-.90 very good; &gt;.90 consider shortening. Aim higher during development as alpha might drop in new samples. Scales for individual assessment (clinical, diagnostic) require much higher reliability (e.g., mid-.90s). Single-item measures cannot use alpha; test-retest is an imperfect alternative. Omega is an option if assumptions for alpha are unmet.  --&gt;</span></span>
<span id="cb17-377"><a href="#cb17-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-378"><a href="#cb17-378" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">###</span><span class="co"> Step 8: Optimize Scale Length  {.unnumbered .toc-ignore} --&gt;</span></span>
<span id="cb17-379"><a href="#cb17-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-380"><a href="#cb17-380" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Trade-off: Shorter scales reduce respondent burden, while longer scales are generally more reliable. The goal is an optimal balance. Brevity is pointless if reliability is too low. Consider shortening only when reliability is high.  --&gt;</span></span>
<span id="cb17-381"><a href="#cb17-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-382"><a href="#cb17-382" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Dropping Items: Removing weak items (low correlation with others) can increase alpha, especially in shorter scales where each item has more impact. If an item&#39;s correlation is only slightly below average, keeping it usually benefits alpha more than removing it hurts.  --&gt;</span></span>
<span id="cb17-383"><a href="#cb17-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-384"><a href="#cb17-384" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Process: Identify items for potential removal based on their impact on alpha (using software output), low item-scale correlations, or low squared multiple correlations (communality).  --&gt;</span></span>
<span id="cb17-385"><a href="#cb17-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-386"><a href="#cb17-386" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Alpha Precision: Alpha itself is an estimate; its stability (reliability) increases with the number of items. Longer scales yield more consistent alpha values across administrations. Build in a safety margin, as alpha may decrease in new samples. --&gt;</span></span>
<span id="cb17-387"><a href="#cb17-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-388"><a href="#cb17-388" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Split Samples: If the development sample is large enough, split it (e.g., in half or unevenly). Develop/optimize the scale on one subsample and cross-validate (check stability of alpha and other stats) on the second subsample, whose data did not influence item selection. This helps assess if initial results were inflated by chance, though subsamples are still more similar than entirely separate samples.  --&gt;</span></span>
<span id="cb17-389"><a href="#cb17-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-390"><a href="#cb17-390" aria-hidden="true" tabindex="-1"></a><span class="fu">### Subsequent Steps in Scales Development {.unnumbered .toc-ignore}</span></span>
<span id="cb17-391"><a href="#cb17-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-392"><a href="#cb17-392" aria-hidden="true" tabindex="-1"></a>Following the initial design of the questionnaire, including the selection and construction of appropriate scales, the next crucial phase involves preparing for validation and data collection.</span>
<span id="cb17-393"><a href="#cb17-393" aria-hidden="true" tabindex="-1"></a>This includes strategically incorporating additional items aimed at facilitating later validation efforts, such as those designed to detect response biases or to assess the questionnaire&#39;s construct validity by measuring theoretically related concepts.</span>
<span id="cb17-394"><a href="#cb17-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-395"><a href="#cb17-395" aria-hidden="true" tabindex="-1"></a>Subsequently, the questionnaire is administered to a development sample.</span>
<span id="cb17-396"><a href="#cb17-396" aria-hidden="true" tabindex="-1"></a>It&#39;s essential that this sample is sufficiently large and representative of the target population to ensure stable results and minimize concerns about subject variance.</span>
<span id="cb17-397"><a href="#cb17-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-398"><a href="#cb17-398" aria-hidden="true" tabindex="-1"></a>Once the data is collected, a thorough evaluation of the individual items is undertaken.</span>
<span id="cb17-399"><a href="#cb17-399" aria-hidden="true" tabindex="-1"></a>This involves examining their intercorrelations to ensure they are measuring a common underlying construct, addressing any negatively correlated items through techniques like reverse scoring, and assessing the correlation of each item with the overall scale.</span>
<span id="cb17-400"><a href="#cb17-400" aria-hidden="true" tabindex="-1"></a>Furthermore, the variance and means of the items are analyzed to ensure they discriminate effectively among respondents.</span>
<span id="cb17-401"><a href="#cb17-401" aria-hidden="true" tabindex="-1"></a>Factor analysis is employed to confirm the dimensionality of the scale, and reliability, often measured by Cronbach&#39;s alpha, is calculated to assess the internal consistency of the items.</span>
<span id="cb17-402"><a href="#cb17-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-403"><a href="#cb17-403" aria-hidden="true" tabindex="-1"></a>Finally, the length of the scale is optimized.</span>
<span id="cb17-404"><a href="#cb17-404" aria-hidden="true" tabindex="-1"></a>This involves balancing the need for brevity to reduce respondent burden with the desire for higher reliability, which is generally associated with longer scales.</span>
<span id="cb17-405"><a href="#cb17-405" aria-hidden="true" tabindex="-1"></a>Weak items that negatively impact reliability are considered for removal, and techniques like splitting the development sample for cross-validation can be used to ensure the stability of the optimized scale in new samples.</span>
<span id="cb17-406"><a href="#cb17-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-407"><a href="#cb17-407" aria-hidden="true" tabindex="-1"></a><span class="fu">## Visualizing Ordinal Data</span></span>
<span id="cb17-408"><a href="#cb17-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-409"><a href="#cb17-409" aria-hidden="true" tabindex="-1"></a>The most important principle in visualizing ordinal data is to always represent ordinal categories in their natural, ordered sequence in any visual representation.</span>
<span id="cb17-410"><a href="#cb17-410" aria-hidden="true" tabindex="-1"></a>In bar charts, bars should be arranged along the axis based on the logical order of the ordinal scale (e.g., from &quot;Low&quot; to &quot;High&quot;).</span>
<span id="cb17-411"><a href="#cb17-411" aria-hidden="true" tabindex="-1"></a>For stacked and divergent bar charts, the segments representing ordinal categories should also follow this intrinsic order within each bar.</span>
<span id="cb17-412"><a href="#cb17-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-413"><a href="#cb17-413" aria-hidden="true" tabindex="-1"></a><span class="in">```{r warning=FALSE}</span></span>
<span id="cb17-414"><a href="#cb17-414" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb17-415"><a href="#cb17-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-416"><a href="#cb17-416" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample data</span></span>
<span id="cb17-417"><a href="#cb17-417" aria-hidden="true" tabindex="-1"></a>satisfaction <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb17-418"><a href="#cb17-418" aria-hidden="true" tabindex="-1"></a>  <span class="at">level =</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="st">&quot;Very Dissatisfied&quot;</span>, <span class="st">&quot;Dissatisfied&quot;</span>, <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Satisfied&quot;</span>, <span class="st">&quot;Very Satisfied&quot;</span>),</span>
<span id="cb17-419"><a href="#cb17-419" aria-hidden="true" tabindex="-1"></a>                 <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;Very Dissatisfied&quot;</span>, <span class="st">&quot;Dissatisfied&quot;</span>, <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Satisfied&quot;</span>, <span class="st">&quot;Very Satisfied&quot;</span>)),</span>
<span id="cb17-420"><a href="#cb17-420" aria-hidden="true" tabindex="-1"></a>  <span class="at">count =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">23</span>, <span class="dv">30</span>, <span class="dv">45</span>, <span class="dv">27</span>)</span>
<span id="cb17-421"><a href="#cb17-421" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-422"><a href="#cb17-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-423"><a href="#cb17-423" aria-hidden="true" tabindex="-1"></a><span class="co"># Create bar chart with ordered categories</span></span>
<span id="cb17-424"><a href="#cb17-424" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(satisfaction, <span class="fu">aes</span>(<span class="at">x =</span> level, <span class="at">y =</span> count)) <span class="sc">+</span></span>
<span id="cb17-425"><a href="#cb17-425" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;steelblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-426"><a href="#cb17-426" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb17-427"><a href="#cb17-427" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Customer Satisfaction Levels&quot;</span>,</span>
<span id="cb17-428"><a href="#cb17-428" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Satisfaction Level&quot;</span>,</span>
<span id="cb17-429"><a href="#cb17-429" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Number of Responses&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-430"><a href="#cb17-430" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>))</span>
<span id="cb17-431"><a href="#cb17-431" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-432"><a href="#cb17-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-433"><a href="#cb17-433" aria-hidden="true" tabindex="-1"></a>The choice of chart should align with the research question and the specific aspect of ordinal data being investigated.</span>
<span id="cb17-434"><a href="#cb17-434" aria-hidden="true" tabindex="-1"></a>Not all chart types are equally effective for representing ordered categorical data.</span>
<span id="cb17-435"><a href="#cb17-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-436"><a href="#cb17-436" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bar Charts {.unnumbered .toc-ignore}</span></span>
<span id="cb17-437"><a href="#cb17-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-438"><a href="#cb17-438" aria-hidden="true" tabindex="-1"></a>Represent each ordinal category with a bar, whose height or length corresponds to the frequency or count of that category.</span>
<span id="cb17-439"><a href="#cb17-439" aria-hidden="true" tabindex="-1"></a>Fundamentally, the bars must be arranged in the logical order of the ordinal variable (e.g., from lowest to highest category).</span>
<span id="cb17-440"><a href="#cb17-440" aria-hidden="true" tabindex="-1"></a>They can be vertical or horizontal; horizontal orientation is often preferred for readability of long category labels.</span>
<span id="cb17-441"><a href="#cb17-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-442"><a href="#cb17-442" aria-hidden="true" tabindex="-1"></a>Bar charts provide a clear and easily understandable visualization of the distribution of a single ordinal variable, highlighting the frequency of each ordered category.</span>
<span id="cb17-443"><a href="#cb17-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-444"><a href="#cb17-444" aria-hidden="true" tabindex="-1"></a><span class="in">```{r warning=FALSE, message=FALSE}</span></span>
<span id="cb17-445"><a href="#cb17-445" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb17-446"><a href="#cb17-446" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb17-447"><a href="#cb17-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-448"><a href="#cb17-448" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample Likert scale data for one survey question</span></span>
<span id="cb17-449"><a href="#cb17-449" aria-hidden="true" tabindex="-1"></a>likert_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb17-450"><a href="#cb17-450" aria-hidden="true" tabindex="-1"></a>  <span class="at">response_category =</span> <span class="fu">factor</span>(</span>
<span id="cb17-451"><a href="#cb17-451" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="st">&quot;Strongly Disagree&quot;</span>, <span class="st">&quot;Disagree&quot;</span>, </span>
<span id="cb17-452"><a href="#cb17-452" aria-hidden="true" tabindex="-1"></a>      <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Agree&quot;</span>, <span class="st">&quot;Strongly Agree&quot;</span>),</span>
<span id="cb17-453"><a href="#cb17-453" aria-hidden="true" tabindex="-1"></a>    <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;Strongly Disagree&quot;</span>, <span class="st">&quot;Disagree&quot;</span>, </span>
<span id="cb17-454"><a href="#cb17-454" aria-hidden="true" tabindex="-1"></a>               <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Agree&quot;</span>, <span class="st">&quot;Strongly Agree&quot;</span>)</span>
<span id="cb17-455"><a href="#cb17-455" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb17-456"><a href="#cb17-456" aria-hidden="true" tabindex="-1"></a>  <span class="at">frequency =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">27</span>, <span class="dv">43</span>, <span class="dv">85</span>, <span class="dv">30</span>)</span>
<span id="cb17-457"><a href="#cb17-457" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-458"><a href="#cb17-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-459"><a href="#cb17-459" aria-hidden="true" tabindex="-1"></a><span class="co"># Create horizontal bar chart with properly ordered categories</span></span>
<span id="cb17-460"><a href="#cb17-460" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(likert_data, <span class="fu">aes</span>(<span class="at">x =</span> response_category,</span>
<span id="cb17-461"><a href="#cb17-461" aria-hidden="true" tabindex="-1"></a>                        <span class="at">y =</span> frequency, </span>
<span id="cb17-462"><a href="#cb17-462" aria-hidden="true" tabindex="-1"></a>                        <span class="at">fill =</span> response_category)) <span class="sc">+</span></span>
<span id="cb17-463"><a href="#cb17-463" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-464"><a href="#cb17-464" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(</span>
<span id="cb17-465"><a href="#cb17-465" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Strongly Disagree&quot;</span> <span class="ot">=</span> <span class="st">&quot;#d7191c&quot;</span>,</span>
<span id="cb17-466"><a href="#cb17-466" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Disagree&quot;</span> <span class="ot">=</span> <span class="st">&quot;#fdae61&quot;</span>,</span>
<span id="cb17-467"><a href="#cb17-467" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Neutral&quot;</span> <span class="ot">=</span> <span class="st">&quot;#ffffbf&quot;</span>,</span>
<span id="cb17-468"><a href="#cb17-468" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Agree&quot;</span> <span class="ot">=</span> <span class="st">&quot;#abd9e9&quot;</span>,</span>
<span id="cb17-469"><a href="#cb17-469" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Strongly Agree&quot;</span> <span class="ot">=</span> <span class="st">&quot;#2c7bb6&quot;</span></span>
<span id="cb17-470"><a href="#cb17-470" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">+</span></span>
<span id="cb17-471"><a href="#cb17-471" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span>  <span class="co"># Horizontal orientation for better label readability</span></span>
<span id="cb17-472"><a href="#cb17-472" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb17-473"><a href="#cb17-473" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb17-474"><a href="#cb17-474" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Responses to: &#39;The new software </span></span>
<span id="cb17-475"><a href="#cb17-475" aria-hidden="true" tabindex="-1"></a><span class="st">    interface is intuitive to use&#39;&quot;</span>,</span>
<span id="cb17-476"><a href="#cb17-476" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">&quot;Distribution of 200 employee responses&quot;</span>,</span>
<span id="cb17-477"><a href="#cb17-477" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb17-478"><a href="#cb17-478" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Number of Responses&quot;</span></span>
<span id="cb17-479"><a href="#cb17-479" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb17-480"><a href="#cb17-480" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb17-481"><a href="#cb17-481" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>,  <span class="co"># Remove legend as colors are self-explanatory</span></span>
<span id="cb17-482"><a href="#cb17-482" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>),</span>
<span id="cb17-483"><a href="#cb17-483" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">&quot;bold&quot;</span>),</span>
<span id="cb17-484"><a href="#cb17-484" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.major.y =</span> <span class="fu">element_blank</span>()  <span class="co"># Remove horizontal grid lines</span></span>
<span id="cb17-485"><a href="#cb17-485" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb17-486"><a href="#cb17-486" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-487"><a href="#cb17-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-488"><a href="#cb17-488" aria-hidden="true" tabindex="-1"></a><span class="fu">### Stacked Bar Charts {.unnumbered .toc-ignore}</span></span>
<span id="cb17-489"><a href="#cb17-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-490"><a href="#cb17-490" aria-hidden="true" tabindex="-1"></a>Show multiple ordinal categories within a single bar, with each segment representing a different category stacked on top of another.</span>
<span id="cb17-491"><a href="#cb17-491" aria-hidden="true" tabindex="-1"></a>They are useful for comparing the distribution of ordinal data across different groups or conditions.</span>
<span id="cb17-492"><a href="#cb17-492" aria-hidden="true" tabindex="-1"></a>They can be displayed as counts or as percentages (where each bar totals 100%).</span>
<span id="cb17-493"><a href="#cb17-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-494"><a href="#cb17-494" aria-hidden="true" tabindex="-1"></a>Stacked bar charts allow comparison of both total amounts within each group and the proportion of each ordinal category within those groups, providing insights into how distributions differ between categories.</span>
<span id="cb17-495"><a href="#cb17-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-496"><a href="#cb17-496" aria-hidden="true" tabindex="-1"></a><span class="in">```{r warning=FALSE}</span></span>
<span id="cb17-497"><a href="#cb17-497" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb17-498"><a href="#cb17-498" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb17-499"><a href="#cb17-499" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb17-500"><a href="#cb17-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-501"><a href="#cb17-501" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample semantic differential scale data</span></span>
<span id="cb17-502"><a href="#cb17-502" aria-hidden="true" tabindex="-1"></a><span class="co"># This represents evaluations of three different smartphones on five dimensions</span></span>
<span id="cb17-503"><a href="#cb17-503" aria-hidden="true" tabindex="-1"></a>semantic_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb17-504"><a href="#cb17-504" aria-hidden="true" tabindex="-1"></a>  <span class="at">product =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Smartphone A&quot;</span>, <span class="st">&quot;Smartphone B&quot;</span>, <span class="st">&quot;Smartphone C&quot;</span>), <span class="at">each =</span> <span class="dv">5</span>),</span>
<span id="cb17-505"><a href="#cb17-505" aria-hidden="true" tabindex="-1"></a>  <span class="at">dimension =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Ineffective - Effective&quot;</span>,</span>
<span id="cb17-506"><a href="#cb17-506" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;Complicated - Simple&quot;</span>,</span>
<span id="cb17-507"><a href="#cb17-507" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;Unreliable - Reliable&quot;</span>,</span>
<span id="cb17-508"><a href="#cb17-508" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;Outdated - Innovative&quot;</span>,</span>
<span id="cb17-509"><a href="#cb17-509" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;Unattractive - Attractive&quot;</span>), <span class="dv">3</span>),</span>
<span id="cb17-510"><a href="#cb17-510" aria-hidden="true" tabindex="-1"></a>  <span class="at">rating_1 =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">8</span>, <span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">7</span>,       <span class="co"># Smartphone A</span></span>
<span id="cb17-511"><a href="#cb17-511" aria-hidden="true" tabindex="-1"></a>               <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>,        <span class="co"># Smartphone B</span></span>
<span id="cb17-512"><a href="#cb17-512" aria-hidden="true" tabindex="-1"></a>               <span class="dv">8</span>, <span class="dv">6</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">3</span>),       <span class="co"># Smartphone C</span></span>
<span id="cb17-513"><a href="#cb17-513" aria-hidden="true" tabindex="-1"></a>  <span class="at">rating_2 =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">15</span>, <span class="dv">8</span>, <span class="dv">13</span>,    <span class="co"># Smartphone A</span></span>
<span id="cb17-514"><a href="#cb17-514" aria-hidden="true" tabindex="-1"></a>               <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">11</span>,      <span class="co"># Smartphone B</span></span>
<span id="cb17-515"><a href="#cb17-515" aria-hidden="true" tabindex="-1"></a>               <span class="dv">12</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">7</span>),     <span class="co"># Smartphone C</span></span>
<span id="cb17-516"><a href="#cb17-516" aria-hidden="true" tabindex="-1"></a>  <span class="at">rating_3 =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">20</span>, <span class="dv">22</span>, <span class="dv">18</span>, <span class="dv">20</span>,   <span class="co"># Smartphone A</span></span>
<span id="cb17-517"><a href="#cb17-517" aria-hidden="true" tabindex="-1"></a>               <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">18</span>, <span class="dv">13</span>, <span class="dv">15</span>,   <span class="co"># Smartphone B</span></span>
<span id="cb17-518"><a href="#cb17-518" aria-hidden="true" tabindex="-1"></a>               <span class="dv">20</span>, <span class="dv">22</span>, <span class="dv">18</span>, <span class="dv">15</span>, <span class="dv">20</span>),  <span class="co"># Smartphone C</span></span>
<span id="cb17-519"><a href="#cb17-519" aria-hidden="true" tabindex="-1"></a>  <span class="at">rating_4 =</span> <span class="fu">c</span>(<span class="dv">35</span>, <span class="dv">30</span>, <span class="dv">32</span>, <span class="dv">40</span>, <span class="dv">35</span>,   <span class="co"># Smartphone A</span></span>
<span id="cb17-520"><a href="#cb17-520" aria-hidden="true" tabindex="-1"></a>               <span class="dv">45</span>, <span class="dv">35</span>, <span class="dv">40</span>, <span class="dv">38</span>, <span class="dv">35</span>,   <span class="co"># Smartphone B</span></span>
<span id="cb17-521"><a href="#cb17-521" aria-hidden="true" tabindex="-1"></a>               <span class="dv">30</span>, <span class="dv">35</span>, <span class="dv">38</span>, <span class="dv">40</span>, <span class="dv">35</span>),  <span class="co"># Smartphone C</span></span>
<span id="cb17-522"><a href="#cb17-522" aria-hidden="true" tabindex="-1"></a>  <span class="at">rating_5 =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">28</span>, <span class="dv">24</span>, <span class="dv">25</span>,   <span class="co"># Smartphone A</span></span>
<span id="cb17-523"><a href="#cb17-523" aria-hidden="true" tabindex="-1"></a>               <span class="dv">30</span>, <span class="dv">30</span>, <span class="dv">33</span>, <span class="dv">37</span>, <span class="dv">35</span>,   <span class="co"># Smartphone B</span></span>
<span id="cb17-524"><a href="#cb17-524" aria-hidden="true" tabindex="-1"></a>               <span class="dv">30</span>, <span class="dv">29</span>, <span class="dv">31</span>, <span class="dv">30</span>, <span class="dv">35</span>)   <span class="co"># Smartphone C</span></span>
<span id="cb17-525"><a href="#cb17-525" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-526"><a href="#cb17-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-527"><a href="#cb17-527" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape data for ggplot</span></span>
<span id="cb17-528"><a href="#cb17-528" aria-hidden="true" tabindex="-1"></a>semantic_long <span class="ot">&lt;-</span> semantic_data <span class="sc">%&gt;%</span></span>
<span id="cb17-529"><a href="#cb17-529" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">starts_with</span>(<span class="st">&quot;rating_&quot;</span>),</span>
<span id="cb17-530"><a href="#cb17-530" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">&quot;rating_level&quot;</span>,</span>
<span id="cb17-531"><a href="#cb17-531" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">&quot;count&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb17-532"><a href="#cb17-532" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb17-533"><a href="#cb17-533" aria-hidden="true" tabindex="-1"></a>    <span class="at">rating_number =</span> <span class="fu">as.numeric</span>(<span class="fu">substr</span>(rating_level, <span class="dv">8</span>, <span class="dv">8</span>)),</span>
<span id="cb17-534"><a href="#cb17-534" aria-hidden="true" tabindex="-1"></a>    <span class="at">rating_label =</span> <span class="fu">factor</span>(</span>
<span id="cb17-535"><a href="#cb17-535" aria-hidden="true" tabindex="-1"></a>      <span class="fu">case_when</span>(</span>
<span id="cb17-536"><a href="#cb17-536" aria-hidden="true" tabindex="-1"></a>        rating_number <span class="sc">==</span> <span class="dv">1</span> <span class="sc">~</span> <span class="st">&quot;1 (Negative)&quot;</span>,</span>
<span id="cb17-537"><a href="#cb17-537" aria-hidden="true" tabindex="-1"></a>        rating_number <span class="sc">==</span> <span class="dv">2</span> <span class="sc">~</span> <span class="st">&quot;2&quot;</span>,</span>
<span id="cb17-538"><a href="#cb17-538" aria-hidden="true" tabindex="-1"></a>        rating_number <span class="sc">==</span> <span class="dv">3</span> <span class="sc">~</span> <span class="st">&quot;3 (Neutral)&quot;</span>,</span>
<span id="cb17-539"><a href="#cb17-539" aria-hidden="true" tabindex="-1"></a>        rating_number <span class="sc">==</span> <span class="dv">4</span> <span class="sc">~</span> <span class="st">&quot;4&quot;</span>,</span>
<span id="cb17-540"><a href="#cb17-540" aria-hidden="true" tabindex="-1"></a>        rating_number <span class="sc">==</span> <span class="dv">5</span> <span class="sc">~</span> <span class="st">&quot;5 (Positive)&quot;</span></span>
<span id="cb17-541"><a href="#cb17-541" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb17-542"><a href="#cb17-542" aria-hidden="true" tabindex="-1"></a>      <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;1 (Negative)&quot;</span>, <span class="st">&quot;2&quot;</span>, <span class="st">&quot;3 (Neutral)&quot;</span>, <span class="st">&quot;4&quot;</span>, <span class="st">&quot;5 (Positive)&quot;</span>)</span>
<span id="cb17-543"><a href="#cb17-543" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-544"><a href="#cb17-544" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb17-545"><a href="#cb17-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-546"><a href="#cb17-546" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate percentages for each product-dimension combination</span></span>
<span id="cb17-547"><a href="#cb17-547" aria-hidden="true" tabindex="-1"></a>semantic_pct <span class="ot">&lt;-</span> semantic_long <span class="sc">%&gt;%</span></span>
<span id="cb17-548"><a href="#cb17-548" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(product, dimension) <span class="sc">%&gt;%</span></span>
<span id="cb17-549"><a href="#cb17-549" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb17-550"><a href="#cb17-550" aria-hidden="true" tabindex="-1"></a>    <span class="at">percentage =</span> count <span class="sc">/</span> <span class="fu">sum</span>(count) <span class="sc">*</span> <span class="dv">100</span>,</span>
<span id="cb17-551"><a href="#cb17-551" aria-hidden="true" tabindex="-1"></a>    <span class="at">total =</span> <span class="fu">sum</span>(count)</span>
<span id="cb17-552"><a href="#cb17-552" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb17-553"><a href="#cb17-553" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>()</span>
<span id="cb17-554"><a href="#cb17-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-555"><a href="#cb17-555" aria-hidden="true" tabindex="-1"></a><span class="co"># Create stacked bar chart</span></span>
<span id="cb17-556"><a href="#cb17-556" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(semantic_pct, <span class="fu">aes</span>(<span class="at">x =</span> dimension, <span class="at">y =</span> percentage, <span class="at">fill =</span> rating_label)) <span class="sc">+</span></span>
<span id="cb17-557"><a href="#cb17-557" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-558"><a href="#cb17-558" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> product) <span class="sc">+</span></span>
<span id="cb17-559"><a href="#cb17-559" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;1 (Negative)&quot;</span> <span class="ot">=</span> <span class="st">&quot;#d7191c&quot;</span>,</span>
<span id="cb17-560"><a href="#cb17-560" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;2&quot;</span> <span class="ot">=</span> <span class="st">&quot;#fdae61&quot;</span>,</span>
<span id="cb17-561"><a href="#cb17-561" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;3 (Neutral)&quot;</span> <span class="ot">=</span> <span class="st">&quot;#ffffbf&quot;</span>,</span>
<span id="cb17-562"><a href="#cb17-562" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;4&quot;</span> <span class="ot">=</span> <span class="st">&quot;#a6d96a&quot;</span>,</span>
<span id="cb17-563"><a href="#cb17-563" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;5 (Positive)&quot;</span> <span class="ot">=</span> <span class="st">&quot;#1a9641&quot;</span>)) <span class="sc">+</span></span>
<span id="cb17-564"><a href="#cb17-564" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb17-565"><a href="#cb17-565" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb17-566"><a href="#cb17-566" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Smartphone Evaluations using Semantic Differential Scales&quot;</span>,</span>
<span id="cb17-567"><a href="#cb17-567" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">&quot;Distribution of ratings across five dimensions&quot;</span>,</span>
<span id="cb17-568"><a href="#cb17-568" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb17-569"><a href="#cb17-569" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Percentage of Responses&quot;</span>,</span>
<span id="cb17-570"><a href="#cb17-570" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;Rating&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-571"><a href="#cb17-571" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb17-572"><a href="#cb17-572" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>,</span>
<span id="cb17-573"><a href="#cb17-573" aria-hidden="true" tabindex="-1"></a>    <span class="at">strip.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">color =</span> <span class="cn">NA</span>),</span>
<span id="cb17-574"><a href="#cb17-574" aria-hidden="true" tabindex="-1"></a>    <span class="at">strip.text =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">&quot;bold&quot;</span>)</span>
<span id="cb17-575"><a href="#cb17-575" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb17-576"><a href="#cb17-576" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-577"><a href="#cb17-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-578"><a href="#cb17-578" aria-hidden="true" tabindex="-1"></a>This visualization effectively reveals patterns such as which smartphone is perceived as more innovative, which has the most consistent ratings across dimensions, and where the greatest differences between products exist.</span>
<span id="cb17-579"><a href="#cb17-579" aria-hidden="true" tabindex="-1"></a>These insights would be difficult to discern from tables of raw data.</span>
<span id="cb17-580"><a href="#cb17-580" aria-hidden="true" tabindex="-1"></a>The stacked bar format is particularly effective for semantic differential scales because it shows the full distribution of responses, not just averages, allowing you to see whether opinions are polarized or consistent across respondents.</span>
<span id="cb17-581"><a href="#cb17-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-582"><a href="#cb17-582" aria-hidden="true" tabindex="-1"></a><span class="fu">### Divergent Stacked Bar Charts {.unnumbered .toc-ignore}</span></span>
<span id="cb17-583"><a href="#cb17-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-584"><a href="#cb17-584" aria-hidden="true" tabindex="-1"></a>Specifically designed to visualize ordinal data with a neutral central category or bipolar responses, such as Likert scales and semantic differentials.</span>
<span id="cb17-585"><a href="#cb17-585" aria-hidden="true" tabindex="-1"></a>Segments representing responses on one side of the neutral point extend in one direction, while segments representing responses on the other side extend in the opposite direction from a central baseline.</span>
<span id="cb17-586"><a href="#cb17-586" aria-hidden="true" tabindex="-1"></a>They effectively illustrate the balance between positive and negative responses and the distribution of opinions.</span>
<span id="cb17-587"><a href="#cb17-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-588"><a href="#cb17-588" aria-hidden="true" tabindex="-1"></a>Divergent stacked bar charts are the recommended visualization for Likert-type scales as they clearly show the proportion of responses in each category and the overall tendency of agreement or disagreement.</span>
<span id="cb17-589"><a href="#cb17-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-590"><a href="#cb17-590" aria-hidden="true" tabindex="-1"></a><span class="in">```{r warning=FALSE, message = F, error = F}</span></span>
<span id="cb17-591"><a href="#cb17-591" aria-hidden="true" tabindex="-1"></a><span class="co"># Install and load required package</span></span>
<span id="cb17-592"><a href="#cb17-592" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;HH&quot;)</span></span>
<span id="cb17-593"><a href="#cb17-593" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(HH)</span>
<span id="cb17-594"><a href="#cb17-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-595"><a href="#cb17-595" aria-hidden="true" tabindex="-1"></a><span class="co"># Frequency data for three items (rows) on a 5-point Likert scale</span></span>
<span id="cb17-596"><a href="#cb17-596" aria-hidden="true" tabindex="-1"></a>likert_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb17-597"><a href="#cb17-597" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Easy&quot;</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">40</span>, <span class="dv">20</span>),</span>
<span id="cb17-598"><a href="#cb17-598" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Helpful&quot;</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">18</span>, <span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">17</span>),</span>
<span id="cb17-599"><a href="#cb17-599" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Recommend&quot;</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">8</span>, <span class="dv">12</span>, <span class="dv">15</span>, <span class="dv">35</span>, <span class="dv">30</span>)</span>
<span id="cb17-600"><a href="#cb17-600" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-601"><a href="#cb17-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-602"><a href="#cb17-602" aria-hidden="true" tabindex="-1"></a><span class="co"># Set column names (Likert scale labels)</span></span>
<span id="cb17-603"><a href="#cb17-603" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(likert_data) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Strongly Disagree&quot;</span>, <span class="st">&quot;Disagree&quot;</span>, <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Agree&quot;</span>, <span class="st">&quot;Strongly Agree&quot;</span>)</span>
<span id="cb17-604"><a href="#cb17-604" aria-hidden="true" tabindex="-1"></a>likert_data <span class="ot">&lt;-</span> <span class="fu">t</span>(likert_data)  <span class="co"># Transpose: items as columns, scale points as rows</span></span>
<span id="cb17-605"><a href="#cb17-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-606"><a href="#cb17-606" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the Likert plot</span></span>
<span id="cb17-607"><a href="#cb17-607" aria-hidden="true" tabindex="-1"></a>likert_plot <span class="ot">&lt;-</span> <span class="fu">likert</span>(likert_data,</span>
<span id="cb17-608"><a href="#cb17-608" aria-hidden="true" tabindex="-1"></a>                      <span class="at">main =</span> <span class="st">&quot;Customer Feedback on Product Experience&quot;</span>,</span>
<span id="cb17-609"><a href="#cb17-609" aria-hidden="true" tabindex="-1"></a>                      <span class="at">xlab =</span> <span class="st">&quot;Percentage of Responses&quot;</span>,</span>
<span id="cb17-610"><a href="#cb17-610" aria-hidden="true" tabindex="-1"></a>                      <span class="at">ylab =</span> <span class="cn">NULL</span>,</span>
<span id="cb17-611"><a href="#cb17-611" aria-hidden="true" tabindex="-1"></a>                      <span class="at">positive.order =</span> <span class="cn">TRUE</span>,</span>
<span id="cb17-612"><a href="#cb17-612" aria-hidden="true" tabindex="-1"></a>                      <span class="at">reference =</span> <span class="dv">0</span>)</span>
<span id="cb17-613"><a href="#cb17-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-614"><a href="#cb17-614" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb17-615"><a href="#cb17-615" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(likert_plot)</span>
<span id="cb17-616"><a href="#cb17-616" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-617"><a href="#cb17-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-618"><a href="#cb17-618" aria-hidden="true" tabindex="-1"></a><span class="fu">### Other Possible Visualizations {.unnumbered .toc-ignore}</span></span>
<span id="cb17-619"><a href="#cb17-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-620"><a href="#cb17-620" aria-hidden="true" tabindex="-1"></a>Depending on the specific analytical objective, these alternative visualizations can provide valuable perspectives on ordinal data, particularly when exploring relationships between variables or tracking changes in rankings.</span>
<span id="cb17-621"><a href="#cb17-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-622"><a href="#cb17-622" aria-hidden="true" tabindex="-1"></a>**Mosaic plots** show the relationship between two or more categorical variables, including ordinal ones, using tiled rectangles whose area is proportional to the frequency of each combination of categories.</span>
<span id="cb17-623"><a href="#cb17-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-624"><a href="#cb17-624" aria-hidden="true" tabindex="-1"></a><span class="in">```{r warning=FALSE}</span></span>
<span id="cb17-625"><a href="#cb17-625" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;ggmosaic&quot;)</span></span>
<span id="cb17-626"><a href="#cb17-626" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb17-627"><a href="#cb17-627" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggmosaic)</span>
<span id="cb17-628"><a href="#cb17-628" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb17-629"><a href="#cb17-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-630"><a href="#cb17-630" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample data for education level (ordinal) </span></span>
<span id="cb17-631"><a href="#cb17-631" aria-hidden="true" tabindex="-1"></a><span class="co">#and job satisfaction (ordinal)</span></span>
<span id="cb17-632"><a href="#cb17-632" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb17-633"><a href="#cb17-633" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb17-634"><a href="#cb17-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-635"><a href="#cb17-635" aria-hidden="true" tabindex="-1"></a>education_levels <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;High School&quot;</span>, <span class="st">&quot;Associate&#39;s&quot;</span>, <span class="st">&quot;Bachelor&#39;s&quot;</span>,</span>
<span id="cb17-636"><a href="#cb17-636" aria-hidden="true" tabindex="-1"></a>                      <span class="st">&quot;Master&#39;s&quot;</span>, <span class="st">&quot;Doctorate&quot;</span>)</span>
<span id="cb17-637"><a href="#cb17-637" aria-hidden="true" tabindex="-1"></a>satisfaction_levels <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Very Dissatisfied&quot;</span>, <span class="st">&quot;Dissatisfied&quot;</span>,</span>
<span id="cb17-638"><a href="#cb17-638" aria-hidden="true" tabindex="-1"></a>                         <span class="st">&quot;Neutral&quot;</span>, <span class="st">&quot;Satisfied&quot;</span>, <span class="st">&quot;Very Satisfied&quot;</span>)</span>
<span id="cb17-639"><a href="#cb17-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-640"><a href="#cb17-640" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample data with a pattern </span></span>
<span id="cb17-641"><a href="#cb17-641" aria-hidden="true" tabindex="-1"></a><span class="co">#(higher education tends to correlate with higher satisfaction)</span></span>
<span id="cb17-642"><a href="#cb17-642" aria-hidden="true" tabindex="-1"></a>mosaic_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb17-643"><a href="#cb17-643" aria-hidden="true" tabindex="-1"></a>  <span class="at">education =</span> <span class="fu">factor</span>(<span class="fu">sample</span>(education_levels, n, <span class="at">replace =</span> <span class="cn">TRUE</span>,</span>
<span id="cb17-644"><a href="#cb17-644" aria-hidden="true" tabindex="-1"></a>                            <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.25</span>, <span class="fl">0.25</span>, <span class="fl">0.15</span>, <span class="fl">0.05</span>)),</span>
<span id="cb17-645"><a href="#cb17-645" aria-hidden="true" tabindex="-1"></a>                     <span class="at">levels =</span> education_levels),</span>
<span id="cb17-646"><a href="#cb17-646" aria-hidden="true" tabindex="-1"></a>  <span class="at">satisfaction =</span> <span class="fu">factor</span>(<span class="cn">NA</span>, <span class="at">levels =</span> satisfaction_levels)</span>
<span id="cb17-647"><a href="#cb17-647" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-648"><a href="#cb17-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-649"><a href="#cb17-649" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate satisfaction levels with </span></span>
<span id="cb17-650"><a href="#cb17-650" aria-hidden="true" tabindex="-1"></a><span class="co">#some correlation to education</span></span>
<span id="cb17-651"><a href="#cb17-651" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n) {</span>
<span id="cb17-652"><a href="#cb17-652" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Higher education levels tend to have higher satisfaction probabilities</span></span>
<span id="cb17-653"><a href="#cb17-653" aria-hidden="true" tabindex="-1"></a>  edu_level <span class="ot">&lt;-</span> <span class="fu">which</span>(education_levels <span class="sc">==</span> mosaic_data<span class="sc">$</span>education[i])</span>
<span id="cb17-654"><a href="#cb17-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-655"><a href="#cb17-655" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Adjust probabilities based on education level</span></span>
<span id="cb17-656"><a href="#cb17-656" aria-hidden="true" tabindex="-1"></a>  probs <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.25</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.1</span>)  <span class="co"># Base probabilities</span></span>
<span id="cb17-657"><a href="#cb17-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-658"><a href="#cb17-658" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Shift probabilities based on education level</span></span>
<span id="cb17-659"><a href="#cb17-659" aria-hidden="true" tabindex="-1"></a>  shift <span class="ot">&lt;-</span> (edu_level <span class="sc">-</span> <span class="dv">3</span>) <span class="sc">*</span> <span class="fl">0.05</span>  <span class="co"># Shift factor based on education</span></span>
<span id="cb17-660"><a href="#cb17-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-661"><a href="#cb17-661" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Adjust probabilities (higher education gets </span></span>
<span id="cb17-662"><a href="#cb17-662" aria-hidden="true" tabindex="-1"></a>  <span class="co">#more weight for higher satisfaction)</span></span>
<span id="cb17-663"><a href="#cb17-663" aria-hidden="true" tabindex="-1"></a>  adjusted_probs <span class="ot">&lt;-</span> probs <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.1</span>, <span class="sc">-</span><span class="fl">0.05</span>, <span class="dv">0</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>) <span class="sc">*</span> edu_level</span>
<span id="cb17-664"><a href="#cb17-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-665"><a href="#cb17-665" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Ensure probabilities are valid</span></span>
<span id="cb17-666"><a href="#cb17-666" aria-hidden="true" tabindex="-1"></a>  adjusted_probs <span class="ot">&lt;-</span> <span class="fu">pmax</span>(adjusted_probs, <span class="fl">0.01</span>)</span>
<span id="cb17-667"><a href="#cb17-667" aria-hidden="true" tabindex="-1"></a>  adjusted_probs <span class="ot">&lt;-</span> adjusted_probs <span class="sc">/</span> <span class="fu">sum</span>(adjusted_probs)</span>
<span id="cb17-668"><a href="#cb17-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-669"><a href="#cb17-669" aria-hidden="true" tabindex="-1"></a>  mosaic_data<span class="sc">$</span>satisfaction[i] <span class="ot">&lt;-</span> <span class="fu">sample</span>(satisfaction_levels, <span class="dv">1</span>, <span class="at">prob =</span> adjusted_probs)</span>
<span id="cb17-670"><a href="#cb17-670" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-671"><a href="#cb17-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-672"><a href="#cb17-672" aria-hidden="true" tabindex="-1"></a><span class="co"># Create mosaic plot</span></span>
<span id="cb17-673"><a href="#cb17-673" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mosaic_data) <span class="sc">+</span></span>
<span id="cb17-674"><a href="#cb17-674" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_mosaic</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">product</span>(education), </span>
<span id="cb17-675"><a href="#cb17-675" aria-hidden="true" tabindex="-1"></a>                  <span class="at">fill =</span> satisfaction)) <span class="sc">+</span></span>
<span id="cb17-676"><a href="#cb17-676" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_brewer</span>(<span class="at">palette =</span> <span class="st">&quot;RdYlGn&quot;</span>, <span class="at">direction =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb17-677"><a href="#cb17-677" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Relationship Between </span></span>
<span id="cb17-678"><a href="#cb17-678" aria-hidden="true" tabindex="-1"></a><span class="st">       Education Level and Job Satisfaction&quot;</span>,</span>
<span id="cb17-679"><a href="#cb17-679" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">&quot;Mosaic plot showing the </span></span>
<span id="cb17-680"><a href="#cb17-680" aria-hidden="true" tabindex="-1"></a><span class="st">       distribution of satisfaction within </span></span>
<span id="cb17-681"><a href="#cb17-681" aria-hidden="true" tabindex="-1"></a><span class="st">       each education level&quot;</span>,</span>
<span id="cb17-682"><a href="#cb17-682" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Education Level&quot;</span>,</span>
<span id="cb17-683"><a href="#cb17-683" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Job Satisfaction&quot;</span>,</span>
<span id="cb17-684"><a href="#cb17-684" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">&quot;Satisfaction Level&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-685"><a href="#cb17-685" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb17-686"><a href="#cb17-686" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>),</span>
<span id="cb17-687"><a href="#cb17-687" aria-hidden="true" tabindex="-1"></a>         <span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span>
<span id="cb17-688"><a href="#cb17-688" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-689"><a href="#cb17-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-690"><a href="#cb17-690" aria-hidden="true" tabindex="-1"></a>This mosaic plot visualizes the relationship between two ordinal variables: education level and job satisfaction.</span>
<span id="cb17-691"><a href="#cb17-691" aria-hidden="true" tabindex="-1"></a>The width of each column represents the proportion of respondents with that education level in the overall sample.</span>
<span id="cb17-692"><a href="#cb17-692" aria-hidden="true" tabindex="-1"></a>Within each education level column, the height of each colored section represents the proportion of respondents reporting that satisfaction level.</span>
<span id="cb17-693"><a href="#cb17-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-694"><a href="#cb17-694" aria-hidden="true" tabindex="-1"></a>**Line charts** (bump charts) visualize the change in rank of different items over time or between categories, emphasizing movement in relative positions.</span>
<span id="cb17-695"><a href="#cb17-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-696"><a href="#cb17-696" aria-hidden="true" tabindex="-1"></a><span class="in">```{r warning=FALSE}</span></span>
<span id="cb17-697"><a href="#cb17-697" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb17-698"><a href="#cb17-698" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb17-699"><a href="#cb17-699" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb17-700"><a href="#cb17-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-701"><a href="#cb17-701" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample data for product rankings over time</span></span>
<span id="cb17-702"><a href="#cb17-702" aria-hidden="true" tabindex="-1"></a>rankings <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb17-703"><a href="#cb17-703" aria-hidden="true" tabindex="-1"></a>  <span class="at">product =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Product A&quot;</span>, <span class="st">&quot;Product B&quot;</span>, </span>
<span id="cb17-704"><a href="#cb17-704" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Product C&quot;</span>, <span class="st">&quot;Product D&quot;</span>, <span class="st">&quot;Product E&quot;</span>), <span class="dv">4</span>),</span>
<span id="cb17-705"><a href="#cb17-705" aria-hidden="true" tabindex="-1"></a>  <span class="at">quarter =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Q1 2024&quot;</span>, <span class="st">&quot;Q2 2024&quot;</span>, </span>
<span id="cb17-706"><a href="#cb17-706" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Q3 2024&quot;</span>, <span class="st">&quot;Q4 2024&quot;</span>), <span class="at">each =</span> <span class="dv">5</span>),</span>
<span id="cb17-707"><a href="#cb17-707" aria-hidden="true" tabindex="-1"></a>  <span class="at">rank =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>,       <span class="co"># Q1 rankings</span></span>
<span id="cb17-708"><a href="#cb17-708" aria-hidden="true" tabindex="-1"></a>           <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">4</span>,       <span class="co"># Q2 rankings</span></span>
<span id="cb17-709"><a href="#cb17-709" aria-hidden="true" tabindex="-1"></a>           <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">4</span>,       <span class="co"># Q3 rankings</span></span>
<span id="cb17-710"><a href="#cb17-710" aria-hidden="true" tabindex="-1"></a>           <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">5</span>)       <span class="co"># Q4 rankings</span></span>
<span id="cb17-711"><a href="#cb17-711" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-712"><a href="#cb17-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-713"><a href="#cb17-713" aria-hidden="true" tabindex="-1"></a><span class="co"># Create bump chart</span></span>
<span id="cb17-714"><a href="#cb17-714" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rankings, <span class="fu">aes</span>(<span class="at">x =</span> quarter, <span class="at">y =</span> rank, </span>
<span id="cb17-715"><a href="#cb17-715" aria-hidden="true" tabindex="-1"></a>                     <span class="at">group =</span> product, <span class="at">color =</span> product)) <span class="sc">+</span></span>
<span id="cb17-716"><a href="#cb17-716" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb17-717"><a href="#cb17-717" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb17-718"><a href="#cb17-718" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_reverse</span>(<span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>) <span class="sc">+</span>  <span class="co"># Reverse Y-axis so </span></span>
<span id="cb17-719"><a href="#cb17-719" aria-hidden="true" tabindex="-1"></a>                                   <span class="co"># rank 1 is at the top</span></span>
<span id="cb17-720"><a href="#cb17-720" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb17-721"><a href="#cb17-721" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Product Rankings by Quarter&quot;</span>,</span>
<span id="cb17-722"><a href="#cb17-722" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">&quot;Showing changes in ranking </span></span>
<span id="cb17-723"><a href="#cb17-723" aria-hidden="true" tabindex="-1"></a><span class="st">       position over time&quot;</span>,</span>
<span id="cb17-724"><a href="#cb17-724" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Quarter&quot;</span>,</span>
<span id="cb17-725"><a href="#cb17-725" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Rank (Lower is Better)&quot;</span>,</span>
<span id="cb17-726"><a href="#cb17-726" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">&quot;Product&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-727"><a href="#cb17-727" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span>
<span id="cb17-728"><a href="#cb17-728" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-729"><a href="#cb17-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-730"><a href="#cb17-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-731"><a href="#cb17-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-732"><a href="#cb17-732" aria-hidden="true" tabindex="-1"></a><span class="fu"># Classical Models for Ordinal Data</span></span>
<span id="cb17-733"><a href="#cb17-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-734"><a href="#cb17-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-735"><a href="#cb17-735" aria-hidden="true" tabindex="-1"></a>::: {.content-visible when-format=&quot;html&quot;}</span>
<span id="cb17-736"><a href="#cb17-736" aria-hidden="true" tabindex="-1"></a>::: column-margin</span>
<span id="cb17-737"><a href="#cb17-737" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &lt;p&gt;&lt;a href=&quot;materials/Script_plots_examples.R&quot; download style=&quot;margin-right: 5px;&quot;&gt; &lt;i class=&quot;bi bi-file-earmark-code-fill&quot; style=&quot;font-size: 0.9em; vertical-align: middle;&quot;&gt;&lt;/i&gt; [R Script]{style=&quot;margin-left: 2px; vertical-align: middle;&quot;} &lt;/a&gt;&lt;/p&gt; --&gt;</span></span>
<span id="cb17-738"><a href="#cb17-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-739"><a href="#cb17-739" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;p&gt;&lt;a</span> <span class="er">href</span><span class="ot">=</span><span class="st">&quot;materials/Ordinal Data Analysis in R - Module 2.pdf&quot;</span> <span class="er">download</span><span class="kw">&gt;</span> <span class="kw">&lt;i</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;bi bi-file-earmark-slides-fill&quot;</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;font-size: 0.9em; vertical-align: middle;&quot;</span><span class="kw">&gt;&lt;/i&gt;</span> <span class="co">[</span><span class="ot">Slides</span><span class="co">]</span>{style=&quot;margin-left: 2px; vertical-align: middle;&quot;} <span class="kw">&lt;/a&gt;&lt;/p&gt;</span></span>
<span id="cb17-740"><a href="#cb17-740" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-741"><a href="#cb17-741" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-742"><a href="#cb17-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-743"><a href="#cb17-743" aria-hidden="true" tabindex="-1"></a><span class="fu">## Limitations of most commonly used models</span></span>
<span id="cb17-744"><a href="#cb17-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-745"><a href="#cb17-745" aria-hidden="true" tabindex="-1"></a><span class="fu">### Limitations of Linear Regression: {.unnumbered .toc-ignore}</span></span>
<span id="cb17-746"><a href="#cb17-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-747"><a href="#cb17-747" aria-hidden="true" tabindex="-1"></a>Linear regression is designed for dependent variables that are continuous and can take any value within a range (or at least have a large number of distinct, equally-spaced values).</span>
<span id="cb17-748"><a href="#cb17-748" aria-hidden="true" tabindex="-1"></a>Applying linear regression to ordinal data involves treating the ordered categories as if they were numerical scores with equal intervals between them.</span>
<span id="cb17-749"><a href="#cb17-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-750"><a href="#cb17-750" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Ignores Non-Interval Nature**: The primary issue is that linear regression assumes that the difference between category 1 and 2 is the same as the difference between category 2 and 3, and so on.</span>
<span id="cb17-751"><a href="#cb17-751" aria-hidden="true" tabindex="-1"></a>    For ordinal data, this is often not true.</span>
<span id="cb17-752"><a href="#cb17-752" aria-hidden="true" tabindex="-1"></a>    The &quot;distance&quot; between &quot;Very Dissatisfied&quot; and &quot;Dissatisfied&quot; might not be the same in the minds of respondents as the distance between &quot;Satisfied&quot; and &quot;Very Satisfied.&quot; By assigning numerical scores (e.g., 1, 2, 3, 4, 5) and running linear regression, we impose an arbitrary interval structure that the data doesn&#39;t necessarily possess.</span>
<span id="cb17-753"><a href="#cb17-753" aria-hidden="true" tabindex="-1"></a>    This can lead to inaccurate estimates of the effects of predictors.</span>
<span id="cb17-754"><a href="#cb17-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-755"><a href="#cb17-755" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Violation of Assumptions**: Linear regression assumes the dependent variable is continuous and errors are normally distributed with constant variance.</span>
<span id="cb17-756"><a href="#cb17-756" aria-hidden="true" tabindex="-1"></a>    For an ordinal variable with a limited number of categories, these assumptions are violated.</span>
<span id="cb17-757"><a href="#cb17-757" aria-hidden="true" tabindex="-1"></a>    The predicted values from a linear model can also fall outside the valid range of the ordinal scale (e.g., predicting a satisfaction level of 0.5 or 5.8 on a 1-5 scale).</span>
<span id="cb17-758"><a href="#cb17-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-759"><a href="#cb17-759" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Misleading Interpretation**: Interpreting coefficients in linear regression involves saying that a one-unit increase in a predictor is associated with a certain change in the mean score of the ordinal variable.</span>
<span id="cb17-760"><a href="#cb17-760" aria-hidden="true" tabindex="-1"></a>    This interpretation is based on the problematic assumption of equal intervals and might not accurately reflect the underlying process generating the ordinal response.</span>
<span id="cb17-761"><a href="#cb17-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-762"><a href="#cb17-762" aria-hidden="true" tabindex="-1"></a><span class="fu">### Limitations of Binary Logistic Regression: {.unnumbered .toc-ignore}</span></span>
<span id="cb17-763"><a href="#cb17-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-764"><a href="#cb17-764" aria-hidden="true" tabindex="-1"></a>Binary logistic regression is suitable for dependent variables with exactly two outcomes (e.g., Yes/No, Success/Failure).</span>
<span id="cb17-765"><a href="#cb17-765" aria-hidden="true" tabindex="-1"></a>To use it with an ordinal variable, you have to collapse the multiple ordered categories into just two.</span>
<span id="cb17-766"><a href="#cb17-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-767"><a href="#cb17-767" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Loss of Information**: The biggest drawback is the loss of valuable information about the granularity and ordering of the original categories.</span>
<span id="cb17-768"><a href="#cb17-768" aria-hidden="true" tabindex="-1"></a>    Forcing a 5-point scale into a binary outcome (e.g., &quot;Satisfied/Very Satisfied&quot; vs. &quot;Dissatisfied/Neutral/Very Dissatisfied&quot;) discards the nuances within the original categories.</span>
<span id="cb17-769"><a href="#cb17-769" aria-hidden="true" tabindex="-1"></a>    A model that can distinguish between &quot;Dissatisfied&quot; and &quot;Very Dissatisfied&quot; will likely be more informative than one that groups them.</span>
<span id="cb17-770"><a href="#cb17-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-771"><a href="#cb17-771" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Arbitrary Threshold**: The choice of where to split the ordinal scale into two groups is often arbitrary.</span>
<span id="cb17-772"><a href="#cb17-772" aria-hidden="true" tabindex="-1"></a>    Different researchers might choose different cut-off points, and this arbitrary choice can significantly influence the results and conclusions drawn from the analysis.</span>
<span id="cb17-773"><a href="#cb17-773" aria-hidden="true" tabindex="-1"></a>    The effect of a predictor might appear different depending on how the dichotomization is performed.</span>
<span id="cb17-774"><a href="#cb17-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-775"><a href="#cb17-775" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Reduced Statistical Power**: By reducing the number of outcomes, you potentially reduce the variability captured by the dependent variable, which can lead to a loss of statistical power to detect significant effects of your predictors compared to a model that utilizes the full ordinal scale.</span>
<span id="cb17-776"><a href="#cb17-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-777"><a href="#cb17-777" aria-hidden="true" tabindex="-1"></a><span class="fu">### Limitations of Multinomial Logistic Regression: {.unnumbered .toc-ignore}</span></span>
<span id="cb17-778"><a href="#cb17-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-779"><a href="#cb17-779" aria-hidden="true" tabindex="-1"></a>Multinomial (or polytomous) logistic regression is designed for dependent variables with three or more categories that have no natural order (e.g., choice of car color: red, blue, green).</span>
<span id="cb17-780"><a href="#cb17-780" aria-hidden="true" tabindex="-1"></a>While it can handle multiple categories, its fundamental structure doesn&#39;t account for ranking.</span>
<span id="cb17-781"><a href="#cb17-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-782"><a href="#cb17-782" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Ignores the Order**: Multinomial logistic regression models the probability of being in each category relative to a chosen baseline category.</span>
<span id="cb17-783"><a href="#cb17-783" aria-hidden="true" tabindex="-1"></a>    It estimates a separate set of coefficients for each category comparison (e.g., Category 2 vs. Category 1, Category 3 vs. Category 1, etc.).</span>
<span id="cb17-784"><a href="#cb17-784" aria-hidden="true" tabindex="-1"></a>    It treats the categories as distinct nominal outcomes, completely ignoring the fact that category 3 falls between category 2 and category 4 in a meaningful way.</span>
<span id="cb17-785"><a href="#cb17-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-786"><a href="#cb17-786" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Difficult Interpretation** (in terms of Order): The coefficients in a multinomial logit model are interpreted in terms of the change in log-odds of being in a specific category versus the baseline category for a one-unit change in a predictor.</span>
<span id="cb17-787"><a href="#cb17-787" aria-hidden="true" tabindex="-1"></a>    While technically correct, relating these separate category-specific effects back to the overall ordered nature of the dependent variable can be cumbersome and less intuitive than the single cumulative odds ratio provided by the cumulative logit model (when the proportional odds assumption holds).</span>
<span id="cb17-788"><a href="#cb17-788" aria-hidden="true" tabindex="-1"></a>    It doesn&#39;t directly answer questions like &quot;how does this predictor affect the likelihood of being in a higher category?&quot;</span>
<span id="cb17-789"><a href="#cb17-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-790"><a href="#cb17-790" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modeling Cumulative Probabilities</span></span>
<span id="cb17-791"><a href="#cb17-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-792"><a href="#cb17-792" aria-hidden="true" tabindex="-1"></a>The primary methodology for modeling ordinal data revolves around the cumulative probabilities associated with the ordered categories.</span>
<span id="cb17-793"><a href="#cb17-793" aria-hidden="true" tabindex="-1"></a>This approach respects the inherent order of the data, ensuring that these probabilities monotonically increase as we move up the ordinal scale.</span>
<span id="cb17-794"><a href="#cb17-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-795"><a href="#cb17-795" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- In the context of binary response variables, logistic regression is the standard model. --&gt;</span></span>
<span id="cb17-796"><a href="#cb17-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-797"><a href="#cb17-797" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- For multinomial variables, the Baseline-category Logit model, an extension of logistic regression, is used to form logits by comparing each category to a baseline category. However, this method is generally better suited for unordered categorical responses because it does not account for the crucial characteristic of ordinality. --&gt;</span></span>
<span id="cb17-798"><a href="#cb17-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-799"><a href="#cb17-799" aria-hidden="true" tabindex="-1"></a>To more appropriately handle ordinality, the cumulative probabilities approach modifies logistic regression by applying transformations that consider the order of the categories.</span>
<span id="cb17-800"><a href="#cb17-800" aria-hidden="true" tabindex="-1"></a>A common transformation is the logit transformation applied to the cumulative probabilities, which enhances the model&#39;s ability to capture the ordered nature of the data.</span>
<span id="cb17-801"><a href="#cb17-801" aria-hidden="true" tabindex="-1"></a>Other transformations, such as probit or log-log, can also be used depending on the specific data characteristics and analytical requirements.</span>
<span id="cb17-802"><a href="#cb17-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-803"><a href="#cb17-803" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Furthermore, two additional transformations are noteworthy for ordinal data: the use of adjacent categories, and the use of the continuation ratio. --&gt;</span></span>
<span id="cb17-804"><a href="#cb17-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-805"><a href="#cb17-805" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- These methods refine the approach by focusing on the relationships between consecutive categories, providing a more detailed modeling of the ordinal data&#39;s structure. --&gt;</span></span>
<span id="cb17-806"><a href="#cb17-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-807"><a href="#cb17-807" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- To model the relationship between predictors and an ordinal response variable, the cumulative logit model doesn&#39;t directly model the probability of being in each specific category (P(Y=c  --&gt;</span></span>
<span id="cb17-808"><a href="#cb17-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-809"><a href="#cb17-809" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- j --&gt;</span></span>
<span id="cb17-810"><a href="#cb17-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-811"><a href="#cb17-811" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ​ --&gt;</span></span>
<span id="cb17-812"><a href="#cb17-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-813"><a href="#cb17-813" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--  )). Instead, it focuses on cumulative probabilities. --&gt;</span></span>
<span id="cb17-814"><a href="#cb17-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-815"><a href="#cb17-815" aria-hidden="true" tabindex="-1"></a>**Definition**: Given an ordinal variable $R$ with $m$ ordered categories, let&#39;s denote these categories as $r_1, r_2, \dots, r_m$, where $r_1$ is the &quot;lowest&quot; category and $r_m$ is the &quot;highest&quot;.</span>
<span id="cb17-816"><a href="#cb17-816" aria-hidden="true" tabindex="-1"></a>The categories have a meaningful order: $r_1 \leq r_2, \leq \dots, \leq r_m$.</span>
<span id="cb17-817"><a href="#cb17-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-818"><a href="#cb17-818" aria-hidden="true" tabindex="-1"></a>A cumulative probability for a specific category $r_j$ is the probability that the observed response $R$ falls into category $r_j$, or any category below it.</span>
<span id="cb17-819"><a href="#cb17-819" aria-hidden="true" tabindex="-1"></a>Mathematically, this is expressed as $P(R \leq r_j)$.</span>
<span id="cb17-820"><a href="#cb17-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-821"><a href="#cb17-821" aria-hidden="true" tabindex="-1"></a>We can define $m-1$ such cumulative probabilities, corresponding to the thresholds between the categories:</span>
<span id="cb17-822"><a href="#cb17-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-823"><a href="#cb17-823" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For the first category $r_1$:\</span>
<span id="cb17-824"><a href="#cb17-824" aria-hidden="true" tabindex="-1"></a>    $P(R \leq r_1) = P(R = r_1)$ is simply the probability of being in the lowest category.</span>
<span id="cb17-825"><a href="#cb17-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-826"><a href="#cb17-826" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For the first category $r_2$:\</span>
<span id="cb17-827"><a href="#cb17-827" aria-hidden="true" tabindex="-1"></a>    $P(R \leq r_2) = P(R = r_1) + P(R = r_2)$ is the probability of being in the second category or any category below it (which is just the first category).</span>
<span id="cb17-828"><a href="#cb17-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-829"><a href="#cb17-829" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For the third category $r_3$:\</span>
<span id="cb17-830"><a href="#cb17-830" aria-hidden="true" tabindex="-1"></a>    $P(R \leq r_3) = P(R = r_1) + P(R = r_2) + P(R = r_3)$ is the probability of being in the third category or any category below it.</span>
<span id="cb17-831"><a href="#cb17-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-832"><a href="#cb17-832" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>...and so on, up to the $(m-1)$-th category $r_{(m-1)}$:\</span>
<span id="cb17-833"><a href="#cb17-833" aria-hidden="true" tabindex="-1"></a>    $P(R \leq r_{(m-1)}) = P(R = r_1) + P(R = r_2) + P(R = r_3) + \dots + P(R = r_{(m-1)})$ is the probability of being in the second-highest category or any category below it.</span>
<span id="cb17-834"><a href="#cb17-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-835"><a href="#cb17-835" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For the last category $r_m$ $r_{(m-1)}$:\</span>
<span id="cb17-836"><a href="#cb17-836" aria-hidden="true" tabindex="-1"></a>    $P(R \leq r_m) = P(R = r_1) + P(R = r_2) + P(R = r_3) + \dots + P(R = r_{(m-1)})+ P(R = r_m)=1$, which is the cumulative probability is always 1 because it includes all possible outcomes.</span>
<span id="cb17-837"><a href="#cb17-837" aria-hidden="true" tabindex="-1"></a>    Since it carries no information about the differences between categories, it is not included in the modeling process; we only model the first $m-1$ cumulative probabilities.</span>
<span id="cb17-838"><a href="#cb17-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-839"><a href="#cb17-839" aria-hidden="true" tabindex="-1"></a>The use of cumulative probabilities is a clever way to turn the ordinal modeling problem into a series of binary comparisons, while respecting the order.</span>
<span id="cb17-840"><a href="#cb17-840" aria-hidden="true" tabindex="-1"></a>Each cumulative probability $P(R \leq r_j)$ inherently creates a binary split at the threshold $r_j$: - Outcome 1: the response is in category $r_j$ or lower $(R\leq r_j)$; - Outcome 2: The response is in category higher than $r_j$ $(R &gt; r_j)$.</span>
<span id="cb17-841"><a href="#cb17-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-842"><a href="#cb17-842" aria-hidden="true" tabindex="-1"></a>By modeling the probability of this binary outcome for each threshold $j=1,\dots,m−1$, we capture the transitions between categories along the ordered scale.</span>
<span id="cb17-843"><a href="#cb17-843" aria-hidden="true" tabindex="-1"></a>The cumulative logit model then applies the logit transformation to these cumulative probabilities, allowing them to be related to a linear combination of predictors.</span>
<span id="cb17-844"><a href="#cb17-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-845"><a href="#cb17-845" aria-hidden="true" tabindex="-1"></a>**Numerical Example**: Let&#39;s consider a simple ordinal variable, &quot;Product Satisfaction,&quot; with $m = 4$ ordered categories:</span>
<span id="cb17-846"><a href="#cb17-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-847"><a href="#cb17-847" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$r_1$: Very Dissatisfied (VD)</span>
<span id="cb17-848"><a href="#cb17-848" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$r_2$: Dissatisfied (D)</span>
<span id="cb17-849"><a href="#cb17-849" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$r_3$: Satisfied (S)</span>
<span id="cb17-850"><a href="#cb17-850" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$r_4$: Very Satisfied (VS)</span>
<span id="cb17-851"><a href="#cb17-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-852"><a href="#cb17-852" aria-hidden="true" tabindex="-1"></a>Suppose, for a particular group of individuals, the probabilities of being in each specific category are:</span>
<span id="cb17-853"><a href="#cb17-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-854"><a href="#cb17-854" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$P(R=VD)=P(R=r_1)=0.10$</span>
<span id="cb17-855"><a href="#cb17-855" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$P(R=D)=P(R=r_2)=0.20$</span>
<span id="cb17-856"><a href="#cb17-856" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$P(R=S)=P(R=r_3)=0.40$</span>
<span id="cb17-857"><a href="#cb17-857" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$P(R=VS)=P(R=r_4)=0.30$</span>
<span id="cb17-858"><a href="#cb17-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-859"><a href="#cb17-859" aria-hidden="true" tabindex="-1"></a>Now, let&#39;s calculate the cumulative probabilities:</span>
<span id="cb17-860"><a href="#cb17-860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-861"><a href="#cb17-861" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Cumulative Probability for $r_1$ (VD) <span class="kw">&lt;br&gt;</span> $P(R \leq r_1) = P(R = VD) = 0.10$ <span class="kw">&lt;br&gt;</span> This represents the probability of being in the &quot;Very Dissatisfied&quot; category or below (just VD).</span>
<span id="cb17-862"><a href="#cb17-862" aria-hidden="true" tabindex="-1"></a>    The implied binary split is $<span class="sc">\{</span>VD<span class="sc">\}</span>$ vs $<span class="sc">\{</span>D, S, VS<span class="sc">\}</span>$.</span>
<span id="cb17-863"><a href="#cb17-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-864"><a href="#cb17-864" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Cumulative Probability for $r_2$ (D) <span class="kw">&lt;br&gt;</span> $P(R \leq r_2) = P(R = VD) + P(R = D) = 0.10 + 0.20 = 0.30$ <span class="kw">&lt;br&gt;</span> This represents the probability of being in the &quot;Dissatisfied&quot; category or below (VD or D).</span>
<span id="cb17-865"><a href="#cb17-865" aria-hidden="true" tabindex="-1"></a>    The implied binary split is $<span class="sc">\{</span>VD, D<span class="sc">\}</span>$ vs $<span class="sc">\{</span>S, VS<span class="sc">\}</span>$.</span>
<span id="cb17-866"><a href="#cb17-866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-867"><a href="#cb17-867" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Cumulative Probability for $r_3$ (S) <span class="kw">&lt;br&gt;</span> $P(R \leq r_3) = P(R = VD) + P(R = D) + P(R = S) = 0.10 + 0.20 + 0.40 = 0.70$ <span class="kw">&lt;br&gt;</span> This represents the probability of being in the &quot;Satisfied&quot; category or below (VD, D, or S).</span>
<span id="cb17-868"><a href="#cb17-868" aria-hidden="true" tabindex="-1"></a>    The implied binary split is $<span class="sc">\{</span>VD, D, S<span class="sc">\}</span>$ vs $<span class="sc">\{</span>VS<span class="sc">\}</span>$.</span>
<span id="cb17-869"><a href="#cb17-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-870"><a href="#cb17-870" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Cumulative Probability for $r_4$ (VS) <span class="kw">&lt;br&gt;</span> $P(R \leq r_4) = P(R = VD) + P(R = D) + P(R = S) + P(R = VS) = 0.10 + 0.20 + 0.40 + 0.3 = 1$ As expected, the cumulative probability for the highest category is 1.</span>
<span id="cb17-871"><a href="#cb17-871" aria-hidden="true" tabindex="-1"></a>    We do not model this.</span>
<span id="cb17-872"><a href="#cb17-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-873"><a href="#cb17-873" aria-hidden="true" tabindex="-1"></a>So, for this 4-category variable, the cumulative logit model will focus on modeling the relationships between predictors and the first $m−1=4−1=3$ cumulative probabilities.</span>
<span id="cb17-874"><a href="#cb17-874" aria-hidden="true" tabindex="-1"></a>Each of these represents a different threshold or cut-point on the ordered scale.</span>
<span id="cb17-875"><a href="#cb17-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-876"><a href="#cb17-876" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Cumulative Logit with Proportional Odds Assumption</span></span>
<span id="cb17-877"><a href="#cb17-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-878"><a href="#cb17-878" aria-hidden="true" tabindex="-1"></a>To be able to model the relationship between the cumulative probabilities and the explanatory variables, a function is needed and, as in the binary logistic regression, we use the logit to model the probability of success.</span>
<span id="cb17-879"><a href="#cb17-879" aria-hidden="true" tabindex="-1"></a>In the case of ordinal data, we apply the logit not to the probability of a single category, but to the cumulative probabilities.</span>
<span id="cb17-880"><a href="#cb17-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-881"><a href="#cb17-881" aria-hidden="true" tabindex="-1"></a>The cumulative logit transformation for the $j$-th threshold (where $j$ goes from $1$ to $m−1$) is defined as the natural logarithm of the cumulative odds:</span>
<span id="cb17-882"><a href="#cb17-882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-883"><a href="#cb17-883" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-884"><a href="#cb17-884" aria-hidden="true" tabindex="-1"></a>\text{logit} <span class="co">[</span><span class="ot"> P (R \leq r_j)</span><span class="co">]</span> = \log \Bigg( \frac{P(R \leq r_j)}{1-P(R \leq r_j)}\Bigg)</span>
<span id="cb17-885"><a href="#cb17-885" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cumlogit1}</span>
<span id="cb17-886"><a href="#cb17-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-887"><a href="#cb17-887" aria-hidden="true" tabindex="-1"></a>Since $1-P(R \leq r_j)$ is the probability that the outcome $R$ is greather than the category $r_j$.</span>
<span id="cb17-888"><a href="#cb17-888" aria-hidden="true" tabindex="-1"></a>So, the cumulative logit can be rewritten as:</span>
<span id="cb17-889"><a href="#cb17-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-890"><a href="#cb17-890" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-891"><a href="#cb17-891" aria-hidden="true" tabindex="-1"></a>\text{logit} <span class="co">[</span><span class="ot"> P (R \leq r_j)</span><span class="co">]</span> = \log \Bigg( \frac{P(R \leq r_j)}{P(R &gt; r_j)}\Bigg)</span>
<span id="cb17-892"><a href="#cb17-892" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cumlogit2}</span>
<span id="cb17-893"><a href="#cb17-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-894"><a href="#cb17-894" aria-hidden="true" tabindex="-1"></a>This expression represents the natural logarithm of the odds of being in category $r_j$ or any category below it, versus being in any category above $r_j$.</span>
<span id="cb17-895"><a href="#cb17-895" aria-hidden="true" tabindex="-1"></a>This transformation, as in the case of the binary logistic regression, maps probabilities (which are between 0 and 1) onto the entire real number line $(-\infty, + \infty)$.</span>
<span id="cb17-896"><a href="#cb17-896" aria-hidden="true" tabindex="-1"></a>This allows us to equate the logit of this cumulative probability to a linear combination of our predictors, which can take any real value.</span>
<span id="cb17-897"><a href="#cb17-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-898"><a href="#cb17-898" aria-hidden="true" tabindex="-1"></a>The resulting statistical model, and the most common one for ordinal data with a cumulative logit link, is known as the Cumulative Logit Proportional Odds Model.</span>
<span id="cb17-899"><a href="#cb17-899" aria-hidden="true" tabindex="-1"></a>Its basic structure assumes that the cumulative logit for each threshold is a linear function of the predictor variables:</span>
<span id="cb17-900"><a href="#cb17-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-901"><a href="#cb17-901" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-902"><a href="#cb17-902" aria-hidden="true" tabindex="-1"></a>\text{logit}<span class="co">[</span><span class="ot">P(R\leq r_j | X_1, \dots, X_k)</span><span class="co">]</span> = \alpha_j + \beta_1X_1 + \beta_2X_2 + \dots + \beta_kX_k</span>
<span id="cb17-903"><a href="#cb17-903" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cumlogit3}</span>
<span id="cb17-904"><a href="#cb17-904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-905"><a href="#cb17-905" aria-hidden="true" tabindex="-1"></a>This equation is estimated simultaneously for each of the $m-1$ cumulative thresholds.</span>
<span id="cb17-906"><a href="#cb17-906" aria-hidden="true" tabindex="-1"></a>in this equation:</span>
<span id="cb17-907"><a href="#cb17-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-908"><a href="#cb17-908" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$P(R \leq r_j | \boldsymbol{X})$ is the cumulative probability of being in category $r_j$ or lower, conditional on the values of the predictor variables $X_1 ,X_2, \dots, X_k$.</span>
<span id="cb17-909"><a href="#cb17-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-910"><a href="#cb17-910" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\alpha_j$ are the intercepts of the model.</span>
<span id="cb17-911"><a href="#cb17-911" aria-hidden="true" tabindex="-1"></a>    A crucial aspect of the cumulative logit model is that there is a different intercept for each of the $m-1$ cumulative logits we are modeling.\</span>
<span id="cb17-912"><a href="#cb17-912" aria-hidden="true" tabindex="-1"></a>    $\alpha_1$ is the intercept for $\text{logit}[P(R\leq r_1)]$, $\alpha_2$ is the intercept for $\text{logit}[P(R\leq r_2)]$, and $\alpha_{(m-1)}$ is the intercept for $\text{logit}[P(R\leq r_{(m-1)})]$.\</span>
<span id="cb17-913"><a href="#cb17-913" aria-hidden="true" tabindex="-1"></a>    These intercepts represent the baseline cumulative log-odds for their respective threshold when all the predictor variables X are zero.\</span>
<span id="cb17-914"><a href="#cb17-914" aria-hidden="true" tabindex="-1"></a>    It is necessary that these intercepts are ordered: $\alpha_1 \leq \alpha_2 \leq \dots \leq \alpha_{(m-1)}$.\</span>
<span id="cb17-915"><a href="#cb17-915" aria-hidden="true" tabindex="-1"></a>    This ensures that the resulting cumulative probabilities are non-decreasing as j increases.</span>
<span id="cb17-916"><a href="#cb17-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-917"><a href="#cb17-917" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\beta_1, \beta_2, \dots, \beta_k$ are the coefficients associated to each predictor variables $X_1$, $X_2$, $\dots, X_k$.\</span>
<span id="cb17-918"><a href="#cb17-918" aria-hidden="true" tabindex="-1"></a>    Since we are operating under proportional odds assumption, in this model these is only one set of $\beta$ coefficients that applies across all $m-1$ cumulative logit equations.\</span>
<span id="cb17-919"><a href="#cb17-919" aria-hidden="true" tabindex="-1"></a>    This implies that the effect of each predictor on the cumulative log-odds is the same.</span>
<span id="cb17-920"><a href="#cb17-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-921"><a href="#cb17-921" aria-hidden="true" tabindex="-1"></a>To demonstrate the proportional odds assumption, let&#39;s consider the cumulative odds for two distinct sets of predictor values: $\boldsymbol{X}^{(1)} = (X_1^{(1)}, \dots, X_k^{(1)})$ and $\boldsymbol{X}^{(2)} = (X_1^{(2)}, \dots, X_k^{(2)})$.</span>
<span id="cb17-922"><a href="#cb17-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-923"><a href="#cb17-923" aria-hidden="true" tabindex="-1"></a>The cumulative odds at threshold $r_j$ for the first set of predictors $\boldsymbol{X}^{(1)}$ are: </span>
<span id="cb17-924"><a href="#cb17-924" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-925"><a href="#cb17-925" aria-hidden="true" tabindex="-1"></a>\text{Odds}(R \leq r_j | \boldsymbol{X}^{(1)}) =\exp \Bigg( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(1)} \Bigg)</span>
<span id="cb17-926"><a href="#cb17-926" aria-hidden="true" tabindex="-1"></a>$$ Similarly, for the second set of predictors $\boldsymbol{X}^{(2)}$: </span>
<span id="cb17-927"><a href="#cb17-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-928"><a href="#cb17-928" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-929"><a href="#cb17-929" aria-hidden="true" tabindex="-1"></a>\text{Odds}(R \leq r_j | \boldsymbol{X}^{(2)}) = \exp \Bigg( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(2)} \Bigg)</span>
<span id="cb17-930"><a href="#cb17-930" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb17-931"><a href="#cb17-931" aria-hidden="true" tabindex="-1"></a>The Odds Ratio (OR) comparing the cumulative odds at $\boldsymbol{X}^{(2)}$ to those at $\boldsymbol{X}^{(1)}$ for the event $R \leq r_j$ is: </span>
<span id="cb17-932"><a href="#cb17-932" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-933"><a href="#cb17-933" aria-hidden="true" tabindex="-1"></a>\text{OR}_j = \frac{\text{Odds}(R \leq r_j | \boldsymbol{X}^{(2)})}{\text{Odds}(R \leq r_j | \boldsymbol{X}^{(1)})}</span>
<span id="cb17-934"><a href="#cb17-934" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb17-935"><a href="#cb17-935" aria-hidden="true" tabindex="-1"></a>Substituting the exponential expressions for the odds: $$</span>
<span id="cb17-936"><a href="#cb17-936" aria-hidden="true" tabindex="-1"></a>\text{OR}_j = \frac{\exp \Big( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(2)} \Big)}{\exp \Big( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(1)} \Big)}</span>
<span id="cb17-937"><a href="#cb17-937" aria-hidden="true" tabindex="-1"></a>$$ Using the property $e^a / e^b = e^{a-b}$, we can simplify the expression: </span>
<span id="cb17-938"><a href="#cb17-938" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-939"><a href="#cb17-939" aria-hidden="true" tabindex="-1"></a>\text{OR}_j = \exp \Bigg( \Big( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(2)} \Big) - \Big( \alpha_j + \sum_{i=1}^{k} \beta_iX_i^{(1)} \Big) \Bigg)</span>
<span id="cb17-940"><a href="#cb17-940" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb17-941"><a href="#cb17-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-942"><a href="#cb17-942" aria-hidden="true" tabindex="-1"></a>Crucially, the intercept term $\alpha_j$ cancels out: </span>
<span id="cb17-943"><a href="#cb17-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-944"><a href="#cb17-944" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-945"><a href="#cb17-945" aria-hidden="true" tabindex="-1"></a>\text{OR}_j = \exp \Bigg( \sum_{i=1}^{k} \beta_iX_i^{(2)} - \sum_{i=1}^{k} \beta_iX_i^{(1)} \Bigg)</span>
<span id="cb17-946"><a href="#cb17-946" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb17-947"><a href="#cb17-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-948"><a href="#cb17-948" aria-hidden="true" tabindex="-1"></a>This can be further condensed:</span>
<span id="cb17-949"><a href="#cb17-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-950"><a href="#cb17-950" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-951"><a href="#cb17-951" aria-hidden="true" tabindex="-1"></a>\text{OR}_j = \exp \Bigg( \sum_{i=1}^{k} \beta_i(X_i^{(2)} - X_i^{(1)}) \Bigg)</span>
<span id="cb17-952"><a href="#cb17-952" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-953"><a href="#cb17-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-954"><a href="#cb17-954" aria-hidden="true" tabindex="-1"></a>As evident from this final formula, the Odds Ratio ($\text{OR}_j$) does not contain the subscript $j$.</span>
<span id="cb17-955"><a href="#cb17-955" aria-hidden="true" tabindex="-1"></a>This signifies that the odds ratio associated with a change in the predictor variables is constant across all $m-1$ cumulative thresholds.</span>
<span id="cb17-956"><a href="#cb17-956" aria-hidden="true" tabindex="-1"></a>This inherent consistency in the effect of predictors across the ordinal categories is precisely what defines the proportional odds assumption.</span>
<span id="cb17-957"><a href="#cb17-957" aria-hidden="true" tabindex="-1"></a>It means that while the baseline odds change for each category, the multiplicative effect of the predictors on these odds remains the same.</span>
<span id="cb17-958"><a href="#cb17-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-959"><a href="#cb17-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-960"><a href="#cb17-960" aria-hidden="true" tabindex="-1"></a>Graphically, this translates to parallelism on the log-odds scale. If you were to plot the cumulative log-odds for different levels of a predictor, you would see a set of parallel lines. For example, imagine an ordinal outcome with four categories (e.g., &#39;Low&#39;, &#39;Medium&#39;, &#39;High&#39;, &#39;Very High&#39;). There would be three cumulative probabilities: $P(R\leq Low)$, $P(R \leq Medium)$, and $P(R \leq High)$. If the Proportional Odds assumption holds for a continuous predictor, then the log-odds for each of these cumulative probabilities would change by the same amount for a one-unit increase in that predictor.</span>
<span id="cb17-961"><a href="#cb17-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-962"><a href="#cb17-962" aria-hidden="true" tabindex="-1"></a>You would visualize three separate curves, one for each cumulative probability, plotted against the predictor on the x-axis, with the y-axis representing the logit of these probabilities. If the Proportional Odds assumption holds, these three curves would run parallel to each other across the entire range of the predictor. They would be shifted vertically relative to each other (due to the different $\alpha_j$, but their slopes (the $\beta$ coefficients) would be identical.</span>
<span id="cb17-963"><a href="#cb17-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-964"><a href="#cb17-964" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=FALSE, message=F, warning=F, error=F}</span></span>
<span id="cb17-965"><a href="#cb17-965" aria-hidden="true" tabindex="-1"></a><span class="co"># R Concept: Illustrating Parallel Log-Odds Lines (PO Assumption Holds)</span></span>
<span id="cb17-966"><a href="#cb17-966" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb17-967"><a href="#cb17-967" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr) <span class="co"># For pivot_longer</span></span>
<span id="cb17-968"><a href="#cb17-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-969"><a href="#cb17-969" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data that adheres to the Proportional Odds assumption</span></span>
<span id="cb17-970"><a href="#cb17-970" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb17-971"><a href="#cb17-971" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb17-972"><a href="#cb17-972" aria-hidden="true" tabindex="-1"></a>predictor_x <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">0</span>, <span class="dv">10</span>) <span class="co"># Our continuous predictor</span></span>
<span id="cb17-973"><a href="#cb17-973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-974"><a href="#cb17-974" aria-hidden="true" tabindex="-1"></a><span class="co"># Define hypothetical thresholds (alpha_j)</span></span>
<span id="cb17-975"><a href="#cb17-975" aria-hidden="true" tabindex="-1"></a>alpha_1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span></span>
<span id="cb17-976"><a href="#cb17-976" aria-hidden="true" tabindex="-1"></a>alpha_2 <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb17-977"><a href="#cb17-977" aria-hidden="true" tabindex="-1"></a>alpha_3 <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb17-978"><a href="#cb17-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-979"><a href="#cb17-979" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a single, constant beta coefficient for the predictor</span></span>
<span id="cb17-980"><a href="#cb17-980" aria-hidden="true" tabindex="-1"></a>beta_x <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb17-981"><a href="#cb17-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-982"><a href="#cb17-982" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate cumulative log-odds for each observation and each threshold</span></span>
<span id="cb17-983"><a href="#cb17-983" aria-hidden="true" tabindex="-1"></a><span class="co"># This simulates the linear predictor part of the model + threshold</span></span>
<span id="cb17-984"><a href="#cb17-984" aria-hidden="true" tabindex="-1"></a>log_odds_1 <span class="ot">&lt;-</span> alpha_1 <span class="sc">+</span> beta_x <span class="sc">*</span> predictor_x</span>
<span id="cb17-985"><a href="#cb17-985" aria-hidden="true" tabindex="-1"></a>log_odds_2 <span class="ot">&lt;-</span> alpha_2 <span class="sc">+</span> beta_x <span class="sc">*</span> predictor_x</span>
<span id="cb17-986"><a href="#cb17-986" aria-hidden="true" tabindex="-1"></a>log_odds_3 <span class="ot">&lt;-</span> alpha_3 <span class="sc">+</span> beta_x <span class="sc">*</span> predictor_x</span>
<span id="cb17-987"><a href="#cb17-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-988"><a href="#cb17-988" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine into a data frame for plotting</span></span>
<span id="cb17-989"><a href="#cb17-989" aria-hidden="true" tabindex="-1"></a>plot_data_po_concept <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb17-990"><a href="#cb17-990" aria-hidden="true" tabindex="-1"></a>  <span class="at">predictor_x =</span> predictor_x,</span>
<span id="cb17-991"><a href="#cb17-991" aria-hidden="true" tabindex="-1"></a>  <span class="at">Threshold_1 =</span> log_odds_1,</span>
<span id="cb17-992"><a href="#cb17-992" aria-hidden="true" tabindex="-1"></a>  <span class="at">Threshold_2 =</span> log_odds_2,</span>
<span id="cb17-993"><a href="#cb17-993" aria-hidden="true" tabindex="-1"></a>  <span class="at">Threshold_3 =</span> log_odds_3</span>
<span id="cb17-994"><a href="#cb17-994" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-995"><a href="#cb17-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-996"><a href="#cb17-996" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape data to long format for ggplot</span></span>
<span id="cb17-997"><a href="#cb17-997" aria-hidden="true" tabindex="-1"></a>plot_data_po_concept_long <span class="ot">&lt;-</span> plot_data_po_concept <span class="sc">%&gt;%</span></span>
<span id="cb17-998"><a href="#cb17-998" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb17-999"><a href="#cb17-999" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols =</span> <span class="fu">starts_with</span>(<span class="st">&quot;Threshold_&quot;</span>),</span>
<span id="cb17-1000"><a href="#cb17-1000" aria-hidden="true" tabindex="-1"></a>    <span class="at">names_to =</span> <span class="st">&quot;Cumulative_Log_Odds_Curve&quot;</span>,</span>
<span id="cb17-1001"><a href="#cb17-1001" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_to =</span> <span class="st">&quot;Log_Odds&quot;</span></span>
<span id="cb17-1002"><a href="#cb17-1002" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb17-1003"><a href="#cb17-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1004"><a href="#cb17-1004" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the parallel log-odds lines</span></span>
<span id="cb17-1005"><a href="#cb17-1005" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plot_data_po_concept_long, <span class="fu">aes</span>(<span class="at">x =</span> predictor_x, <span class="at">y =</span> Log_Odds, <span class="at">color =</span> Cumulative_Log_Odds_Curve)) <span class="sc">+</span></span>
<span id="cb17-1006"><a href="#cb17-1006" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">group =</span> Cumulative_Log_Odds_Curve), <span class="at">stat =</span> <span class="st">&quot;smooth&quot;</span>, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">formula =</span> y <span class="sc">~</span> x, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span> <span class="co"># Linear fit to emphasize parallelism</span></span>
<span id="cb17-1007"><a href="#cb17-1007" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb17-1008"><a href="#cb17-1008" aria-hidden="true" tabindex="-1"></a>    <span class="co"># title = &quot;Proportional Odds Assumption Holds&quot;,</span></span>
<span id="cb17-1009"><a href="#cb17-1009" aria-hidden="true" tabindex="-1"></a>    <span class="co"># subtitle = &quot;The effect (slope) of the predictor is constant across all cumulative thresholds&quot;,</span></span>
<span id="cb17-1010"><a href="#cb17-1010" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Predictor Variable (X)&quot;</span>,</span>
<span id="cb17-1011"><a href="#cb17-1011" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Cumulative Log-Odds&quot;</span>,</span>
<span id="cb17-1012"><a href="#cb17-1012" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&quot;Cumulative Threshold&quot;</span></span>
<span id="cb17-1013"><a href="#cb17-1013" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb17-1014"><a href="#cb17-1014" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb17-1015"><a href="#cb17-1015" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_brewer</span>(<span class="at">palette =</span> <span class="st">&quot;Set1&quot;</span>, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;P(R &lt;= r1)&quot;</span>, <span class="st">&quot;P(R &lt;= r2)&quot;</span>, <span class="st">&quot;P(R &lt;= r3)&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb17-1016"><a href="#cb17-1016" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span>
<span id="cb17-1017"><a href="#cb17-1017" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-1018"><a href="#cb17-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1019"><a href="#cb17-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1020"><a href="#cb17-1020" aria-hidden="true" tabindex="-1"></a>The Proportional Odds assumption is useful for two main reason: </span>
<span id="cb17-1021"><a href="#cb17-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1022"><a href="#cb17-1022" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>**Parsimony and Simplicity**: This is a major advantage. If the assumption holds, the $\beta$ coefficients are estimated for each predictor, regardless of the number of categories $m$.  Fewer parameters make the model easier to estimate, interpret, and potentially more stable, especially with smaller sample sizes.</span>
<span id="cb17-1023"><a href="#cb17-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1024"><a href="#cb17-1024" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Clear and Consistent Interpretation**: A single Odds Ratio per predictor provides a clear, concise summary of its effect across the entire ordinal scale. </span>
<span id="cb17-1025"><a href="#cb17-1025" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1026"><a href="#cb17-1026" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- For instance, if $$\text{exp}(\beta_{temp})=0.75$$, we confidently say that increasing temperature by one unit multiplies the odds of being in a lower rating category by 0.75, regardless the categories we are comparing.  --&gt;</span></span>
<span id="cb17-1027"><a href="#cb17-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1028"><a href="#cb17-1028" aria-hidden="true" tabindex="-1"></a><span class="fu">### Latent Variable Motivation {.unnumbered .toc-ignore}</span></span>
<span id="cb17-1029"><a href="#cb17-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1030"><a href="#cb17-1030" aria-hidden="true" tabindex="-1"></a>To better understand this model we can think about an underlying, unobserved latent continuous variable, called $R^*$.</span>
<span id="cb17-1031"><a href="#cb17-1031" aria-hidden="true" tabindex="-1"></a>Let&#39;s imagine that the ordinal response $R$ that we observe is actually a categorized version of the continuous unobserved variable $R^*$.</span>
<span id="cb17-1032"><a href="#cb17-1032" aria-hidden="true" tabindex="-1"></a>We can assume that $R^*$ is linearly related to our predictors plus some error, similar to a standard linear regression model:</span>
<span id="cb17-1033"><a href="#cb17-1033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1034"><a href="#cb17-1034" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1035"><a href="#cb17-1035" aria-hidden="true" tabindex="-1"></a>R^* = \beta_0^* + \beta_1^*X_1 + \dots + \beta_k^*X_k + \epsilon</span>
<span id="cb17-1036"><a href="#cb17-1036" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1037"><a href="#cb17-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1038"><a href="#cb17-1038" aria-hidden="true" tabindex="-1"></a>We can set some fixed thresholds, $\gamma_0 = -\infty, \gamma_1$, $\gamma_2$, $\dots, \gamma_{(m-1)}$, $\gamma_m = +\infty$ on the $R^*$ scale, such that if $R^*$ falls between two thresholds, the observed ordinal variable $R$ falls into the corresponding category.</span>
<span id="cb17-1039"><a href="#cb17-1039" aria-hidden="true" tabindex="-1"></a>The thresholds are set such that $\gamma_0 &lt; \gamma_1$ <span class="sc">\&lt;</span> $\gamma_2$ <span class="sc">\&lt;</span> $\dots &lt; \gamma_{(m-1)}$ $&lt;\gamma_m$.</span>
<span id="cb17-1040"><a href="#cb17-1040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1041"><a href="#cb17-1041" aria-hidden="true" tabindex="-1"></a>The ordinal category is determined by $R^*$ based on the thresholds:</span>
<span id="cb17-1042"><a href="#cb17-1042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1043"><a href="#cb17-1043" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$R = r_1$ if $R^* \leq \gamma_1$</span>
<span id="cb17-1044"><a href="#cb17-1044" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$R = r_2$ if $\gamma_1 &lt; R^* \leq \gamma_2$</span>
<span id="cb17-1045"><a href="#cb17-1045" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$R = r_j$ if $\gamma_{(j-1)} &lt; R^* \leq \gamma_j$</span>
<span id="cb17-1046"><a href="#cb17-1046" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$R = r_m$ if $R^* &gt; \gamma_{(m-1)}$</span>
<span id="cb17-1047"><a href="#cb17-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1048"><a href="#cb17-1048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1049"><a href="#cb17-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1050"><a href="#cb17-1050" aria-hidden="true" tabindex="-1"></a><span class="in">```{r warning = F, message= F, error = F, echo=F}</span></span>
<span id="cb17-1051"><a href="#cb17-1051" aria-hidden="true" tabindex="-1"></a><span class="co"># Campioniamo dati da una distribuzione normale</span></span>
<span id="cb17-1052"><a href="#cb17-1052" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb17-1053"><a href="#cb17-1053" aria-hidden="true" tabindex="-1"></a>data_continua <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="at">mean =</span> <span class="dv">4</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb17-1054"><a href="#cb17-1054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1055"><a href="#cb17-1055" aria-hidden="true" tabindex="-1"></a><span class="co"># Discretizziamo i dati arrotondandoli ai numeri interi più vicini</span></span>
<span id="cb17-1056"><a href="#cb17-1056" aria-hidden="true" tabindex="-1"></a>data_discreti <span class="ot">&lt;-</span> <span class="fu">round</span>(data_continua)</span>
<span id="cb17-1057"><a href="#cb17-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1058"><a href="#cb17-1058" aria-hidden="true" tabindex="-1"></a><span class="co"># Creiamo l&#39;istogramma dei dati discreti con contorni grigi e senza asse Y</span></span>
<span id="cb17-1059"><a href="#cb17-1059" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data_discreti, </span>
<span id="cb17-1060"><a href="#cb17-1060" aria-hidden="true" tabindex="-1"></a>     <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="fu">min</span>(data_discreti) <span class="sc">-</span> <span class="fl">0.5</span>, <span class="fu">max</span>(data_discreti) <span class="sc">+</span> <span class="fl">0.5</span>, <span class="dv">1</span>),  <span class="co"># Intervalli discreti</span></span>
<span id="cb17-1061"><a href="#cb17-1061" aria-hidden="true" tabindex="-1"></a>     <span class="at">prob =</span> <span class="cn">TRUE</span>, </span>
<span id="cb17-1062"><a href="#cb17-1062" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">&quot;white&quot;</span>, </span>
<span id="cb17-1063"><a href="#cb17-1063" aria-hidden="true" tabindex="-1"></a>     <span class="at">border =</span> <span class="st">&quot;grey&quot;</span>, </span>
<span id="cb17-1064"><a href="#cb17-1064" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>, </span>
<span id="cb17-1065"><a href="#cb17-1065" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>, </span>
<span id="cb17-1066"><a href="#cb17-1066" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;&quot;</span>, </span>
<span id="cb17-1067"><a href="#cb17-1067" aria-hidden="true" tabindex="-1"></a>     <span class="at">yaxt =</span> <span class="st">&#39;n&#39;</span>)  <span class="co"># Rimuoviamo l&#39;asse Y</span></span>
<span id="cb17-1068"><a href="#cb17-1068" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1069"><a href="#cb17-1069" aria-hidden="true" tabindex="-1"></a><span class="co"># Sovrapponiamo la curva della distribuzione normale continua</span></span>
<span id="cb17-1070"><a href="#cb17-1070" aria-hidden="true" tabindex="-1"></a>x_vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(data_discreti), <span class="fu">max</span>(data_discreti), <span class="at">length =</span> <span class="dv">100</span>)</span>
<span id="cb17-1071"><a href="#cb17-1071" aria-hidden="true" tabindex="-1"></a>y_vals <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x_vals, <span class="at">mean =</span> <span class="dv">4</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb17-1072"><a href="#cb17-1072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1073"><a href="#cb17-1073" aria-hidden="true" tabindex="-1"></a><span class="co"># Aggiungiamo la curva normale continua al grafico</span></span>
<span id="cb17-1074"><a href="#cb17-1074" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x_vals, y_vals, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb17-1075"><a href="#cb17-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1076"><a href="#cb17-1076" aria-hidden="true" tabindex="-1"></a><span class="co"># Aggiungiamo delle linee verticali per i valori discreti</span></span>
<span id="cb17-1077"><a href="#cb17-1077" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">c</span>(<span class="fl">1.5</span>, <span class="fl">2.5</span>, <span class="fl">3.5</span>, <span class="fl">4.5</span>, <span class="fl">5.5</span>, <span class="fl">6.5</span>), <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lty =</span> <span class="dv">4</span>, <span class="at">lwd =</span> <span class="fl">1.5</span>)</span>
<span id="cb17-1078"><a href="#cb17-1078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1079"><a href="#cb17-1079" aria-hidden="true" tabindex="-1"></a><span class="co"># Aggiungiamo le lettere greche corrispondenti ai valori gamma</span></span>
<span id="cb17-1080"><a href="#cb17-1080" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fu">c</span>(<span class="fl">1.5</span>, <span class="fl">2.5</span>, <span class="fl">3.5</span>, <span class="fl">4.5</span>, <span class="fl">5.5</span>, <span class="fl">6.5</span>),  <span class="co"># Posizioni sull&#39;asse X</span></span>
<span id="cb17-1081"><a href="#cb17-1081" aria-hidden="true" tabindex="-1"></a>     <span class="at">y =</span> <span class="fu">rep</span>(<span class="fl">0.05</span>, <span class="dv">6</span>),  <span class="co"># Altezza sull&#39;asse Y (modifica per posizionare il testo)</span></span>
<span id="cb17-1082"><a href="#cb17-1082" aria-hidden="true" tabindex="-1"></a>     <span class="at">labels =</span> <span class="fu">expression</span>(gamma[<span class="dv">1</span>] <span class="sc">==</span> <span class="fl">1.5</span>, </span>
<span id="cb17-1083"><a href="#cb17-1083" aria-hidden="true" tabindex="-1"></a>                         gamma[<span class="dv">2</span>] <span class="sc">==</span> <span class="fl">2.5</span>, </span>
<span id="cb17-1084"><a href="#cb17-1084" aria-hidden="true" tabindex="-1"></a>                         gamma[<span class="dv">3</span>] <span class="sc">==</span> <span class="fl">3.5</span>, </span>
<span id="cb17-1085"><a href="#cb17-1085" aria-hidden="true" tabindex="-1"></a>                         gamma[<span class="dv">4</span>] <span class="sc">==</span> <span class="fl">4.5</span>, </span>
<span id="cb17-1086"><a href="#cb17-1086" aria-hidden="true" tabindex="-1"></a>                         gamma[<span class="dv">5</span>] <span class="sc">==</span> <span class="fl">5.5</span>, </span>
<span id="cb17-1087"><a href="#cb17-1087" aria-hidden="true" tabindex="-1"></a>                         gamma[<span class="dv">6</span>] <span class="sc">==</span> <span class="fl">6.5</span>), </span>
<span id="cb17-1088"><a href="#cb17-1088" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex =</span> <span class="fl">0.8</span>,  <span class="co"># Dimensione del testo</span></span>
<span id="cb17-1089"><a href="#cb17-1089" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">&quot;black&quot;</span>)  <span class="co"># Colore del testo</span></span>
<span id="cb17-1090"><a href="#cb17-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1091"><a href="#cb17-1091" aria-hidden="true" tabindex="-1"></a><span class="co"># Aggiungiamo gamma_0 = -∞ manualmente usando Unicode per il simbolo di infinito</span></span>
<span id="cb17-1092"><a href="#cb17-1092" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="fl">0.5</span>, <span class="at">y =</span> <span class="fl">0.05</span>, <span class="at">labels =</span> <span class="fu">expression</span>(gamma[<span class="dv">0</span>] <span class="sc">==</span> <span class="st">&quot;-\u221E&quot;</span>), <span class="at">cex =</span> <span class="fl">0.8</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>)</span>
<span id="cb17-1093"><a href="#cb17-1093" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="fl">7.5</span>, <span class="at">y =</span> <span class="fl">0.05</span>, <span class="at">labels =</span> <span class="fu">expression</span>(gamma[<span class="dv">7</span>] <span class="sc">==</span> <span class="st">&quot;+\u221E&quot;</span>), <span class="at">cex =</span> <span class="fl">0.8</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>)</span>
<span id="cb17-1094"><a href="#cb17-1094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1095"><a href="#cb17-1095" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-1096"><a href="#cb17-1096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1097"><a href="#cb17-1097" aria-hidden="true" tabindex="-1"></a>If we assume that the error $\epsilon$ follows a standard logistic distribution, it can be shown that this structure leads directly to the form of the cumulative logit model:</span>
<span id="cb17-1098"><a href="#cb17-1098" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1099"><a href="#cb17-1099" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1100"><a href="#cb17-1100" aria-hidden="true" tabindex="-1"></a>\text{logit}<span class="co">[</span><span class="ot">P \leq r_j | \boldsymbol{X})</span><span class="co">]</span> = (\gamma_j - \beta_0^*) - \beta_1^*X_1 - \dots - \beta_k^*X_k,</span>
<span id="cb17-1101"><a href="#cb17-1101" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1102"><a href="#cb17-1102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1103"><a href="#cb17-1103" aria-hidden="true" tabindex="-1"></a>which clearly matches the cumulative logit model form given in @eq-cumlogit3 if we define the model intercept $\alpha_j = \gamma_j - \beta_0^*$ and the model&#39;s coefficients $\beta_i = -\beta_i^*$.</span>
<span id="cb17-1104"><a href="#cb17-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1105"><a href="#cb17-1105" aria-hidden="true" tabindex="-1"></a>In this latent variable framework, the Proportional Odds assumption means two things:</span>
<span id="cb17-1106"><a href="#cb17-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1107"><a href="#cb17-1107" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>The thresholds on the $R^*$ scale are fixed and do not depend on the predictor variables $X$.</span>
<span id="cb17-1108"><a href="#cb17-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1109"><a href="#cb17-1109" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>The effect of each predictor $X_i$(represented by is simply to shift the entire distribution of the latent variable $R^*$ along the continuous scale. This shift is the same magnitude regardless of where the fixed thresholds $\gamma_j$ are located.</span>
<span id="cb17-1110"><a href="#cb17-1110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1111"><a href="#cb17-1111" aria-hidden="true" tabindex="-1"></a>This parallel shif&quot; of the latent distribution is the reason why the odds ratios for cumulative probabilities are proportional across all thresholds.</span>
<span id="cb17-1112"><a href="#cb17-1112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1113"><a href="#cb17-1113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1114"><a href="#cb17-1114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1115"><a href="#cb17-1115" aria-hidden="true" tabindex="-1"></a><span class="fu">### Testing the Proportional Odds Assumption {.unnumbered .toc-ignore}</span></span>
<span id="cb17-1116"><a href="#cb17-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1117"><a href="#cb17-1117" aria-hidden="true" tabindex="-1"></a>Violating the Proportional Odds assumption can lead to inaccurate conclusions about the effects of the predictors. The most robust and commonly recommended way to test the Proportional Odds assumption with  is by using a Likelihood Ratio Test to compare a constrained model (the PO model) with a more flexible, unconstrained model (where the PO assumption is relaxed for a specific predictor).</span>
<span id="cb17-1118"><a href="#cb17-1118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1119"><a href="#cb17-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1120"><a href="#cb17-1120" aria-hidden="true" tabindex="-1"></a>The <span class="in">`clm()`</span> function from the ordinal package allows you to relax the PO assumption for specific predictors using the <span class="in">`nominal = ~ predictor`</span> argument. This creates a &quot;partial proportional odds&quot; model (also known as a generalized ordinal logit model). We then compare this more complex model (where the assumption is relaxed) to our original, simpler proportional odds model using <span class="in">`anova()`</span>, which performs a Likelihood Ratio Test.</span>
<span id="cb17-1121"><a href="#cb17-1121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1122"><a href="#cb17-1122" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>**Null Hypothesis ($H_0$)**: The Proportional Odds assumption holds for the specified predictor (i.e., its coefficient is constant across all thresholds).</span>
<span id="cb17-1123"><a href="#cb17-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1124"><a href="#cb17-1124" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>**Alternative Hypothesis ($h_1$)**: The Proportional Odds assumption does not hold for the specified predictor (i.e., its coefficient varies across thresholds).</span>
<span id="cb17-1125"><a href="#cb17-1125" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1126"><a href="#cb17-1126" aria-hidden="true" tabindex="-1"></a>Imagine we have an ordinal outcome Response (e.g., &#39;Low&#39;, &#39;Medium&#39;, &#39;High&#39;) and a continuous predictor Experience.</span>
<span id="cb17-1127"><a href="#cb17-1127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1128"><a href="#cb17-1128" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb17-1129"><a href="#cb17-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1130"><a href="#cb17-1130" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb17-1131"><a href="#cb17-1131" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ordinal) </span>
<span id="cb17-1132"><a href="#cb17-1132" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2) </span>
<span id="cb17-1133"><a href="#cb17-1133" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)   </span>
<span id="cb17-1134"><a href="#cb17-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1135"><a href="#cb17-1135" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb17-1136"><a href="#cb17-1136" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb17-1137"><a href="#cb17-1137" aria-hidden="true" tabindex="-1"></a>  <span class="at">Response =</span> <span class="fu">factor</span>(<span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&quot;Low&quot;</span>, <span class="st">&quot;Medium&quot;</span>, <span class="st">&quot;High&quot;</span>), <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>),</span>
<span id="cb17-1138"><a href="#cb17-1138" aria-hidden="true" tabindex="-1"></a>                    <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;Low&quot;</span>, <span class="st">&quot;Medium&quot;</span>, <span class="st">&quot;High&quot;</span>), <span class="at">ordered =</span> <span class="cn">TRUE</span>),</span>
<span id="cb17-1139"><a href="#cb17-1139" aria-hidden="true" tabindex="-1"></a>  <span class="at">Experience =</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">5</span>, <span class="dv">2</span>)</span>
<span id="cb17-1140"><a href="#cb17-1140" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-1141"><a href="#cb17-1141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1142"><a href="#cb17-1142" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a standard Proportional Odds model</span></span>
<span id="cb17-1143"><a href="#cb17-1143" aria-hidden="true" tabindex="-1"></a>po_model_hypo <span class="ot">&lt;-</span> <span class="fu">clm</span>(Response <span class="sc">~</span> Experience, <span class="at">data =</span> data)</span>
<span id="cb17-1144"><a href="#cb17-1144" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(po_model_hypo)</span>
<span id="cb17-1145"><a href="#cb17-1145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1146"><a href="#cb17-1146" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a model where the PO assumption is relaxed for &#39;Experience&#39;</span></span>
<span id="cb17-1147"><a href="#cb17-1147" aria-hidden="true" tabindex="-1"></a>non_po_model_hypo <span class="ot">&lt;-</span> <span class="fu">clm</span>(Response <span class="sc">~</span> Experience, <span class="at">nominal =</span> <span class="sc">~</span> Experience, <span class="at">data =</span> data)</span>
<span id="cb17-1148"><a href="#cb17-1148" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(non_po_model_hypo) </span>
<span id="cb17-1149"><a href="#cb17-1149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1150"><a href="#cb17-1150" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the models using anova()</span></span>
<span id="cb17-1151"><a href="#cb17-1151" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(po_model_hypo, non_po_model_hypo)</span>
<span id="cb17-1152"><a href="#cb17-1152" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-1153"><a href="#cb17-1153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1154"><a href="#cb17-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1155"><a href="#cb17-1155" aria-hidden="true" tabindex="-1"></a>**Interpretation of the results**</span>
<span id="cb17-1156"><a href="#cb17-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1157"><a href="#cb17-1157" aria-hidden="true" tabindex="-1"></a><span class="in">`po_model_hypo`</span> is the Proportional Odds model, where the effect of <span class="in">`Experience`</span> is assumed to be constant across all thresholds.</span>
<span id="cb17-1158"><a href="#cb17-1158" aria-hidden="true" tabindex="-1"></a><span class="in">`non_po_model_hypo`</span> is the generalized ordinal logit model (or partial proportional odds model), where the effect of <span class="in">`Experience`</span> is allowed to vary across the thresholds.</span>
<span id="cb17-1159"><a href="#cb17-1159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1160"><a href="#cb17-1160" aria-hidden="true" tabindex="-1"></a>The AIC is 225.10 for <span class="in">`po_model_hypo`</span> and 227.09 for <span class="in">`non_po_model_hypo`</span>, this already suggest that the simpler model should be preferred.</span>
<span id="cb17-1161"><a href="#cb17-1161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1162"><a href="#cb17-1162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1163"><a href="#cb17-1163" aria-hidden="true" tabindex="-1"></a><span class="in">`LR.stat`</span> (Likelihood Ratio Statistic) is the test statistic for comparing the two nested models. It&#39;s calculated as $2 \cdot (logLik_{unconstrained} −logLik_{constrained})$.</span>
<span id="cb17-1164"><a href="#cb17-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1165"><a href="#cb17-1165" aria-hidden="true" tabindex="-1"></a>In this example, <span class="in">`LR.stat`</span> = 0.0028. This indicates that the unconstrained model doesn&#39;t provide a much better fit than the constrained model.</span>
<span id="cb17-1166"><a href="#cb17-1166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1167"><a href="#cb17-1167" aria-hidden="true" tabindex="-1"></a><span class="in">`Pr(&gt;Chisq)`</span> (p-value) is the p-value associated with the LR.stat.</span>
<span id="cb17-1168"><a href="#cb17-1168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1169"><a href="#cb17-1169" aria-hidden="true" tabindex="-1"></a>Based on this Likelihood Ratio Test, there is no statistically significant evidence to suggest that the Proportional Odds assumption is violated for the Experience predictor in the data. The effect of Experience on the log-odds of cumulative probabilities does not appear to vary significantly across the different thresholds.</span>
<span id="cb17-1170"><a href="#cb17-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1171"><a href="#cb17-1171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1172"><a href="#cb17-1172" aria-hidden="true" tabindex="-1"></a><span class="fu">### Graphical Inspection {.unnumbered .toc-ignore}</span></span>
<span id="cb17-1173"><a href="#cb17-1173" aria-hidden="true" tabindex="-1"></a>While statistically rigorous, formal tests can be overly sensitive, especially in large datasets. A statistically significant p-value might indicate a violation that is numerically very small and practically insignificant. This is where graphical inspection becomes invaluable.</span>
<span id="cb17-1174"><a href="#cb17-1174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1175"><a href="#cb17-1175" aria-hidden="true" tabindex="-1"></a>Graphical inspection provides a visual assessment of whether the coefficients for a given predictor truly remain constant across thresholds. This involves fitting a more flexible model and then plotting the estimated coefficients for each predictor across the different thresholds.</span>
<span id="cb17-1176"><a href="#cb17-1176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1177"><a href="#cb17-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1178"><a href="#cb17-1178" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r} --&gt;</span></span>
<span id="cb17-1179"><a href="#cb17-1179" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Ensure necessary packages are loaded --&gt;</span></span>
<span id="cb17-1180"><a href="#cb17-1180" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- library(ordinal) --&gt;</span></span>
<span id="cb17-1181"><a href="#cb17-1181" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- library(ggplot2) --&gt;</span></span>
<span id="cb17-1182"><a href="#cb17-1182" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- library(tidyr) # For pivot_longer --&gt;</span></span>
<span id="cb17-1183"><a href="#cb17-1183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1184"><a href="#cb17-1184" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Re-create hypothetical data and models for a clean run --&gt;</span></span>
<span id="cb17-1185"><a href="#cb17-1185" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- set.seed(456) --&gt;</span></span>
<span id="cb17-1186"><a href="#cb17-1186" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- hypothetical_data &lt;- data.frame( --&gt;</span></span>
<span id="cb17-1187"><a href="#cb17-1187" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   Response = factor(sample(c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;), 100, replace = TRUE), --&gt;</span></span>
<span id="cb17-1188"><a href="#cb17-1188" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                     levels = c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;), ordered = TRUE), --&gt;</span></span>
<span id="cb17-1189"><a href="#cb17-1189" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   Experience = rnorm(100, 5, 2) --&gt;</span></span>
<span id="cb17-1190"><a href="#cb17-1190" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ) --&gt;</span></span>
<span id="cb17-1191"><a href="#cb17-1191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1192"><a href="#cb17-1192" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- po_model_hypo &lt;- clm(Response ~ Experience, data = hypothetical_data) --&gt;</span></span>
<span id="cb17-1193"><a href="#cb17-1193" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- non_po_model_hypo &lt;- clm(Response ~ Experience, nominal = ~ Experience, data = hypothetical_data) --&gt;</span></span>
<span id="cb17-1194"><a href="#cb17-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1195"><a href="#cb17-1195" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Extract coefficients and SEs from the non-PO model --&gt;</span></span>
<span id="cb17-1196"><a href="#cb17-1196" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- coef_values &lt;- coef(non_po_model_hypo) --&gt;</span></span>
<span id="cb17-1197"><a href="#cb17-1197" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- vcov_matrix &lt;- vcov(non_po_model_hypo) --&gt;</span></span>
<span id="cb17-1198"><a href="#cb17-1198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1199"><a href="#cb17-1199" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Identify the coefficients related to &#39;Experience&#39; that vary by threshold. --&gt;</span></span>
<span id="cb17-1200"><a href="#cb17-1200" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # These typically have names like &#39;Experience:1|2&#39;, &#39;Experience:2|3&#39;, etc. --&gt;</span></span>
<span id="cb17-1201"><a href="#cb17-1201" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # We&#39;ll explicitly filter for these nominal coefficients. --&gt;</span></span>
<span id="cb17-1202"><a href="#cb17-1202" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- nominal_coeffs_names &lt;- names(coef_values)[grep(&quot;Experience:&quot;, names(coef_values))] --&gt;</span></span>
<span id="cb17-1203"><a href="#cb17-1203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1204"><a href="#cb17-1204" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- exp_coeffs &lt;- coef_values[nominal_coeffs_names] --&gt;</span></span>
<span id="cb17-1205"><a href="#cb17-1205" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- exp_ses &lt;- sqrt(diag(vcov_matrix))[nominal_coeffs_names] --&gt;</span></span>
<span id="cb17-1206"><a href="#cb17-1206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1207"><a href="#cb17-1207" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Create a data frame for plotting --&gt;</span></span>
<span id="cb17-1208"><a href="#cb17-1208" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- plot_data_coeffs &lt;- data.frame( --&gt;</span></span>
<span id="cb17-1209"><a href="#cb17-1209" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   Threshold = nominal_coeffs_names, # Use the actual names like Experience:1|2 --&gt;</span></span>
<span id="cb17-1210"><a href="#cb17-1210" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   Estimate = exp_coeffs, --&gt;</span></span>
<span id="cb17-1211"><a href="#cb17-1211" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   SE = exp_ses --&gt;</span></span>
<span id="cb17-1212"><a href="#cb17-1212" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ) --&gt;</span></span>
<span id="cb17-1213"><a href="#cb17-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1214"><a href="#cb17-1214" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Add 95% confidence intervals --&gt;</span></span>
<span id="cb17-1215"><a href="#cb17-1215" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- plot_data_coeffs$Lower &lt;- plot_data_coeffs$Estimate - 1.96 * plot_data_coeffs$SE --&gt;</span></span>
<span id="cb17-1216"><a href="#cb17-1216" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- plot_data_coeffs$Upper &lt;- plot_data_coeffs$Estimate + 1.96 * plot_data_coeffs$SE --&gt;</span></span>
<span id="cb17-1217"><a href="#cb17-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1218"><a href="#cb17-1218" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Add the single PO coefficient for comparison (from po_model_hypo) --&gt;</span></span>
<span id="cb17-1219"><a href="#cb17-1219" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- po_estimate_x &lt;- coef(po_model_hypo)[&quot;Experience&quot;] --&gt;</span></span>
<span id="cb17-1220"><a href="#cb17-1220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1221"><a href="#cb17-1221" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # Ensure Threshold is a factor for correct ordering on the plot --&gt;</span></span>
<span id="cb17-1222"><a href="#cb17-1222" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- plot_data_coeffs$Threshold &lt;- factor(plot_data_coeffs$Threshold, --&gt;</span></span>
<span id="cb17-1223"><a href="#cb17-1223" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--                                      levels = rev(nominal_coeffs_names)) # Reverse for typical plot order --&gt;</span></span>
<span id="cb17-1224"><a href="#cb17-1224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1225"><a href="#cb17-1225" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- # --- Plotting the coefficients across thresholds --- --&gt;</span></span>
<span id="cb17-1226"><a href="#cb17-1226" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ggplot(plot_data_coeffs, aes(x = Threshold, y = Estimate)) + --&gt;</span></span>
<span id="cb17-1227"><a href="#cb17-1227" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   geom_point(size = 3) + --&gt;</span></span>
<span id="cb17-1228"><a href="#cb17-1228" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2) + --&gt;</span></span>
<span id="cb17-1229"><a href="#cb17-1229" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   geom_hline(yintercept = po_estimate_x, linetype = &quot;dashed&quot;, color = &quot;blue&quot;, size = 0.8) + --&gt;</span></span>
<span id="cb17-1230"><a href="#cb17-1230" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   labs( --&gt;</span></span>
<span id="cb17-1231"><a href="#cb17-1231" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     title = &quot;Estimated Coefficients for &#39;Experience&#39; Across Thresholds&quot;, --&gt;</span></span>
<span id="cb17-1232"><a href="#cb17-1232" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     subtitle = &quot;Dashed line is the PO model estimate (assuming constant effect)&quot;, --&gt;</span></span>
<span id="cb17-1233"><a href="#cb17-1233" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     y = &quot;Coefficient Estimate&quot;, --&gt;</span></span>
<span id="cb17-1234"><a href="#cb17-1234" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--     x = &quot;Cumulative Threshold&quot; --&gt;</span></span>
<span id="cb17-1235"><a href="#cb17-1235" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   ) + --&gt;</span></span>
<span id="cb17-1236"><a href="#cb17-1236" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   theme_minimal() + --&gt;</span></span>
<span id="cb17-1237"><a href="#cb17-1237" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--   coord_flip() # Flip coordinates for better readability --&gt;</span></span>
<span id="cb17-1238"><a href="#cb17-1238" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ``` --&gt;</span></span>
<span id="cb17-1239"><a href="#cb17-1239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1240"><a href="#cb17-1240" aria-hidden="true" tabindex="-1"></a><span class="fu">### Violation of the Proportional Odds Assumption {.unnumbered .toc-ignore}</span></span>
<span id="cb17-1241"><a href="#cb17-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1242"><a href="#cb17-1242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1243"><a href="#cb17-1243" aria-hidden="true" tabindex="-1"></a>When the Proportional Odds assumption is violated for a predictor, the effect of that predictor on the cumulative log-odds is not constant across thresholds. Graphically, this means the lines for different cumulative probabilities would not be parallel. Their slopes would differ, meaning the $\beta$ coefficients are not the same for each threshold.</span>
<span id="cb17-1244"><a href="#cb17-1244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1245"><a href="#cb17-1245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1246"><a href="#cb17-1246" aria-hidden="true" tabindex="-1"></a><span class="in">```{r echo = F, warning = F, error = F, message=F}</span></span>
<span id="cb17-1247"><a href="#cb17-1247" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">789</span>)</span>
<span id="cb17-1248"><a href="#cb17-1248" aria-hidden="true" tabindex="-1"></a>n_violation <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb17-1249"><a href="#cb17-1249" aria-hidden="true" tabindex="-1"></a>predictor_z <span class="ot">&lt;-</span> <span class="fu">runif</span>(n_violation, <span class="dv">0</span>, <span class="dv">10</span>) <span class="co"># Our continuous predictor</span></span>
<span id="cb17-1250"><a href="#cb17-1250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1251"><a href="#cb17-1251" aria-hidden="true" tabindex="-1"></a><span class="co"># Define hypothetical thresholds</span></span>
<span id="cb17-1252"><a href="#cb17-1252" aria-hidden="true" tabindex="-1"></a>alpha_1_viol <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span></span>
<span id="cb17-1253"><a href="#cb17-1253" aria-hidden="true" tabindex="-1"></a>alpha_2_viol <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb17-1254"><a href="#cb17-1254" aria-hidden="true" tabindex="-1"></a>alpha_3_viol <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb17-1255"><a href="#cb17-1255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1256"><a href="#cb17-1256" aria-hidden="true" tabindex="-1"></a><span class="co"># Define different beta coefficients for the predictor at each threshold</span></span>
<span id="cb17-1257"><a href="#cb17-1257" aria-hidden="true" tabindex="-1"></a>beta_z_1 <span class="ot">&lt;-</span> <span class="fl">0.8</span> <span class="co"># Stronger effect for lower threshold</span></span>
<span id="cb17-1258"><a href="#cb17-1258" aria-hidden="true" tabindex="-1"></a>beta_z_2 <span class="ot">&lt;-</span> <span class="fl">0.4</span> <span class="co"># Moderate effect for middle threshold</span></span>
<span id="cb17-1259"><a href="#cb17-1259" aria-hidden="true" tabindex="-1"></a>beta_z_3 <span class="ot">&lt;-</span> <span class="fl">0.1</span> <span class="co"># Weaker effect for higher threshold</span></span>
<span id="cb17-1260"><a href="#cb17-1260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1261"><a href="#cb17-1261" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate cumulative log-odds for each observation and each threshold with varying betas</span></span>
<span id="cb17-1262"><a href="#cb17-1262" aria-hidden="true" tabindex="-1"></a>log_odds_1_viol <span class="ot">&lt;-</span> alpha_1_viol <span class="sc">+</span> beta_z_1 <span class="sc">*</span> predictor_z</span>
<span id="cb17-1263"><a href="#cb17-1263" aria-hidden="true" tabindex="-1"></a>log_odds_2_viol <span class="ot">&lt;-</span> alpha_2_viol <span class="sc">+</span> beta_z_2 <span class="sc">*</span> predictor_z</span>
<span id="cb17-1264"><a href="#cb17-1264" aria-hidden="true" tabindex="-1"></a>log_odds_3_viol <span class="ot">&lt;-</span> alpha_3_viol <span class="sc">+</span> beta_z_3 <span class="sc">*</span> predictor_z</span>
<span id="cb17-1265"><a href="#cb17-1265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1266"><a href="#cb17-1266" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine into a data frame for plotting</span></span>
<span id="cb17-1267"><a href="#cb17-1267" aria-hidden="true" tabindex="-1"></a>plot_data_non_po_concept <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb17-1268"><a href="#cb17-1268" aria-hidden="true" tabindex="-1"></a>  <span class="at">predictor_z =</span> predictor_z,</span>
<span id="cb17-1269"><a href="#cb17-1269" aria-hidden="true" tabindex="-1"></a>  <span class="at">Threshold_1 =</span> log_odds_1_viol,</span>
<span id="cb17-1270"><a href="#cb17-1270" aria-hidden="true" tabindex="-1"></a>  <span class="at">Threshold_2 =</span> log_odds_2_viol,</span>
<span id="cb17-1271"><a href="#cb17-1271" aria-hidden="true" tabindex="-1"></a>  <span class="at">Threshold_3 =</span> log_odds_3_viol</span>
<span id="cb17-1272"><a href="#cb17-1272" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-1273"><a href="#cb17-1273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1274"><a href="#cb17-1274" aria-hidden="true" tabindex="-1"></a>plot_data_non_po_concept_long <span class="ot">&lt;-</span> plot_data_non_po_concept <span class="sc">%&gt;%</span></span>
<span id="cb17-1275"><a href="#cb17-1275" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb17-1276"><a href="#cb17-1276" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols =</span> <span class="fu">starts_with</span>(<span class="st">&quot;Threshold_&quot;</span>),</span>
<span id="cb17-1277"><a href="#cb17-1277" aria-hidden="true" tabindex="-1"></a>    <span class="at">names_to =</span> <span class="st">&quot;Cumulative_Log_Odds_Curve&quot;</span>,</span>
<span id="cb17-1278"><a href="#cb17-1278" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_to =</span> <span class="st">&quot;Log_Odds&quot;</span></span>
<span id="cb17-1279"><a href="#cb17-1279" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb17-1280"><a href="#cb17-1280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1281"><a href="#cb17-1281" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the non-parallel log-odds lines</span></span>
<span id="cb17-1282"><a href="#cb17-1282" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plot_data_non_po_concept_long, <span class="fu">aes</span>(<span class="at">x =</span> predictor_z, <span class="at">y =</span> Log_Odds, <span class="at">color =</span> Cumulative_Log_Odds_Curve)) <span class="sc">+</span></span>
<span id="cb17-1283"><a href="#cb17-1283" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">group =</span> Cumulative_Log_Odds_Curve), <span class="at">stat =</span> <span class="st">&quot;smooth&quot;</span>, <span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">formula =</span> y <span class="sc">~</span> x, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span> <span class="co"># Linear fit</span></span>
<span id="cb17-1284"><a href="#cb17-1284" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb17-1285"><a href="#cb17-1285" aria-hidden="true" tabindex="-1"></a>    <span class="co"># title = &quot;Non-Parallel Log-Odds Lines (PO Assumption Violated)&quot;,</span></span>
<span id="cb17-1286"><a href="#cb17-1286" aria-hidden="true" tabindex="-1"></a>    <span class="co"># subtitle = &quot;The effect (slope) of the predictor varies across cumulative thresholds&quot;,</span></span>
<span id="cb17-1287"><a href="#cb17-1287" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Predictor Variable (Z)&quot;</span>,</span>
<span id="cb17-1288"><a href="#cb17-1288" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Cumulative Log-Odds&quot;</span>,</span>
<span id="cb17-1289"><a href="#cb17-1289" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&quot;Cumulative Threshold&quot;</span></span>
<span id="cb17-1290"><a href="#cb17-1290" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb17-1291"><a href="#cb17-1291" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb17-1292"><a href="#cb17-1292" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_brewer</span>(<span class="at">palette =</span> <span class="st">&quot;Set1&quot;</span>, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;P(R &lt;= r1)&quot;</span>, <span class="st">&quot;P(R &lt;= r2)&quot;</span>, <span class="st">&quot;P(R &lt;= r3)&quot;</span>)) <span class="sc">+</span></span>
<span id="cb17-1293"><a href="#cb17-1293" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span>
<span id="cb17-1294"><a href="#cb17-1294" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-1295"><a href="#cb17-1295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1296"><a href="#cb17-1296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1297"><a href="#cb17-1297" aria-hidden="true" tabindex="-1"></a>When the formal tests and especially the graphical inspection indicate a statistically and practically significant violation, it is not possible to proceed with the standard Proportional Odds model, as the coefficient estimates would be biased and their interpretation misleading.</span>
<span id="cb17-1298"><a href="#cb17-1298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1299"><a href="#cb17-1299" aria-hidden="true" tabindex="-1"></a>There are two main alternative models to handle this problem:</span>
<span id="cb17-1300"><a href="#cb17-1300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1301"><a href="#cb17-1301" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Generalized Ordinal Logit Models** (or Partial Proportional Odds Models): are a flexible extension of the proportional odds model. They allow the coefficients of specific predictor variables to vary across the cumulative logit equations (i.e., across the thresholds), while still forcing other predictors (those that do satisfy the Proportional Odds assumption) to have constant effects. When only a subset of coefficients is allowed to vary, it&#39;s specifically called a Partial Proportional Odds (PPO) model. </span>
<span id="cb17-1302"><a href="#cb17-1302" aria-hidden="true" tabindex="-1"></a>Instead of estimating a single $\beta_i$ for a predictor $X_i$, a PPO model estimates a separate $\beta_{ij}$ for each cumulative logit $r_j$.  </span>
<span id="cb17-1303"><a href="#cb17-1303" aria-hidden="true" tabindex="-1"></a>The advantages are:</span>
<span id="cb17-1304"><a href="#cb17-1304" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>*Flexibility*: It directly addresses the violation by allowing coefficients to differ where necessary.</span>
<span id="cb17-1305"><a href="#cb17-1305" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>*Parsimony* (relative to Multinomial): It retains some of the efficiency of the ordinal model. If only a few predictors violate the Proportional Odds assumption, it is possible to estimate fewer parameters than a full multinomial logit model, making it more parsimonious and potentially more stable.</span>
<span id="cb17-1306"><a href="#cb17-1306" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>*Maintains Ordinality*: Crucially, it still respects the inherent ordering of the outcome categories. This means that the interpretations are still about &quot;moving up or down&quot; the ordered scale, but the strength of that effect can differ at various points along the scale.</span>
<span id="cb17-1307"><a href="#cb17-1307" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>*Interpretation*: While more complex than the Proportional Odds model, the interpretation of varying coefficients provides a richer understanding. You might find that a predictor has a strong effect in distinguishing &quot;Low&quot; from &quot;Medium/High&quot; but a much weaker effect in distinguishing &quot;Medium&quot; from &quot;High&quot;.</span>
<span id="cb17-1308"><a href="#cb17-1308" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-1309"><a href="#cb17-1309" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Multinomial Logit Model**: A multinomial (or polytomous) logit model treats the outcome categories as purely nominal (unordered), even if they are inherently ordinal. It fits a separate binary logistic regression model for each category, comparing it to a chosen reference category. Advantages are:</span>
<span id="cb17-1310"><a href="#cb17-1310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1311"><a href="#cb17-1311" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>*No PO Assumption*: It makes no assumption about the effects of predictors being constant across categories; therefore, it automatically handles any PO violation.</span>
<span id="cb17-1312"><a href="#cb17-1312" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>*Maximum Flexibility*: It is the most flexible approach for categorical outcomes, as it allows for completely different effects for each category comparison.</span>
<span id="cb17-1313"><a href="#cb17-1313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1314"><a href="#cb17-1314" aria-hidden="true" tabindex="-1"></a>However, thre are some disadvantages:</span>
<span id="cb17-1315"><a href="#cb17-1315" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>*Loss of Ordinal Information*: This can lead to less precise estimates and interpretations that don&#39;t fully reflect the nature of your outcome. </span>
<span id="cb17-1316"><a href="#cb17-1316" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>*Increased Complexity and Reduced Parsimony*: $(m−1)\cdot k$ coefficients (where $k$ is the number of predictors), which is more than a Proportional Odds model ($k$ predictors) or even a PPO model. This increased number of parameters can lead to:</span>
<span id="cb17-1317"><a href="#cb17-1317" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>*Larger standard errors*: Less statistical power.</span>
<span id="cb17-1318"><a href="#cb17-1318" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>*Difficulty in interpretation*: Interpreting multiple sets of coefficients and odds ratios can be cumbersome.</span>
<span id="cb17-1319"><a href="#cb17-1319" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>*Overfitting*: Especially with smaller sample sizes, estimating too many parameters can lead to models that fit the current data well but generalize poorly.</span>
<span id="cb17-1320"><a href="#cb17-1320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1321"><a href="#cb17-1321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1322"><a href="#cb17-1322" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb17-1323"><a href="#cb17-1323" aria-hidden="true" tabindex="-1"></a> It is crucial to recognize that a statistically significant p-value from a formal test, such as the Likelihood Ratio Test, does not always signify a practically meaningful violation of the Proportional Odds assumption, especially in large datasets where even trivial deviations can be flagged. Therefore, graphical inspection becomes invaluable: if the estimated coefficients for a predictor across thresholds are very similar and their confidence intervals largely overlap (indicating near-parallelism), then despite a statistical rejection, the practical implication of the violation might be minimal, allowing one to retain the more parsimonious standard PO model. Conversely, if coefficients vary widely with little to no overlap in their confidence intervals, indicating both statistical and practical significance, then adopting a more flexible model like a Partial Proportional Odds model or, as a last resort, a Multinomial Logit model, becomes necessary to accurately reflect the data.</span>
<span id="cb17-1324"><a href="#cb17-1324" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-1325"><a href="#cb17-1325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1326"><a href="#cb17-1326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1327"><a href="#cb17-1327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1328"><a href="#cb17-1328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1329"><a href="#cb17-1329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1330"><a href="#cb17-1330" aria-hidden="true" tabindex="-1"></a><span class="fu">## Coefficients interpretation </span></span>
<span id="cb17-1331"><a href="#cb17-1331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1332"><a href="#cb17-1332" aria-hidden="true" tabindex="-1"></a>Consider the effect of changing a single predictor, $X_i$, by one unit, while holding all other predictors constant.</span>
<span id="cb17-1333"><a href="#cb17-1333" aria-hidden="true" tabindex="-1"></a>The change in the cumulative log-odds for a one-unit increase in $X_i$ is simply the coefficient $\beta_i$.</span>
<span id="cb17-1334"><a href="#cb17-1334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1335"><a href="#cb17-1335" aria-hidden="true" tabindex="-1"></a>So, $\beta_i$ is the change in the cumulative log-odds for a one-unit increase in $X_i$, holding other predictors constant.</span>
<span id="cb17-1336"><a href="#cb17-1336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1337"><a href="#cb17-1337" aria-hidden="true" tabindex="-1"></a>To get the Odds Ratio, we exponentiate the coefficient: $OR_i = \text{exp}(\beta_i)$.</span>
<span id="cb17-1338"><a href="#cb17-1338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1339"><a href="#cb17-1339" aria-hidden="true" tabindex="-1"></a>This $OR_i$ is the multiplicative change in the cumulative odds for a one-unit increase in $X_i$.</span>
<span id="cb17-1340"><a href="#cb17-1340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1341"><a href="#cb17-1341" aria-hidden="true" tabindex="-1"></a>For a one-unit increase in the predictor $X_i$, while holding all other predictors constant, the odds of being in category $r_j$ or any category below it, versus being in a category above $r_j$, are multiplied by $\text{exp}(\beta_i)$.</span>
<span id="cb17-1342"><a href="#cb17-1342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1343"><a href="#cb17-1343" aria-hidden="true" tabindex="-1"></a>**Note** Due to the Proportional Odds assumption, this multiplicative effect, $\text{exp}(\beta_i)$, is the same for all $m-1$ thresholds.</span>
<span id="cb17-1344"><a href="#cb17-1344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1345"><a href="#cb17-1345" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If $\beta_i &gt; 0$ (and thus $\text{exp}(\beta_i)&gt;1$): A one-unit increase in $X_i$ increases the cumulative log-odds.</span>
<span id="cb17-1346"><a href="#cb17-1346" aria-hidden="true" tabindex="-1"></a>    This means it increases the odds of being in category $r_j$ or below.\</span>
<span id="cb17-1347"><a href="#cb17-1347" aria-hidden="true" tabindex="-1"></a>    Therefore, a positive $\beta_i$ indicates that higher values of $X_i$ are associated with a greater likelihood of being in the lower (or earlier) categories of the ordinal variable $R$.</span>
<span id="cb17-1348"><a href="#cb17-1348" aria-hidden="true" tabindex="-1"></a>    Equivalently, it&#39;s associated with a lower likelihood of being in the higher categories.</span>
<span id="cb17-1349"><a href="#cb17-1349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1350"><a href="#cb17-1350" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If $\beta_i &lt;0$ (and thus $\text{exp}(\beta_i)&lt;1$): A one-unit increase in $X_i$ decreases the cumulative log-odds.</span>
<span id="cb17-1351"><a href="#cb17-1351" aria-hidden="true" tabindex="-1"></a>    This means it decreases the odds of being in category $r_j$ or below.\</span>
<span id="cb17-1352"><a href="#cb17-1352" aria-hidden="true" tabindex="-1"></a>    Therefore, a negative $\beta_i$ indicates that higher values of $X_i$ are associated with a greater likelihood of being in the higher (or later) categories of the ordinal variable Y.</span>
<span id="cb17-1353"><a href="#cb17-1353" aria-hidden="true" tabindex="-1"></a>    Equivalently, it&#39;s associated with a lower likelihood of being in the lower categories.</span>
<span id="cb17-1354"><a href="#cb17-1354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1355"><a href="#cb17-1355" aria-hidden="true" tabindex="-1"></a><span class="fu">### Connection with the Latent Variable interpretation {.unnumbered .toc-ignore}</span></span>
<span id="cb17-1356"><a href="#cb17-1356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1357"><a href="#cb17-1357" aria-hidden="true" tabindex="-1"></a>In the latent variable model $R^* = \beta_0^* + \beta_1^*X_1 + \dots + \beta_k^*X_k + \epsilon$, a positive $\beta_i^*$ means that increasing $X_i$ increases the value of the latent variable $R^*$.</span>
<span id="cb17-1358"><a href="#cb17-1358" aria-hidden="true" tabindex="-1"></a>Since higher values of $R^*$ correspond to higher ordinal categories, $\beta_i&gt;0$ implies a shift towards higher categories.</span>
<span id="cb17-1359"><a href="#cb17-1359" aria-hidden="true" tabindex="-1"></a>As we saw in the derivation, the cumulative logit model coefficient $\beta_I$ (for $P(Y \leq r_j)$) is typically $-\beta_i^*$.</span>
<span id="cb17-1360"><a href="#cb17-1360" aria-hidden="true" tabindex="-1"></a>So, if $\beta_i^*&gt;0$, then $\beta_i&lt;0$ in the cumulative logit model, which is associated with higher ordinal categories.</span>
<span id="cb17-1361"><a href="#cb17-1361" aria-hidden="true" tabindex="-1"></a>This confirms the consistency between the two interpretations, although the sign convention can be tricky.</span>
<span id="cb17-1362"><a href="#cb17-1362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1363"><a href="#cb17-1363" aria-hidden="true" tabindex="-1"></a>To avoid confusion, it is generally easiest and most standard to interpret the results directly from the estimated coefficients ($\beta_i$) and Odds Ratios ($\text{exp}(\beta_i)$) from the cumulative logit model output:</span>
<span id="cb17-1364"><a href="#cb17-1364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1365"><a href="#cb17-1365" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\text{exp}(\beta_i)&gt;1$: Higher values of $X_i$ are associated with increased odds of being in a lower category (or equivalently, decreased odds of being in a higher category).</span>
<span id="cb17-1366"><a href="#cb17-1366" aria-hidden="true" tabindex="-1"></a>    The shift is towards the beginning of the ordered scale.</span>
<span id="cb17-1367"><a href="#cb17-1367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1368"><a href="#cb17-1368" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\text{exp}(\beta_i)&lt;1$: Higher values of $X_i$ are associated with decreased odds of being in a lower category (or equivalently, increased odds of being in a higher category).</span>
<span id="cb17-1369"><a href="#cb17-1369" aria-hidden="true" tabindex="-1"></a>    The shift is towards the end of the ordered scale.</span>
<span id="cb17-1370"><a href="#cb17-1370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1371"><a href="#cb17-1371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1372"><a href="#cb17-1372" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Including and Interpreting Qualitative Predictors  {.unnumbered .toc-ignore}</span></span>
<span id="cb17-1373"><a href="#cb17-1373" aria-hidden="true" tabindex="-1"></a>Categorical predictors (nominal or ordinal, when used as predictors) cannot be entered directly into the model as single numbers. Instead, we use dummy variables. For a categorical predictor with $m$ categories, $m−1$ dummy variables will be created. One category is designated as the &quot;reference category&quot;. This category does not get its own dummy variable; its effect is absorbed into the intercept ($\alpha_j$). All other categories are then compared to this reference category.</span>
<span id="cb17-1374"><a href="#cb17-1374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1375"><a href="#cb17-1375" aria-hidden="true" tabindex="-1"></a>Choice Considerations:</span>
<span id="cb17-1376"><a href="#cb17-1376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1377"><a href="#cb17-1377" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>Clinical/Logical Baseline: a naturally occurring baseline (e.g., &quot;No exposure,&quot; &quot;Placebo group,&quot; &quot;Male gender&quot; if female is the group of interest).</span>
<span id="cb17-1378"><a href="#cb17-1378" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1379"><a href="#cb17-1379" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>Largest Category: often chosen for statistical stability, as there&#39;s more data for comparison.</span>
<span id="cb17-1380"><a href="#cb17-1380" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1381"><a href="#cb17-1381" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>First or Last Category: convenient for software defaults.</span>
<span id="cb17-1382"><a href="#cb17-1382" aria-hidden="true" tabindex="-1"></a>Category of Primary Interest: if you want to compare all other groups to a specific group.</span>
<span id="cb17-1383"><a href="#cb17-1383" aria-hidden="true" tabindex="-1"></a>Example: Gender Predictor (Male, Female)</span>
<span id="cb17-1384"><a href="#cb17-1384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1385"><a href="#cb17-1385" aria-hidden="true" tabindex="-1"></a>Let&#39;s assume &quot;Female&quot; is the reference category, and the ordinal dependent variable is &quot;Self-Rated Health&quot; (1=Poor to 5=Excellent). We create one dummy variable for &quot;Male&quot;.</span>
<span id="cb17-1386"><a href="#cb17-1386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1387"><a href="#cb17-1387" aria-hidden="true" tabindex="-1"></a>$X_{\text{male}}=1$ if Gender = Male</span>
<span id="cb17-1388"><a href="#cb17-1388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1389"><a href="#cb17-1389" aria-hidden="true" tabindex="-1"></a>$X_{\text{male}}=0$ if Gender = Female</span>
<span id="cb17-1390"><a href="#cb17-1390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1391"><a href="#cb17-1391" aria-hidden="true" tabindex="-1"></a>The proportional odds model incorporating Gender would look like:</span>
<span id="cb17-1392"><a href="#cb17-1392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1393"><a href="#cb17-1393" aria-hidden="true" tabindex="-1"></a>$$\text{logit}<span class="co">[</span><span class="ot">P(R\leq r_j∣Gender,Other Predictors)</span><span class="co">]</span> = \alpha_j + \beta_{male}X_{male} + \beta_{OthPred}X_{OthPred} $$</span>
<span id="cb17-1394"><a href="#cb17-1394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1395"><a href="#cb17-1395" aria-hidden="true" tabindex="-1"></a>The coefficient for a dummy variable represents the difference in the cumulative log-odds between the category represented by the dummy variable and the reference category, holding all other predictors constant.</span>
<span id="cb17-1396"><a href="#cb17-1396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1397"><a href="#cb17-1397" aria-hidden="true" tabindex="-1"></a>The Odds Ratio for a dummy variable is $e^{\beta_{\text{dummy}}}$. This Odds Ratio represents the ratio of the odds of being in a lower outcome category for the dummy variable group compared to the reference group, holding other predictors constant.</span>
<span id="cb17-1398"><a href="#cb17-1398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1399"><a href="#cb17-1399" aria-hidden="true" tabindex="-1"></a>Example: Gender Predictor (Male, Female) for Self-Rated Health</span>
<span id="cb17-1400"><a href="#cb17-1400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1401"><a href="#cb17-1401" aria-hidden="true" tabindex="-1"></a>Let&#39;s continue with &quot;Self-Rated Health&quot; (1=Poor to 5=Excellent).</span>
<span id="cb17-1402"><a href="#cb17-1402" aria-hidden="true" tabindex="-1"></a>Assume &quot;Female&quot; is the reference category.</span>
<span id="cb17-1403"><a href="#cb17-1403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1404"><a href="#cb17-1404" aria-hidden="true" tabindex="-1"></a>In our example, keeping Female as the reference category, if the estimated $\beta_{male}$ is 0.4, the Odds Ratio for Male would be $e^{0.4}\approx 1.49$.</span>
<span id="cb17-1405"><a href="#cb17-1405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1406"><a href="#cb17-1406" aria-hidden="true" tabindex="-1"></a>Interpretation:</span>
<span id="cb17-1407"><a href="#cb17-1407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1408"><a href="#cb17-1408" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>Coefficient ($\beta_{male}=0.4$): Males have, on average, 0.4 units higher cumulative log-odds of being in a lower self-rated health category (e.g., Poor, Fair, Good, Very Good) compared to females, holding other predictors constant.</span>
<span id="cb17-1409"><a href="#cb17-1409" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1410"><a href="#cb17-1410" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>Odds Ratio ($OR_{male}=1.49): The odds of a male reporting &quot;Poor or Fair or Good or Very Good Health&quot; vs. &quot;Excellent Health&quot; are 1.49 times the odds for a female, holding all other predictors constant. Similarly, the odds of a male reporting &quot;Poor or Fair or Good Health&quot; vs. &quot;Very Good or Excellent Health&quot; are 1.49 times the odds for a female, and so on, across all cumulative splits.</span>
<span id="cb17-1411"><a href="#cb17-1411" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1412"><a href="#cb17-1412" aria-hidden="true" tabindex="-1"></a>In simpler terms, males have a higher odds of being in the less healthy (lower) categories of self-rated health compared to females. This effect is assumed to be consistent across the entire range of health categories.</span>
<span id="cb17-1413"><a href="#cb17-1413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1414"><a href="#cb17-1414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1415"><a href="#cb17-1415" aria-hidden="true" tabindex="-1"></a><span class="fu">### Inference on Parameters {.unnumbered .toc-ignore}</span></span>
<span id="cb17-1416"><a href="#cb17-1416" aria-hidden="true" tabindex="-1"></a>Once the model is fitted using Maximum Likelihood Estimation, it is necessary to understand the statistical significance and precision of the parameter estimates. </span>
<span id="cb17-1417"><a href="#cb17-1417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1418"><a href="#cb17-1418" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Significance Tests for Individual Predictors {.unnumbered .toc-ignore}</span></span>
<span id="cb17-1419"><a href="#cb17-1419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1420"><a href="#cb17-1420" aria-hidden="true" tabindex="-1"></a>To determine if an individual predictor variable has a statistically significant effect on the ordinal outcome, most statistical software packages provide a Wald Test for each predictor.</span>
<span id="cb17-1421"><a href="#cb17-1421" aria-hidden="true" tabindex="-1"></a>The Wald test calculates a z-statistic for each coefficient: $Z= \frac{Estimate}{Std Error}$. </span>
<span id="cb17-1422"><a href="#cb17-1422" aria-hidden="true" tabindex="-1"></a>This z-statistic is then squared to get $\chi^2$ statistic with 1 degree of freedom: $Wald\chi^2 = Z^2$.  </span>
<span id="cb17-1423"><a href="#cb17-1423" aria-hidden="true" tabindex="-1"></a>A p-value is then calculated based on this $\chi^2$ statistic. The *Null Hypothesis* ($H_0$) is that the coefficient for this predictor is zero (i.e., the predictor has no effect on the cumulative log-odds). The *Alternative Hypothesis* ($H_1$) is that the coefficient for this predictor is not zero (i.e., the predictor has a significant effect).  </span>
<span id="cb17-1424"><a href="#cb17-1424" aria-hidden="true" tabindex="-1"></a>If the p-value $(Pr(&gt;|z|))$ is small (typically less than 0.05), the null hypothesis is rejected. This suggests that the predictor has a statistically significant effect on the ordinal outcome.</span>
<span id="cb17-1425"><a href="#cb17-1425" aria-hidden="true" tabindex="-1"></a>If the p-value is large, we fail to reject the null hypothesis. There&#39;s insufficient evidence to conclude that the predictor has a significant effect.</span>
<span id="cb17-1426"><a href="#cb17-1426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1427"><a href="#cb17-1427" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Confidence Intervals for the coefficients and the Odds Ratios {.unnumbered .toc-ignore}</span></span>
<span id="cb17-1428"><a href="#cb17-1428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1429"><a href="#cb17-1429" aria-hidden="true" tabindex="-1"></a>While p-values give about statistical significance, confidence intervals (CIs) provide a range of plausible values for the true population parameter, giving information about the precision of our estimates.  </span>
<span id="cb17-1430"><a href="#cb17-1430" aria-hidden="true" tabindex="-1"></a>Interpretation for coefficients ($\beta$): A 95% CI for a coefficient means that if we were to repeat the study many times, 95% of the calculated CIs would contain the true population coefficient. If a CI for $\beta$ does not include 0, then the coefficient is statistically significant at the corresponding alpha level (e.g., 0.05 for a 95% CI).  </span>
<span id="cb17-1431"><a href="#cb17-1431" aria-hidden="true" tabindex="-1"></a>Interpretation for Odds Ratios ($exp^\beta$)):  A 95% CI for an OR means that we are 95% confident that the true population OR lies within this range.  If a CI for an OR does not include 1, then the effect is statistically significant.  </span>
<span id="cb17-1432"><a href="#cb17-1432" aria-hidden="true" tabindex="-1"></a>If the CI is entirely above 1, the predictor significantly increases the odds of a lower outcome.  </span>
<span id="cb17-1433"><a href="#cb17-1433" aria-hidden="true" tabindex="-1"></a>If the CI is entirely below 1, the predictor significantly decreases the odds of a lower outcome (i.e., increases the odds of a higher outcome).</span>
<span id="cb17-1434"><a href="#cb17-1434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1435"><a href="#cb17-1435" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Evaluating Model Fit and Performance {.unnumbered .toc-ignore}</span></span>
<span id="cb17-1436"><a href="#cb17-1436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1437"><a href="#cb17-1437" aria-hidden="true" tabindex="-1"></a>There are several statistics to evaluate the Goodness of Fit of a Proportional Odds Model.</span>
<span id="cb17-1438"><a href="#cb17-1438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1439"><a href="#cb17-1439" aria-hidden="true" tabindex="-1"></a>In linear regression, the $R^2$ is commonly used to describe the proportion of variance in the dependent variable explained by the independent variables. However, for ordinal logistic regression (and other generalized linear models), the concept of explained variance is more complex, and the traditional $R^2$ is not appropriate because the model relies on a non-linear link function.  </span>
<span id="cb17-1440"><a href="#cb17-1440" aria-hidden="true" tabindex="-1"></a>Instead, **Pseudo R-squared** measures are commonly used and they attempt to provide an analogous quantification of how well the model fits the data, or how much variance it &quot;explains&quot;, relative to a null model.  </span>
<span id="cb17-1441"><a href="#cb17-1441" aria-hidden="true" tabindex="-1"></a>They typically compare the log-likelihood of the fitted model ($L_{model}$) to the log-likelihood of a null (intercept-only) model ($L_{null}$).  </span>
<span id="cb17-1442"><a href="#cb17-1442" aria-hidden="true" tabindex="-1"></a>Common types of Pseudo R-squared include:</span>
<span id="cb17-1443"><a href="#cb17-1443" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>McFadden&#39;s $R^2$: $1−\Big(\frac{L_{model}}{L_{null}}\Big)$</span>
<span id="cb17-1444"><a href="#cb17-1444" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-1445"><a href="#cb17-1445" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>Cox &amp; Snell&#39;s $R^2$: $1−\Big(\frac{L_{model}}{L_{null}}\Big)^{\frac{2}{n}}$</span>
<span id="cb17-1446"><a href="#cb17-1446" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1447"><a href="#cb17-1447" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1448"><a href="#cb17-1448" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb17-1449"><a href="#cb17-1449" aria-hidden="true" tabindex="-1"></a> Do NOT compare directly to linear regression $R^2$: Pseudo R-squared values are typically much lower than $R^2$ values from linear regression models, even for models that fit the data very well. A McFadden&#39;s $R^2$ of 0.20 might be considered very good in an ordinal logistic regression context, whereas a linear $R^2$ of 0.20 would often be considered weak.</span>
<span id="cb17-1450"><a href="#cb17-1450" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-1451"><a href="#cb17-1451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1452"><a href="#cb17-1452" aria-hidden="true" tabindex="-1"></a>Another widely used statistics is the **Likelihood Ratio Test**, which is used for comparing two nested models: the likelihood of a simpler model (the null hypothesis model) to the likelihood of a more complex model (the alternative hypothesis model) that contains all the parameters of the simpler model plus some additional parameters. If the more complex model significantly improves the likelihood, it suggests that the additional parameters are meaningful.</span>
<span id="cb17-1453"><a href="#cb17-1453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1454"><a href="#cb17-1454" aria-hidden="true" tabindex="-1"></a>Let $L_{restricted}$ be the maximum likelihood of the simpler (nested) model, and L </span>
<span id="cb17-1455"><a href="#cb17-1455" aria-hidden="true" tabindex="-1"></a>$L_{full}$ be the maximum likelihood of the more complex (full) model.</span>
<span id="cb17-1456"><a href="#cb17-1456" aria-hidden="true" tabindex="-1"></a>The likelihood ratio test statistic ($\Lambda$) is:</span>
<span id="cb17-1457"><a href="#cb17-1457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1458"><a href="#cb17-1458" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1459"><a href="#cb17-1459" aria-hidden="true" tabindex="-1"></a>\Lambda = - 2 \cdot \log \Bigg(\frac{L_{restricted}}{L_{full}}\Bigg)</span>
<span id="cb17-1460"><a href="#cb17-1460" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1461"><a href="#cb17-1461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1462"><a href="#cb17-1462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1463"><a href="#cb17-1463" aria-hidden="true" tabindex="-1"></a>Which simplifies to (due to properties of logarithms):</span>
<span id="cb17-1464"><a href="#cb17-1464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1465"><a href="#cb17-1465" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1466"><a href="#cb17-1466" aria-hidden="true" tabindex="-1"></a>\Lambda = -2 \cdot <span class="co">[</span><span class="ot">\log(L_{restricted})-\log(L_{full})</span><span class="co">]</span></span>
<span id="cb17-1467"><a href="#cb17-1467" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1468"><a href="#cb17-1468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1469"><a href="#cb17-1469" aria-hidden="true" tabindex="-1"></a>The Null Hypothesis ($H_0$) of this test is that the additional parameters in the full model do not significantly improve the fit, so the simpler model is enough. The Alternative Hypothesis ($H_1$) is that the more complex model provides a significantly better fit.</span>
<span id="cb17-1470"><a href="#cb17-1470" aria-hidden="true" tabindex="-1"></a>Under the null hypothesis, $\Lambda$ asymptotically follows a chi-squared distribution with degrees of freedom equal to the difference in the number of parameters between the two models.  </span>
<span id="cb17-1471"><a href="#cb17-1471" aria-hidden="true" tabindex="-1"></a>A large $\Lambda$ value (and small p-value) indicates that the more complex model fits the data significantly better than the simpler model, leading to rejection of $H_0$.</span>
<span id="cb17-1472"><a href="#cb17-1472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1473"><a href="#cb17-1473" aria-hidden="true" tabindex="-1"></a>**Information criteria** provide a way to balance model fit with model complexity. They are particularly useful for comparing non-nested models or when there are multiple competing models. Lower values generally indicate a better model. The goal is to find a model that explains the data well without being overly complex.</span>
<span id="cb17-1474"><a href="#cb17-1474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1475"><a href="#cb17-1475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1476"><a href="#cb17-1476" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>AIC = $-2 \log(L_{model})+2k$  </span>
<span id="cb17-1477"><a href="#cb17-1477" aria-hidden="true" tabindex="-1"></a> where</span>
<span id="cb17-1478"><a href="#cb17-1478" aria-hidden="true" tabindex="-1"></a><span class="ss">   * </span>$L_{model}$ is the maximum likelihood of the fitted model</span>
<span id="cb17-1479"><a href="#cb17-1479" aria-hidden="true" tabindex="-1"></a><span class="ss">   * </span>$k$ is the is the number of parameters in the model,including the intercept and any cut-points in ordinal regression</span>
<span id="cb17-1480"><a href="#cb17-1480" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb17-1481"><a href="#cb17-1481" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb17-1482"><a href="#cb17-1482" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>BIC = $-2 \log(L_{model})+k\log(n)$  </span>
<span id="cb17-1483"><a href="#cb17-1483" aria-hidden="true" tabindex="-1"></a> where</span>
<span id="cb17-1484"><a href="#cb17-1484" aria-hidden="true" tabindex="-1"></a><span class="ss">   * </span>$L_{model}$ is the maximum likelihood of the fitted model</span>
<span id="cb17-1485"><a href="#cb17-1485" aria-hidden="true" tabindex="-1"></a><span class="ss">   * </span>$k$ is the is the number of parameters in the model,including the intercept and any cut-points in ordinal regression</span>
<span id="cb17-1486"><a href="#cb17-1486" aria-hidden="true" tabindex="-1"></a><span class="ss">   * </span>$n$ is the sample size</span>
<span id="cb17-1487"><a href="#cb17-1487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1488"><a href="#cb17-1488" aria-hidden="true" tabindex="-1"></a>AIC tends to favor more complex models and is generally better for prediction accuracy.</span>
<span id="cb17-1489"><a href="#cb17-1489" aria-hidden="true" tabindex="-1"></a>BIC tends to favor simpler, more parsimonious models and is often preferred for model selection when the goal is to identify the &quot;true&quot; underlying model.</span>
<span id="cb17-1490"><a href="#cb17-1490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1491"><a href="#cb17-1491" aria-hidden="true" tabindex="-1"></a><span class="fu">## Beyond the Proportional Odds Logit Model</span></span>
<span id="cb17-1492"><a href="#cb17-1492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1493"><a href="#cb17-1493" aria-hidden="true" tabindex="-1"></a>The Proportional Odds Model using the logit link function is the most common and often the default choice for analyzing ordinal data due to its interpretability (log-odds) and computational stability. However, the Proportional Odds Model is just one member of a broader family of models for ordinal outcomes. The specific choice of model can influence the interpretation and the fit to the data. Several alternatives exist.</span>
<span id="cb17-1494"><a href="#cb17-1494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1495"><a href="#cb17-1495" aria-hidden="true" tabindex="-1"></a><span class="fu">### Alternative Link Functions for Cumulative Models</span></span>
<span id="cb17-1496"><a href="#cb17-1496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1497"><a href="#cb17-1497" aria-hidden="true" tabindex="-1"></a>In a Proportional Odds Model, the &quot;link function&quot; transforms the cumulative probabilities to a linear scale, where they are modeled by your predictors.</span>
<span id="cb17-1498"><a href="#cb17-1498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1499"><a href="#cb17-1499" aria-hidden="true" tabindex="-1"></a>The general form of a cumulative model is:</span>
<span id="cb17-1500"><a href="#cb17-1500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1501"><a href="#cb17-1501" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1502"><a href="#cb17-1502" aria-hidden="true" tabindex="-1"></a>g<span class="co">[</span><span class="ot">P(R \leq r_j)</span><span class="co">]</span> = \alpha_j - \boldsymbol{\beta}^T\boldsymbol{X}</span>
<span id="cb17-1503"><a href="#cb17-1503" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1504"><a href="#cb17-1504" aria-hidden="true" tabindex="-1"></a>where</span>
<span id="cb17-1505"><a href="#cb17-1505" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>$P(R \leq r_j)$ is the cumulative probability of being in category $j$ or lower</span>
<span id="cb17-1506"><a href="#cb17-1506" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>$g(\cdot)$ is the link function</span>
<span id="cb17-1507"><a href="#cb17-1507" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>$\alpha_j$ are the category-specific intercepts</span>
<span id="cb17-1508"><a href="#cb17-1508" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>$\boldsymbol{\beta}$ is the vector of regression coefficients for the predictors</span>
<span id="cb17-1509"><a href="#cb17-1509" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>$\boldsymbol{X}$ is the vector of predictor variables</span>
<span id="cb17-1510"><a href="#cb17-1510" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1511"><a href="#cb17-1511" aria-hidden="true" tabindex="-1"></a> The link function can be a logit function, as shown previously, but it may be another function.</span>
<span id="cb17-1512"><a href="#cb17-1512" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1513"><a href="#cb17-1513" aria-hidden="true" tabindex="-1"></a> **Probit Link**</span>
<span id="cb17-1514"><a href="#cb17-1514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1515"><a href="#cb17-1515" aria-hidden="true" tabindex="-1"></a>The probit link uses the inverse of the standard normal cumulative distribution function ($\Phi^{-1}$) and it models the cumulative probabilities on a scale that corresponds to the normal distribution</span>
<span id="cb17-1516"><a href="#cb17-1516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1517"><a href="#cb17-1517" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1518"><a href="#cb17-1518" aria-hidden="true" tabindex="-1"></a>\text{probit}<span class="co">[</span><span class="ot">P(R\leq r_j)</span><span class="co">]</span> = \Phi^{-1}<span class="co">[</span><span class="ot">P(R\leq r_j)</span><span class="co">]</span> =  \alpha_j - \boldsymbol{\beta}^T\boldsymbol{X}</span>
<span id="cb17-1519"><a href="#cb17-1519" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1520"><a href="#cb17-1520" aria-hidden="true" tabindex="-1"></a>The coefficients are interpreted in terms of standard deviation units of the underlying latent normal variable. A one-unit increase in $X_k$ leads to a $\beta_k$ standard deviation change in the latent variable. They don&#39;t have the direct odds ratio interpretation of the logit model.</span>
<span id="cb17-1521"><a href="#cb17-1521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1522"><a href="#cb17-1522" aria-hidden="true" tabindex="-1"></a>This link function is often preferred when there&#39;s a theoretical belief that the underlying continuous variable driving the ordinal outcome is normally distributed. </span>
<span id="cb17-1523"><a href="#cb17-1523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1524"><a href="#cb17-1524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1525"><a href="#cb17-1525" aria-hidden="true" tabindex="-1"></a>**Log-log Link**</span>
<span id="cb17-1526"><a href="#cb17-1526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1527"><a href="#cb17-1527" aria-hidden="true" tabindex="-1"></a>The Log-Log link is defined as follows:</span>
<span id="cb17-1528"><a href="#cb17-1528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1529"><a href="#cb17-1529" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1530"><a href="#cb17-1530" aria-hidden="true" tabindex="-1"></a>\text{loglog}<span class="co">[</span><span class="ot">P(R\leq r_j)</span><span class="co">]</span> =  \log(-\log(P(R\leq r_j))) =  \alpha_j - \boldsymbol{\beta}^T\boldsymbol{X}</span>
<span id="cb17-1531"><a href="#cb17-1531" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1532"><a href="#cb17-1532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1533"><a href="#cb17-1533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1534"><a href="#cb17-1534" aria-hidden="true" tabindex="-1"></a>This link is used when the probability of the lowest category is expected to decrease very quickly, or when the process leading to higher categories accelerates rapidly. </span>
<span id="cb17-1535"><a href="#cb17-1535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1536"><a href="#cb17-1536" aria-hidden="true" tabindex="-1"></a>The interpretation is less straightforward than logit. It&#39;s more sensitive to changes in the upper tail of the probability distribution. It implies that the probability of being in a lower category decreases rapidly.</span>
<span id="cb17-1537"><a href="#cb17-1537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1538"><a href="#cb17-1538" aria-hidden="true" tabindex="-1"></a><span class="fu">## Alternative Model Structures </span></span>
<span id="cb17-1539"><a href="#cb17-1539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1540"><a href="#cb17-1540" aria-hidden="true" tabindex="-1"></a>Beyond altering the link function for cumulative probabilities, it is possible to change what probabilities the model is trying to explain.</span>
<span id="cb17-1541"><a href="#cb17-1541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1542"><a href="#cb17-1542" aria-hidden="true" tabindex="-1"></a>**Adjacent Categories Logit Model**</span>
<span id="cb17-1543"><a href="#cb17-1543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1544"><a href="#cb17-1544" aria-hidden="true" tabindex="-1"></a>Instead of modeling cumulative probabilities, the adjacent categories model focuses on the log-odds of being in category $r_j$ versus the next adjacent category $r_{j+1}$:</span>
<span id="cb17-1545"><a href="#cb17-1545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1546"><a href="#cb17-1546" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1547"><a href="#cb17-1547" aria-hidden="true" tabindex="-1"></a>\log \Bigg(\frac{P(R = r_j)}{P(R = r_{j+1})}\Bigg) = \alpha_j - \boldsymbol{\beta}^T\boldsymbol{X} \qquad \text{for} \qquad j = 1,\dots,m-1</span>
<span id="cb17-1548"><a href="#cb17-1548" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1549"><a href="#cb17-1549" aria-hidden="true" tabindex="-1"></a> In this model, the coefficients are not constrained to be the same across all adjacent log-odds comparisons. This means it does not assume the proportional odds assumption. Each $\alpha_j$ is a separate intercept for that specific adjacent comparison, and each $\beta_j$  is a separate vector of coefficients. So, for each pair of adjacent categories $j$ and $j+1$, $\text{exp}(\beta_k)$ is the odds ratio of being in category $j$ versus $j+1$ for a one-unit change in $X_k$. </span>
<span id="cb17-1550"><a href="#cb17-1550" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1551"><a href="#cb17-1551" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1552"><a href="#cb17-1552" aria-hidden="true" tabindex="-1"></a> The advantage of this model is that it does not impose the proportional odds assumption, so it is more flexible compared to the Proportional Odds Model. However, it leads to the estimation of $m-1$ sets of predictors which are many more parameters compared to the Proportional Odds Model; this can lead ot larger standard errors and require larger sample sizes.</span>
<span id="cb17-1553"><a href="#cb17-1553" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1554"><a href="#cb17-1554" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1555"><a href="#cb17-1555" aria-hidden="true" tabindex="-1"></a>**Continuation Ratio Logit Model**</span>
<span id="cb17-1556"><a href="#cb17-1556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1557"><a href="#cb17-1557" aria-hidden="true" tabindex="-1"></a>This model focuses on the log-odds of being in category $j$ versus being in a higher category, given that the outcome is at least $j$. It&#39;s a sequential modeling approach.</span>
<span id="cb17-1558"><a href="#cb17-1558" aria-hidden="true" tabindex="-1"></a>The model is expressed as:</span>
<span id="cb17-1559"><a href="#cb17-1559" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb17-1560"><a href="#cb17-1560" aria-hidden="true" tabindex="-1"></a>\log\left(\frac{P(R = r_j \mid R \ge r_j)}{P(R &gt; r_j \mid R \ge r_j)}\right) = \alpha_j - \boldsymbol{\beta}_j^T \mathbf{X} \quad \text{for } j=1, \dots, m-1 </span>
<span id="cb17-1561"><a href="#cb17-1561" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1562"><a href="#cb17-1562" aria-hidden="true" tabindex="-1"></a>Where:</span>
<span id="cb17-1563"><a href="#cb17-1563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1564"><a href="#cb17-1564" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$P(Y = j \mid Y \ge j)$ is the conditional probability of observing outcome category $j$, given that the outcome is in category $j$ or higher.</span>
<span id="cb17-1565"><a href="#cb17-1565" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$P(Y &gt; j \mid Y \ge j)$ is the conditional probability of observing an outcome category higher than $j$, given that the outcome is in category $j$ or higher.</span>
<span id="cb17-1566"><a href="#cb17-1566" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$\alpha_j$ is the category-specific intercept for the $j$-th comparison.</span>
<span id="cb17-1567"><a href="#cb17-1567" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$\boldsymbol{\beta}_j$ is the vector of regression coefficients for the predictors $\mathbf{x}$ for the $j$-th comparison.</span>
<span id="cb17-1568"><a href="#cb17-1568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1569"><a href="#cb17-1569" aria-hidden="true" tabindex="-1"></a>The exponential of a coefficient, $\exp(\beta_{jk})$, represents the odds ratio of observing category $j$ versus observing a category higher than $j$, given that the outcome is at least $j$, for a one-unit increase in predictor $x_k$. Crucially, the coefficients $\boldsymbol{\beta}_j$ can vary across these sequential comparisons (i.e., for different values of $j$). This means the effect of a predictor might differ depending on which step of the ordinal scale is examined.</span>
<span id="cb17-1570"><a href="#cb17-1570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1571"><a href="#cb17-1571" aria-hidden="true" tabindex="-1"></a>Similar to the adjacent categories model, the continuation ratio model typically does not assume proportional odds. This means it does not constrain the $\boldsymbol{\beta}$ coefficients to be constant across all sequential comparisons. However, a &quot;proportional odds&quot; variant can be imposed on the continuation ratios by forcing $\boldsymbol{\beta}$ to be constant across all $j$.</span>
<span id="cb17-1572"><a href="#cb17-1572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1573"><a href="#cb17-1573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1574"><a href="#cb17-1574" aria-hidden="true" tabindex="-1"></a>This model is especially suited for situations where the ordinal categories represent a natural progression or a series of choices. Common applications include:</span>
<span id="cb17-1575"><a href="#cb17-1575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1576"><a href="#cb17-1576" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>**Educational Attainment**: Modeling the odds of graduating from high school versus continuing to college, then the odds of completing college versus pursuing graduate studies, and so on.</span>
<span id="cb17-1577"><a href="#cb17-1577" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-1578"><a href="#cb17-1578" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>**Disease Progression**: Analyzing the odds of a patient staying at their current disease stage versus progressing to the next, more severe stage.</span>
<span id="cb17-1579"><a href="#cb17-1579" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-1580"><a href="#cb17-1580" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>**Consumer Behavior**: Understanding the odds of a customer making a basic purchase versus upgrading to a premium version.</span>
<span id="cb17-1581"><a href="#cb17-1581" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-1582"><a href="#cb17-1582" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-1583"><a href="#cb17-1583" aria-hidden="true" tabindex="-1"></a><span class="fu">#  Beyond Standard Approaches: Modeling Ordinal Data with CUB Models</span></span>
<span id="cb17-1584"><a href="#cb17-1584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1585"><a href="#cb17-1585" aria-hidden="true" tabindex="-1"></a>::: {.content-visible when-format=&quot;html&quot;}</span>
<span id="cb17-1586"><a href="#cb17-1586" aria-hidden="true" tabindex="-1"></a>::: column-margin</span>
<span id="cb17-1587"><a href="#cb17-1587" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- &lt;p&gt;&lt;a href=&quot;materials/Script_plots_examples.R&quot; download style=&quot;margin-right: 5px;&quot;&gt; &lt;i class=&quot;bi bi-file-earmark-code-fill&quot; style=&quot;font-size: 0.9em; vertical-align: middle;&quot;&gt;&lt;/i&gt; [R Script]{style=&quot;margin-left: 2px; vertical-align: middle;&quot;} &lt;/a&gt;&lt;/p&gt; --&gt;</span></span>
<span id="cb17-1588"><a href="#cb17-1588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1589"><a href="#cb17-1589" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;p&gt;&lt;a</span> <span class="er">href</span><span class="ot">=</span><span class="st">&quot;materials/Ordinal Data Analysis in R - Module 3.pdf&quot;</span> <span class="er">download</span><span class="kw">&gt;</span> <span class="kw">&lt;i</span> <span class="er">class</span><span class="ot">=</span><span class="st">&quot;bi bi-file-earmark-slides-fill&quot;</span> <span class="er">style</span><span class="ot">=</span><span class="st">&quot;font-size: 0.9em; vertical-align: middle;&quot;</span><span class="kw">&gt;&lt;/i&gt;</span> <span class="co">[</span><span class="ot">Slides</span><span class="co">]</span>{style=&quot;margin-left: 2px; vertical-align: middle;&quot;} <span class="kw">&lt;/a&gt;&lt;/p&gt;</span></span>
<span id="cb17-1590"><a href="#cb17-1590" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-1591"><a href="#cb17-1591" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-1592"><a href="#cb17-1592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1593"><a href="#cb17-1593" aria-hidden="true" tabindex="-1"></a> While powerful and widely used,  Ordered logit models operate under specific assumptions:</span>
<span id="cb17-1594"><a href="#cb17-1594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1595"><a href="#cb17-1595" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>**Proportional Odds Assumption**: This assumption can be restrictive and, if violated, can lead to misleading conclusions.</span>
<span id="cb17-1596"><a href="#cb17-1596" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1597"><a href="#cb17-1597" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>**Latent Variable Interpretation**: While mathematically convenient, the interpretation of the latent variable might not always align perfectly with the psychological process of how an individual actually chooses an ordered category. The continuous latent variable often represents an underlying &quot;utility&quot; or &quot;propensity,&quot; but it doesn&#39;t explicitly account for aspects like uncertainty or indecision in the response process.</span>
<span id="cb17-1598"><a href="#cb17-1598" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1599"><a href="#cb17-1599" aria-hidden="true" tabindex="-1"></a>These limitations highlight a need for alternative modeling frameworks that can capture the nuanced complexities inherent in how individuals respond to ordinal scales.</span>
<span id="cb17-1600"><a href="#cb17-1600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1601"><a href="#cb17-1601" aria-hidden="true" tabindex="-1"></a>There is a clear and compelling need for specialized statistical models designed to capture the unique characteristics of ordinal data and, importantly, to reflect the underlying cognitive and psychological processes through which individuals select a particular ordered category. This is where CUB models (Combination of a Uniform and a shifted Binomial random variable) come into play.</span>
<span id="cb17-1602"><a href="#cb17-1602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1603"><a href="#cb17-1603" aria-hidden="true" tabindex="-1"></a>CUB models, primarily developed by Domenico Piccolo and collaborators starting in the early 2000s, offer a distinct and innovative approach to modeling ordinal data. They stand apart from traditional methods by explicitly incorporating psychological interpretations into their statistical structure.</span>
<span id="cb17-1604"><a href="#cb17-1604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1605"><a href="#cb17-1605" aria-hidden="true" tabindex="-1"></a>At their core, CUB models are mixture models specifically tailored for ordinal data. The fundamental idea is that a respondent&#39;s observed rating is not solely a direct and deterministic mapping of their true &quot;feeling&quot; or &quot;utility.&quot; Instead, it is also significantly affected by an element of &quot;uncertainty&quot; or &quot;indecision&quot; that can influence the final choice. This acknowledgment of psychological complexity in the response process is what makes CUB models particularly insightful for rating data.</span>
<span id="cb17-1606"><a href="#cb17-1606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1607"><a href="#cb17-1607" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Psychological Reasons Behind the CUB Model</span></span>
<span id="cb17-1608"><a href="#cb17-1608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1609"><a href="#cb17-1609" aria-hidden="true" tabindex="-1"></a>The innovation of the CUB model lies in its attempt to statistically represent two fundamental psychological components that influence a respondent&#39;s choice on an ordinal scale. The model posits that an observed rating $R$ is a probabilistic outcome of a decision process that weighs two components.</span>
<span id="cb17-1610"><a href="#cb17-1610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1611"><a href="#cb17-1611" aria-hidden="true" tabindex="-1"></a>**1. Feeling (or Attraction/Preference)**</span>
<span id="cb17-1612"><a href="#cb17-1612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1613"><a href="#cb17-1613" aria-hidden="true" tabindex="-1"></a>This component represents the conscious, rational, and deliberative aspect of the decision-making process. It reflects the respondent&#39;s genuine evaluation, opinion, or perception regarding the item being rated. The &quot;feeling&quot; directs the respondent towards a specific category on the scale that best aligns with their internal assessment. This is the component that captures the respondent&#39;s true position or stance on the matter at hand.</span>
<span id="cb17-1614"><a href="#cb17-1614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1615"><a href="#cb17-1615" aria-hidden="true" tabindex="-1"></a>Depending on the specific context of the rating, &quot;feeling&quot; can be interpreted as:</span>
<span id="cb17-1616"><a href="#cb17-1616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1617"><a href="#cb17-1617" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Agreement/Disagreement**: How much a person agrees or disagrees with a statement.</span>
<span id="cb17-1618"><a href="#cb17-1618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1619"><a href="#cb17-1619" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Satisfaction/Dissatisfaction**: The level of contentment or discontent with a product, service, or experience.</span>
<span id="cb17-1620"><a href="#cb17-1620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1621"><a href="#cb17-1621" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Liking/Disliking**: The degree of preference or aversion towards an item.</span>
<span id="cb17-1622"><a href="#cb17-1622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1623"><a href="#cb17-1623" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Perceived quality, importance, risk, etc.**: The subjective assessment of various attributes.</span>
<span id="cb17-1624"><a href="#cb17-1624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1625"><a href="#cb17-1625" aria-hidden="true" tabindex="-1"></a>In essence, the feeling component drives the respondent towards a particular region of the ordinal scale, reflecting their underlying preference or &quot;attraction&quot; to certain categories.</span>
<span id="cb17-1626"><a href="#cb17-1626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1627"><a href="#cb17-1627" aria-hidden="true" tabindex="-1"></a>**2. Uncertainty (or Indecision/Fuzziness)**</span>
<span id="cb17-1628"><a href="#cb17-1628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1629"><a href="#cb17-1629" aria-hidden="true" tabindex="-1"></a>This component captures the hesitation, randomness, or lack of decisiveness that can accompany the choice process. It acknowledges a crucial psychological reality: respondents may not always have a perfectly clear and precise mapping of their internal feeling onto the provided scale categories. This can introduce a degree of randomness or &quot;noise&quot; into the selection process.</span>
<span id="cb17-1630"><a href="#cb17-1630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1631"><a href="#cb17-1631" aria-hidden="true" tabindex="-1"></a>Sources of this uncertainty can be varied and include:</span>
<span id="cb17-1632"><a href="#cb17-1632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1633"><a href="#cb17-1633" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Lack of Information or Knowledge**: The respondent might not have sufficient information to form a strong opinion about the item being rated.</span>
<span id="cb17-1634"><a href="#cb17-1634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1635"><a href="#cb17-1635" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Ambiguity**: The question wording or the definition of the scale categories might be unclear, leading to confusion.</span>
<span id="cb17-1636"><a href="#cb17-1636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1637"><a href="#cb17-1637" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Personal Tendencies**: Some individuals may inherently be more indecisive or tend to use certain parts of a scale (e.g., sticking to the middle categories).</span>
<span id="cb17-1638"><a href="#cb17-1638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1639"><a href="#cb17-1639" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Cognitive Effort/Satisficing**: In long surveys or under time pressure, respondents might engage in &quot;satisficing&quot; behavior. Instead of expending full mental energy to find the optimal category, they might pick a plausible but not necessarily precise one to save cognitive effort.</span>
<span id="cb17-1640"><a href="#cb17-1640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1641"><a href="#cb17-1641" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Time Pressure or Fatigue**: Being rushed or tired can reduce the ability to make a precise decision.</span>
<span id="cb17-1642"><a href="#cb17-1642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1643"><a href="#cb17-1643" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Emotional State or Mood**: A respondent&#39;s transient emotional state can also introduce variability into their choices.</span>
<span id="cb17-1644"><a href="#cb17-1644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1645"><a href="#cb17-1645" aria-hidden="true" tabindex="-1"></a>The uncertainty component effectively describes the probability that the respondent&#39;s choice is influenced by random factors rather than a specific preference.</span>
<span id="cb17-1646"><a href="#cb17-1646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1647"><a href="#cb17-1647" aria-hidden="true" tabindex="-1"></a><span class="fu">## The CUB Model: Statistical Formulation</span></span>
<span id="cb17-1648"><a href="#cb17-1648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1649"><a href="#cb17-1649" aria-hidden="true" tabindex="-1"></a>The basic CUB model, designed for m ordered categories (typically $r=1,2,\dots,m$), is a finite mixture of two discrete probability distributions:</span>
<span id="cb17-1650"><a href="#cb17-1650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1651"><a href="#cb17-1651" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>A shifted Binomial distribution to model the feeling (or attraction/preference) component.</span>
<span id="cb17-1652"><a href="#cb17-1652" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>A discrete Uniform distribution to model the uncertainty (or indecision/fuzziness) component.</span>
<span id="cb17-1653"><a href="#cb17-1653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1654"><a href="#cb17-1654" aria-hidden="true" tabindex="-1"></a>The Probability Mass Function (PMF) for an observed rating $R=r$ is given by:</span>
<span id="cb17-1655"><a href="#cb17-1655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1656"><a href="#cb17-1656" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1657"><a href="#cb17-1657" aria-hidden="true" tabindex="-1"></a>P(R = r \mid \pi,\xi) = \pi B(r \mid\xi) + (1-\pi)U(r)</span>
<span id="cb17-1658"><a href="#cb17-1658" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1659"><a href="#cb17-1659" aria-hidden="true" tabindex="-1"></a>where the elements of the mixture are: </span>
<span id="cb17-1660"><a href="#cb17-1660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1661"><a href="#cb17-1661" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$m$: This is the number of ordered categories on the scale. For instance, if a scale ranges from &quot;1 = Strongly Disagree&quot; to &quot;5 = Strongly Agree,&quot; then $m=5$.</span>
<span id="cb17-1662"><a href="#cb17-1662" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>$r$: This denotes the selected category by a respondent, where $r\in <span class="sc">\{</span> 1,2,…,m<span class="sc">\}</span>$.</span>
<span id="cb17-1663"><a href="#cb17-1663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1664"><a href="#cb17-1664" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>$\pi \in (0,1]$, acts as a mixture weight. $\pi$ represents the probability that the observed choice is driven by the feeling component (i.e., the shifted Binomial distribution).  </span>
<span id="cb17-1665"><a href="#cb17-1665" aria-hidden="true" tabindex="-1"></a>Consequently, $(1−\pi)$ is called **Uncertainty parameter** and represents the probability that the observed choice is driven by the uncertainty component (i.e., the discrete Uniform distribution). A higher value of $(1−\pi)$ means greater indecision or randomness in the response, indicating that the uniform component has a stronger influence.</span>
<span id="cb17-1666"><a href="#cb17-1666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1667"><a href="#cb17-1667" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>$\xi \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$, is directly related to the shifted Binomial distribution and determines the location of the &quot;feeling&quot;.  </span>
<span id="cb17-1668"><a href="#cb17-1668" aria-hidden="true" tabindex="-1"></a>More intuitively, $(1−\xi)$ is often considered the direct measure of &quot;feeling&quot;, indeed it is called **Feeling parameter**.  </span>
<span id="cb17-1669"><a href="#cb17-1669" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>If $(1−\xi)$ is high (e.g., close to 1, meaning $\xi$ is close to 0), there&#39;s a strong underlying feeling towards the higher end of the scale.</span>
<span id="cb17-1670"><a href="#cb17-1670" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>If $(1−\xi)$ is low (e.g., close to 0, meaning $\xi$ is close to 1), there&#39;s a strong underlying feeling towards the lower end of the scale.</span>
<span id="cb17-1671"><a href="#cb17-1671" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>If $(1−\xi) = 0.5$ (meaning $\xi=0.5$), the feeling component is neutral or centered, implying a symmetric preference if not for the influence of uncertainty.</span>
<span id="cb17-1672"><a href="#cb17-1672" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1673"><a href="#cb17-1673" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1674"><a href="#cb17-1674" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$U(r)$: This is the probability of choosing category $r$ according to a discrete Uniform distribution.  </span>
<span id="cb17-1675"><a href="#cb17-1675" aria-hidden="true" tabindex="-1"></a>For any category $r\in<span class="sc">\{</span>1,2,…,m<span class="sc">\}</span>$, $U(r)= \frac{1}{m}$.  </span>
<span id="cb17-1676"><a href="#cb17-1676" aria-hidden="true" tabindex="-1"></a>This component represents complete randomness or a lack of specific preference among the $m$ categories. If a respondent is entirely uncertain or indecisive, their response is essentially a random pick from the available options.</span>
<span id="cb17-1677"><a href="#cb17-1677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1678"><a href="#cb17-1678" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$B(r∣\xi)$: This is the probability of choosing category $r$ according to a shifted Binomial distribution.  </span>
<span id="cb17-1679"><a href="#cb17-1679" aria-hidden="true" tabindex="-1"></a>Specifically, this refers to $P(X=r−1)$ where $X\sim Bin(m−1,1−\xi)$. The &quot;shifted&quot; aspect arises because the rating scale typically starts from 1, while a standard Binomial distribution&#39;s trials start from 0. Thus, to model a choice of $r$ on a scale $1,…,m$, we consider $r−1$ successes out of $m−1$ trials.  </span>
<span id="cb17-1680"><a href="#cb17-1680" aria-hidden="true" tabindex="-1"></a>So, the PMF is:</span>
<span id="cb17-1681"><a href="#cb17-1681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1682"><a href="#cb17-1682" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1683"><a href="#cb17-1683" aria-hidden="true" tabindex="-1"></a>B(r\mid\xi)=\binom{m-1}{r-1}(1-\xi)^{r-1}\xi^{m-r}</span>
<span id="cb17-1684"><a href="#cb17-1684" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1685"><a href="#cb17-1685" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1686"><a href="#cb17-1686" aria-hidden="true" tabindex="-1"></a>This component models the feeling towards a particular category, allowing for various shapes (unimodal, skewed left/right, or even U-shaped if $(1−\xi)$ is extremely close to 0 or 1, though the latter is less common in direct &quot;feeling&quot; interpretation). It captures where the respondent&#39;s underlying preference lies on the scale.</span>
<span id="cb17-1687"><a href="#cb17-1687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1688"><a href="#cb17-1688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1689"><a href="#cb17-1689" aria-hidden="true" tabindex="-1"></a>Finally, the CUB model can be written as:</span>
<span id="cb17-1690"><a href="#cb17-1690" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1691"><a href="#cb17-1691" aria-hidden="true" tabindex="-1"></a>P(R = r \mid \pi,\xi) = \pi \binom{m-1}{r-1}(1-\xi)^{r-1}\xi^{m-r} + (1-\pi) \frac{1}{m}</span>
<span id="cb17-1692"><a href="#cb17-1692" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1693"><a href="#cb17-1693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1694"><a href="#cb17-1694" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpretation of Parameters</span></span>
<span id="cb17-1695"><a href="#cb17-1695" aria-hidden="true" tabindex="-1"></a>The feeling $(1-\xi)$ and the uncertainty $(1-\pi)$ parameters are not merely statistical quantities; they have direct psychological meanings related to the respondent&#39;s decision process.</span>
<span id="cb17-1696"><a href="#cb17-1696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1697"><a href="#cb17-1697" aria-hidden="true" tabindex="-1"></a>**The Uncertainty Parameter**</span>
<span id="cb17-1698"><a href="#cb17-1698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1699"><a href="#cb17-1699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1700"><a href="#cb17-1700" aria-hidden="true" tabindex="-1"></a>It directly quantifies the level of uncertainty or indecision in the respondent&#39;s choice.</span>
<span id="cb17-1701"><a href="#cb17-1701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1702"><a href="#cb17-1702" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>If  $(1-\pi = 0)$ (i.e., $\pi = 1$) it means that the observed choice is entirely determined by the feeling, modeled by the binomial component. There is no uncertainty. The distribution of responses will reflect the shape of the Binomial.</span>
<span id="cb17-1703"><a href="#cb17-1703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1704"><a href="#cb17-1704" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If $(1−\pi)=1$ (i.e., $\pi=0$) it means that the observed choice is entirely determined by &quot;uncertainty&quot; (Uniform component). The respondent&#39;s feeling plays no role. The distribution of responses will be perfectly flat, meaning each category is chosen with equal probability.</span>
<span id="cb17-1705"><a href="#cb17-1705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1706"><a href="#cb17-1706" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Values between 0 and 1 indicate a mix of the two components. A higher value of $(1−\pi)$ effectively &quot;flattens&quot; the observed distribution of responses towards a uniform shape, as the random component gains more influence.</span>
<span id="cb17-1707"><a href="#cb17-1707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1708"><a href="#cb17-1708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1709"><a href="#cb17-1709" aria-hidden="true" tabindex="-1"></a>**The Feeling Parameter**</span>
<span id="cb17-1710"><a href="#cb17-1710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1711"><a href="#cb17-1711" aria-hidden="true" tabindex="-1"></a>The quantity $(1−\xi)$ measures the underlying &quot;feeling&quot;, &quot;preference&quot;, or &quot;attraction&quot; of the respondent. It dictates the skewness and location of the Binomial component.</span>
<span id="cb17-1712"><a href="#cb17-1712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1713"><a href="#cb17-1713" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If $(1−\xi)$ is high (close to 1, so $\xi$ is close to 0), it means that there&#39;s a strong attraction towards higher-valued categories. The Binomial component will be skewed to the right, with its mode (most frequent value) located at or near the maximum category $m$.</span>
<span id="cb17-1714"><a href="#cb17-1714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1715"><a href="#cb17-1715" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If $(1−\xi)$ is low (close to 0, so $\xi$ is close to 1) it means that there&#39;s a strong attraction towards lower-valued categories. The Binomial component will be skewed to the left, with its mode located at or near the minimum category 1.</span>
<span id="cb17-1716"><a href="#cb17-1716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1717"><a href="#cb17-1717" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If $(1−\xi)=0.5$ (so $\xi=0.5$), the Binomial component is symmetric around the center of the scale, indicating a neutral or balanced feeling.</span>
<span id="cb17-1718"><a href="#cb17-1718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1719"><a href="#cb17-1719" aria-hidden="true" tabindex="-1"></a><span class="al">![Probability distribution functions of the CUB model, for $m = 7$ and 9 combinations of feeling and uncertainty.](images\CUBgrid.jpg)</span>{width=80%}</span>
<span id="cb17-1720"><a href="#cb17-1720" aria-hidden="true" tabindex="-1"></a><span class="in">```{r echo = F, message=F, warning=F, eval=F}</span></span>
<span id="cb17-1721"><a href="#cb17-1721" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(CUB)</span>
<span id="cb17-1722"><a href="#cb17-1722" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb17-1723"><a href="#cb17-1723" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb17-1724"><a href="#cb17-1724" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb17-1725"><a href="#cb17-1725" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="dv">7</span></span>
<span id="cb17-1726"><a href="#cb17-1726" aria-hidden="true" tabindex="-1"></a>pai.vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.2</span>,<span class="fl">0.5</span>, <span class="fl">0.8</span>)</span>
<span id="cb17-1727"><a href="#cb17-1727" aria-hidden="true" tabindex="-1"></a>csi.vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.2</span>,<span class="fl">0.5</span>, <span class="fl">0.8</span>)</span>
<span id="cb17-1728"><a href="#cb17-1728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1729"><a href="#cb17-1729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1730"><a href="#cb17-1730" aria-hidden="true" tabindex="-1"></a>parameters <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">nrow =</span> <span class="dv">9</span>, <span class="at">ncol =</span> <span class="dv">2</span><span class="sc">+</span>m)</span>
<span id="cb17-1731"><a href="#cb17-1731" aria-hidden="true" tabindex="-1"></a>idx <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb17-1732"><a href="#cb17-1732" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)) {</span>
<span id="cb17-1733"><a href="#cb17-1733" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)) {</span>
<span id="cb17-1734"><a href="#cb17-1734" aria-hidden="true" tabindex="-1"></a>    parameters[idx,<span class="dv">1</span>] <span class="ot">&lt;-</span> pai.vec[i]</span>
<span id="cb17-1735"><a href="#cb17-1735" aria-hidden="true" tabindex="-1"></a>    parameters[idx,<span class="dv">2</span>] <span class="ot">&lt;-</span> pai.vec[j]</span>
<span id="cb17-1736"><a href="#cb17-1736" aria-hidden="true" tabindex="-1"></a>    parameters[idx,<span class="dv">3</span><span class="sc">:</span>(<span class="dv">2</span><span class="sc">+</span>m)] <span class="ot">&lt;-</span> <span class="fu">probcub00</span>(m,pai.vec[i],pai.vec[j])</span>
<span id="cb17-1737"><a href="#cb17-1737" aria-hidden="true" tabindex="-1"></a>    idx <span class="ot">&lt;-</span> idx<span class="sc">+</span><span class="dv">1</span></span>
<span id="cb17-1738"><a href="#cb17-1738" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb17-1739"><a href="#cb17-1739" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-1740"><a href="#cb17-1740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1741"><a href="#cb17-1741" aria-hidden="true" tabindex="-1"></a>freq_mat <span class="ot">&lt;-</span> parameters[,<span class="dv">3</span><span class="sc">:</span><span class="dv">9</span>]</span>
<span id="cb17-1742"><a href="#cb17-1742" aria-hidden="true" tabindex="-1"></a>plots <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb17-1743"><a href="#cb17-1743" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Ciclo sui 9 casi</span></span>
<span id="cb17-1744"><a href="#cb17-1744" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>) {</span>
<span id="cb17-1745"><a href="#cb17-1745" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Frequenze per il caso i</span></span>
<span id="cb17-1746"><a href="#cb17-1746" aria-hidden="true" tabindex="-1"></a>  df_i <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb17-1747"><a href="#cb17-1747" aria-hidden="true" tabindex="-1"></a>    Modalità <span class="ot">=</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>,</span>
<span id="cb17-1748"><a href="#cb17-1748" aria-hidden="true" tabindex="-1"></a>    <span class="at">Frequenza =</span> freq_mat[i, ]</span>
<span id="cb17-1749"><a href="#cb17-1749" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb17-1750"><a href="#cb17-1750" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-1751"><a href="#cb17-1751" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calcola 1 - pi e 1 - xi</span></span>
<span id="cb17-1752"><a href="#cb17-1752" aria-hidden="true" tabindex="-1"></a>  one_minus_pi <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="dv">1</span> <span class="sc">-</span> parameters[i,<span class="dv">1</span>], <span class="dv">2</span>)</span>
<span id="cb17-1753"><a href="#cb17-1753" aria-hidden="true" tabindex="-1"></a>  one_minus_xi <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="dv">1</span> <span class="sc">-</span> parameters[i,<span class="dv">2</span>], <span class="dv">2</span>)</span>
<span id="cb17-1754"><a href="#cb17-1754" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-1755"><a href="#cb17-1755" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Titolo con i simboli greci</span></span>
<span id="cb17-1756"><a href="#cb17-1756" aria-hidden="true" tabindex="-1"></a>  titolo <span class="ot">&lt;-</span> <span class="fu">bquote</span>( (<span class="dv">1</span> <span class="sc">-</span> pi) <span class="sc">*</span> <span class="st">&quot; = &quot;</span> <span class="sc">*</span> .(one_minus_pi) <span class="sc">*</span> <span class="st">&quot;,   &quot;</span> <span class="sc">*</span></span>
<span id="cb17-1757"><a href="#cb17-1757" aria-hidden="true" tabindex="-1"></a>                     (<span class="dv">1</span> <span class="sc">-</span> xi) <span class="sc">*</span> <span class="st">&quot; = &quot;</span> <span class="sc">*</span> .(one_minus_xi))</span>
<span id="cb17-1758"><a href="#cb17-1758" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-1759"><a href="#cb17-1759" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Grafico</span></span>
<span id="cb17-1760"><a href="#cb17-1760" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_i, <span class="fu">aes</span>(<span class="at">x =</span> Modalità, <span class="at">y =</span> Frequenza)) <span class="sc">+</span></span>
<span id="cb17-1761"><a href="#cb17-1761" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> Frequenza), <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-1762"><a href="#cb17-1762" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>) <span class="sc">+</span></span>
<span id="cb17-1763"><a href="#cb17-1763" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb17-1764"><a href="#cb17-1764" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylim</span>(<span class="dv">0</span>,<span class="fl">0.5</span>) <span class="sc">+</span> </span>
<span id="cb17-1765"><a href="#cb17-1765" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> titolo, <span class="at">x =</span> <span class="st">&quot;&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Frequencies&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-1766"><a href="#cb17-1766" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">panel.grid =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb17-1767"><a href="#cb17-1767" aria-hidden="true" tabindex="-1"></a>          <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb17-1768"><a href="#cb17-1768" aria-hidden="true" tabindex="-1"></a>   plots[[i]] <span class="ot">&lt;-</span> p</span>
<span id="cb17-1769"><a href="#cb17-1769" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Salva come immagine quadrata</span></span>
<span id="cb17-1770"><a href="#cb17-1770" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggsave</span>(<span class="at">filename =</span> <span class="fu">paste0</span>(<span class="st">&quot;caso_&quot;</span>, i, <span class="st">&quot;.jpg&quot;</span>),</span>
<span id="cb17-1771"><a href="#cb17-1771" aria-hidden="true" tabindex="-1"></a>         <span class="at">plot =</span> p,</span>
<span id="cb17-1772"><a href="#cb17-1772" aria-hidden="true" tabindex="-1"></a>         <span class="at">width =</span> <span class="dv">5</span>, <span class="at">height =</span> <span class="dv">5</span>, <span class="at">units =</span> <span class="st">&quot;in&quot;</span>, <span class="at">dpi =</span> <span class="dv">300</span>)</span>
<span id="cb17-1773"><a href="#cb17-1773" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-1774"><a href="#cb17-1774" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-1775"><a href="#cb17-1775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1776"><a href="#cb17-1776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1777"><a href="#cb17-1777" aria-hidden="true" tabindex="-1"></a><span class="fu">### Model identifiability and Estimation</span></span>
<span id="cb17-1778"><a href="#cb17-1778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1779"><a href="#cb17-1779" aria-hidden="true" tabindex="-1"></a>The CUB model is identifiable (i.e., different sets of parameter values lead to different probability distributions for the observed data) if the number of categories $m &gt; 3$.</span>
<span id="cb17-1780"><a href="#cb17-1780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1781"><a href="#cb17-1781" aria-hidden="true" tabindex="-1"></a>The parameters $(\pi, \xi)$ of the CUB model are typically estimated using the Maximum Likelihood Estimation (MLE) method. MLE search for the parameter values that maximize the likelihood of observing the given data.</span>
<span id="cb17-1782"><a href="#cb17-1782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1783"><a href="#cb17-1783" aria-hidden="true" tabindex="-1"></a>Since the CUB model is a mixture model, direct maximization of this log-likelihood function can be complex due to its non-linear nature. Therefore, the Expectation-Maximization (EM) algorithm is a common and robust iterative method for finding the MLEs. </span>
<span id="cb17-1784"><a href="#cb17-1784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1785"><a href="#cb17-1785" aria-hidden="true" tabindex="-1"></a><span class="fu">### Assessing the Goodness of Fit</span></span>
<span id="cb17-1786"><a href="#cb17-1786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1787"><a href="#cb17-1787" aria-hidden="true" tabindex="-1"></a> A particularly common and intuitive measure for assessing how well a CUB model fits the observed data is the Dissimilarity ($Diss$) Index. It quantifies the absolute difference between the observed and fitted proportions for each category. The $Diss$ index is defined as follows:</span>
<span id="cb17-1788"><a href="#cb17-1788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1789"><a href="#cb17-1789" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1790"><a href="#cb17-1790" aria-hidden="true" tabindex="-1"></a>Diss = \frac{1}{2}\sum_{r = 1}^{m} \mid f_r - p_r(\hat{\boldsymbol{\theta}})\mid</span>
<span id="cb17-1791"><a href="#cb17-1791" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1792"><a href="#cb17-1792" aria-hidden="true" tabindex="-1"></a>where $f_r$ are the observed relative frequencies and $p_r(\hat{\boldsymbol{\theta}})$ are the estimated probabilities for the response categories.</span>
<span id="cb17-1793"><a href="#cb17-1793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1794"><a href="#cb17-1794" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Values of $Diss$ closer to 0 indicate a better fit, with a perfect fit yielding $Diss = 0$.</span>
<span id="cb17-1795"><a href="#cb17-1795" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The maximum value of $Diss$ is 1 when there is no overlap between observed and fitted distributions.</span>
<span id="cb17-1796"><a href="#cb17-1796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1797"><a href="#cb17-1797" aria-hidden="true" tabindex="-1"></a>The Dissimilarity Index is popular because it provides a direct and easily interpretable measure of the overall discrepancy between the observed data distribution and the distribution predicted by the CUB model. In other words, it measures the proportion of responses to be changed to achieve a perfect fit.  </span>
<span id="cb17-1798"><a href="#cb17-1798" aria-hidden="true" tabindex="-1"></a>It is less sensitive to low expected frequencies than the Pearson Chi-squared test and gives a clear indication of prediction accuracy.</span>
<span id="cb17-1799"><a href="#cb17-1799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1800"><a href="#cb17-1800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1801"><a href="#cb17-1801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1802"><a href="#cb17-1802" aria-hidden="true" tabindex="-1"></a><span class="fu">### Parameter Space Visualization</span></span>
<span id="cb17-1803"><a href="#cb17-1803" aria-hidden="true" tabindex="-1"></a>CUB models offer a highly intuitive way to visualize the joint interpretation of their parameters: the parameter space visualization. This is typically represented on a unit square where:</span>
<span id="cb17-1804"><a href="#cb17-1804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1805"><a href="#cb17-1805" aria-hidden="true" tabindex="-1"></a>The x-axis represents $(1−\pi)$, the uncertainty level.</span>
<span id="cb17-1806"><a href="#cb17-1806" aria-hidden="true" tabindex="-1"></a>The y-axis represents $(1−\xi)$, the feeling or attraction level.</span>
<span id="cb17-1807"><a href="#cb17-1807" aria-hidden="true" tabindex="-1"></a>This &quot;CUB plot&quot; is incredibly helpful for comparing different datasets, subgroups, or even changes within a single group over time. Key regions of this plot offer immediate insights:</span>
<span id="cb17-1808"><a href="#cb17-1808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1809"><a href="#cb17-1809" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Bottom-left corner** ($(1−\pi)\approx0,(1−\xi)\approx0$): This indicates very low uncertainty (respondents are very certain in their choices) and a strong feeling towards low scores (e.g., strong disagreement, high dissatisfaction).</span>
<span id="cb17-1810"><a href="#cb17-1810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1811"><a href="#cb17-1811" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Top-left corner** ($(1−\pi)\approx0,(1−\xi)\approx1$): This signifies very low uncertainty and a strong feeling towards high scores (e.g., strong agreement, high satisfaction).</span>
<span id="cb17-1812"><a href="#cb17-1812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1813"><a href="#cb17-1813" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Right side** ($(1−\pi)\approx1$): This region represents very high uncertainty. In this scenario, the feeling component becomes less influential, and responses tend to be closer to a uniform distribution, indicating a significant degree of randomness in the choices.</span>
<span id="cb17-1814"><a href="#cb17-1814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1815"><a href="#cb17-1815" aria-hidden="true" tabindex="-1"></a>This graphical representation provides a powerful diagnostic tool for understanding the underlying psychological processes at play in rating data.</span>
<span id="cb17-1816"><a href="#cb17-1816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1817"><a href="#cb17-1817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1818"><a href="#cb17-1818" aria-hidden="true" tabindex="-1"></a><span class="al">![Graphical representation of the parameter space of the CUB model](images\cartesian_agg.jpg)</span>{width=100%}</span>
<span id="cb17-1819"><a href="#cb17-1819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1820"><a href="#cb17-1820" aria-hidden="true" tabindex="-1"></a><span class="fu">## Extensions of the CUB Model: Incorporating Covariates</span></span>
<span id="cb17-1821"><a href="#cb17-1821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1822"><a href="#cb17-1822" aria-hidden="true" tabindex="-1"></a>The basic CUB model, as discussed in Chapter 2, provides a powerful framework for understanding the underlying feeling and uncertainty in rating data. However, the basic formulation assumes a homogeneity in the population, meaning that the parameters are constant for all individuals. While useful for initial descriptive analysis, this assumption often oversimplifies the complex reality of human responses.</span>
<span id="cb17-1823"><a href="#cb17-1823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1824"><a href="#cb17-1824" aria-hidden="true" tabindex="-1"></a>In real-world applications, it is almost always more realistic to assume that the psychological components driving responses (the feeling and uncertainty components) vary across different individuals or groups. These variations are often systematically related to observable characteristics of the respondents or the context in which the ratings are collected. </span>
<span id="cb17-1825"><a href="#cb17-1825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1826"><a href="#cb17-1826" aria-hidden="true" tabindex="-1"></a>The introduction of covariates into the CUB model allows us to move beyond a simple description of the overall population&#39;s feeling and uncertainty, enabling a much more nuanced and insightful analysis. Specifically, introducing covariates allows us to:</span>
<span id="cb17-1827"><a href="#cb17-1827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1828"><a href="#cb17-1828" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>**Explain heterogeneity in response patterns**: Instead of treating differences in responses as random noise, covariates enable us to identify systematic factors that explain why different individuals or groups exhibit different levels of feeling and uncertainty.</span>
<span id="cb17-1829"><a href="#cb17-1829" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1830"><a href="#cb17-1830" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Understand how specific characteristics influence feeling and uncertainty**: This is perhaps the most powerful advantage. We can quantify the impact of a 10-year age increase on the probability of certainty (π) or the effect of a higher education level on the tendency to rate highly (1−ξ). This moves from mere description to explanation and inference.</span>
<span id="cb17-1831"><a href="#cb17-1831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1832"><a href="#cb17-1832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1833"><a href="#cb17-1833" aria-hidden="true" tabindex="-1"></a><span class="fu">### Statistical Formulation of CUB Model with Covariates</span></span>
<span id="cb17-1834"><a href="#cb17-1834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1835"><a href="#cb17-1835" aria-hidden="true" tabindex="-1"></a>Formulation of CUB with Covariates</span>
<span id="cb17-1836"><a href="#cb17-1836" aria-hidden="true" tabindex="-1"></a>In a CUB model with covariates, the core idea is that the parameters $\pi$ and $\xi$  are no longer fixed constants across all individuals. Instead, they are modeled as functions of a set of explanatory variables. Let $y_i$ be a vector of covariates for subject $i$ specifically influencing their uncertainty, and $w_i$ be a vector of covariates for subject $i$ influencing their feeling. These covariate vectors can be the same, overlap, or be entirely different.</span>
<span id="cb17-1837"><a href="#cb17-1837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1838"><a href="#cb17-1838" aria-hidden="true" tabindex="-1"></a>To ensure that the parameters $\pi_i$ and $\xi_i$ remain within their valid range of $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$, a link function is employed, typically a logistic (logit) function, which is standard practice for modeling probabilities in generalized linear models.</span>
<span id="cb17-1839"><a href="#cb17-1839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1840"><a href="#cb17-1840" aria-hidden="true" tabindex="-1"></a>**Modeling the uncertainty**</span>
<span id="cb17-1841"><a href="#cb17-1841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1842"><a href="#cb17-1842" aria-hidden="true" tabindex="-1"></a>Since $\pi_i\in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$, we model it using a logistic link. It&#39;s often more intuitive to model $(1-\pi_i)$, which represents the probability that the choice is driven by the uniform component.</span>
<span id="cb17-1843"><a href="#cb17-1843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1844"><a href="#cb17-1844" aria-hidden="true" tabindex="-1"></a>The log-odds of uncertainty are linked to the covariates $y_i$:</span>
<span id="cb17-1845"><a href="#cb17-1845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1846"><a href="#cb17-1846" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1847"><a href="#cb17-1847" aria-hidden="true" tabindex="-1"></a>\text{logit}(1-\pi_i) = \log \Bigg(\frac{1-\pi_i}{\pi_i}\Bigg) = \boldsymbol{y}^{T}_i\boldsymbol{\beta}</span>
<span id="cb17-1848"><a href="#cb17-1848" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1849"><a href="#cb17-1849" aria-hidden="true" tabindex="-1"></a>where $\boldsymbol{\beta}$ is a vector of coefficients corresponding to the covariates $\boldsymbol{y}_i$.</span>
<span id="cb17-1850"><a href="#cb17-1850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1851"><a href="#cb17-1851" aria-hidden="true" tabindex="-1"></a>From this, we can derive the direct relationships for $(1−\pi_i)$ and $\pi_i$</span>
<span id="cb17-1852"><a href="#cb17-1852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1853"><a href="#cb17-1853" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1854"><a href="#cb17-1854" aria-hidden="true" tabindex="-1"></a>(1-\pi_i)=\frac{\exp(\boldsymbol{y}^{T}_i\boldsymbol{\beta})}{1+\exp(\boldsymbol{y}^{T}_i\boldsymbol{\beta})}</span>
<span id="cb17-1855"><a href="#cb17-1855" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1856"><a href="#cb17-1856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1857"><a href="#cb17-1857" aria-hidden="true" tabindex="-1"></a>And consequently, for $\pi_i$:</span>
<span id="cb17-1858"><a href="#cb17-1858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1859"><a href="#cb17-1859" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1860"><a href="#cb17-1860" aria-hidden="true" tabindex="-1"></a>\pi_i = 1-(1-\pi_i) = 1- \frac{\exp(\boldsymbol{y}^{T}_i\boldsymbol{\beta})}{1+\exp(\boldsymbol{y}^{T}_i\boldsymbol{\beta})} = \frac{1}{1+\exp(\boldsymbol{y}^{T}_i\boldsymbol{\beta})}</span>
<span id="cb17-1861"><a href="#cb17-1861" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1862"><a href="#cb17-1862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1863"><a href="#cb17-1863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1864"><a href="#cb17-1864" aria-hidden="true" tabindex="-1"></a>**Modeling the feeling**</span>
<span id="cb17-1865"><a href="#cb17-1865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1866"><a href="#cb17-1866" aria-hidden="true" tabindex="-1"></a>Similarly, for $\xi_i\in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$, a logit link is applied. It&#39;s often more insightful to directly model $(1-\xi_i)$, which represents the feeling towards higher scores on the scale.</span>
<span id="cb17-1867"><a href="#cb17-1867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1868"><a href="#cb17-1868" aria-hidden="true" tabindex="-1"></a>The log-odds of feeling for higher scores are linked to the covariates $w_i$ :</span>
<span id="cb17-1869"><a href="#cb17-1869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1870"><a href="#cb17-1870" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1871"><a href="#cb17-1871" aria-hidden="true" tabindex="-1"></a>\text{logit}(1-\xi_i) = \log \Bigg(\frac{1-\xi_i}{\xi_i}\Bigg) = \boldsymbol{w}^{T}_i\boldsymbol{\gamma}</span>
<span id="cb17-1872"><a href="#cb17-1872" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1873"><a href="#cb17-1873" aria-hidden="true" tabindex="-1"></a>where $\boldsymbol{\gamma}$ is a vector of coefficients corresponding to the covariates $\boldsymbol{w}_i$.</span>
<span id="cb17-1874"><a href="#cb17-1874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1875"><a href="#cb17-1875" aria-hidden="true" tabindex="-1"></a>This implies the following fo $(1−\xi_i)$:</span>
<span id="cb17-1876"><a href="#cb17-1876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1877"><a href="#cb17-1877" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1878"><a href="#cb17-1878" aria-hidden="true" tabindex="-1"></a>(1-\xi_i)=\frac{\exp(\boldsymbol{w}^{T}_i\boldsymbol{\gamma})}{1+\exp(\boldsymbol{w}^{T}_i\boldsymbol{\gamma})}</span>
<span id="cb17-1879"><a href="#cb17-1879" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1880"><a href="#cb17-1880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1881"><a href="#cb17-1881" aria-hidden="true" tabindex="-1"></a>And for $\xi_i$:</span>
<span id="cb17-1882"><a href="#cb17-1882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1883"><a href="#cb17-1883" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1884"><a href="#cb17-1884" aria-hidden="true" tabindex="-1"></a>\xi_i = 1-(1-\xi_i) = 1- \frac{\exp(\boldsymbol{w}^{T}_i\boldsymbol{\gamma})}{1+\exp(\boldsymbol{w}^{T}_i\boldsymbol{\gamma})} = \frac{1}{1+\exp(\boldsymbol{w}^{T}_i\boldsymbol{\gamma})}</span>
<span id="cb17-1885"><a href="#cb17-1885" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1886"><a href="#cb17-1886" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1887"><a href="#cb17-1887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1888"><a href="#cb17-1888" aria-hidden="true" tabindex="-1"></a>With these formulations, the overall probability mass function for an observed rating R=r for subject i becomes:</span>
<span id="cb17-1889"><a href="#cb17-1889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1890"><a href="#cb17-1890" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1891"><a href="#cb17-1891" aria-hidden="true" tabindex="-1"></a>P(R_i = r \mid \pi_i,\xi_i) = \pi_i \binom{m-1}{r-1}(1-\xi_i)^{r-1}\xi_i^{m-r} + (1-\pi_i) \frac{1}{m}</span>
<span id="cb17-1892"><a href="#cb17-1892" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1893"><a href="#cb17-1893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1894"><a href="#cb17-1894" aria-hidden="true" tabindex="-1"></a>where $\pi_i$ and $\xi_i$ are determined by the covariates as defined above.</span>
<span id="cb17-1895"><a href="#cb17-1895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1896"><a href="#cb17-1896" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpretation of Covariate Effects</span></span>
<span id="cb17-1897"><a href="#cb17-1897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1898"><a href="#cb17-1898" aria-hidden="true" tabindex="-1"></a>Interpreting the coefficients ($\beta$ and $\gamma$) in a CUB model with covariates is crucial for understanding how specific characteristics influence the psychological components of rating. Remember that these coefficients operate on the log-odds scale due to the logistic link.</span>
<span id="cb17-1899"><a href="#cb17-1899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1900"><a href="#cb17-1900" aria-hidden="true" tabindex="-1"></a>**Coefficients $\beta$**</span>
<span id="cb17-1901"><a href="#cb17-1901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1902"><a href="#cb17-1902" aria-hidden="true" tabindex="-1"></a>These coefficients describe the impact of covariates on the log-odds of uncertainty.</span>
<span id="cb17-1903"><a href="#cb17-1903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1904"><a href="#cb17-1904" aria-hidden="true" tabindex="-1"></a>A positive coefficient $\beta_k$ implies that an increase in the $k$-th covariate $y_{ik}$, holding other covariates constant, increases the log-odds of uncertainty. Therefore $(1−\pi_i)$ increases and makes the respondent&#39;s choice more driven by the uniform component. This suggests that as $y_{ik}$ increases, the individual is more indecisive or random in their rating.</span>
<span id="cb17-1905"><a href="#cb17-1905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1906"><a href="#cb17-1906" aria-hidden="true" tabindex="-1"></a>A negative $\beta_k$ implies that an increase in $y_{ik}$ decreases the log-odds of uncertainty, thus decreasing $(1−\pi_i)$ and making the respondent&#39;s choice more driven by their underlying feeling. This suggests that as $y_{ik}$ increases, the individual becomes more certain in their rating.</span>
<span id="cb17-1907"><a href="#cb17-1907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1908"><a href="#cb17-1908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1909"><a href="#cb17-1909" aria-hidden="true" tabindex="-1"></a>**Coefficients $\gamma$**</span>
<span id="cb17-1910"><a href="#cb17-1910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1911"><a href="#cb17-1911" aria-hidden="true" tabindex="-1"></a>These coefficients describe the impact of covariates $w_i$  on the log-odds of feeling towards higher scores.</span>
<span id="cb17-1912"><a href="#cb17-1912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1913"><a href="#cb17-1913" aria-hidden="true" tabindex="-1"></a>A positive $\gamma_k$ implies that an increase in the $k$-th covariate $w_{ik}$, holding other covariates constant, increases the log-odds of feeling for higher scores, thus increasing $(1-\xi_i)$. This means that as $w_{ik}$ increases, the individual&#39;s underlying preference shifts towards the higher end of the rating scale.</span>
<span id="cb17-1914"><a href="#cb17-1914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1915"><a href="#cb17-1915" aria-hidden="true" tabindex="-1"></a>A negative $\gamma_k$ implies that an increase in $w_{ik}$ decreases the log-odds of feeling for higher scores, thus decreasing $(1-\xi_i)$. This means that as $w_{ik}$ increases, the individual&#39;s underlying preference shifts towards the lower end of the rating scale.</span>
<span id="cb17-1916"><a href="#cb17-1916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1917"><a href="#cb17-1917" aria-hidden="true" tabindex="-1"></a>**Important Note**: CUB models with covariates are not Generalized Linear Models (GLMs) in the strict sense. While the parameters $\pi_i$ and $\xi_i$ are linked to covariates using GLM-like structures (specifically, logistic regressions), the response variable itself (the mixture of Binomial and Uniform distributions) does not belong to the exponential family.</span>
<span id="cb17-1918"><a href="#cb17-1918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1919"><a href="#cb17-1919" aria-hidden="true" tabindex="-1"></a><span class="fu">## CUB Model with Shelter Option</span></span>
<span id="cb17-1920"><a href="#cb17-1920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1921"><a href="#cb17-1921" aria-hidden="true" tabindex="-1"></a>While the basic CUB model effectively captures the feeling and uncertainty in ordinal responses, real-world rating data often exhibit additional complexities. </span>
<span id="cb17-1922"><a href="#cb17-1922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1923"><a href="#cb17-1923" aria-hidden="true" tabindex="-1"></a>One such common phenomenon is the tendency for respondents to disproportionately select a specific category, not entirely explained by their true underlying feeling or by simple random guessing. This over-selection of a particular category suggests it acts as a &quot;shelter&quot; or &quot;refuge&quot; for some respondents.</span>
<span id="cb17-1924"><a href="#cb17-1924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1925"><a href="#cb17-1925" aria-hidden="true" tabindex="-1"></a>The shelter effect describes a situation where a specific category on an ordinal scale receives an &quot;extra&quot; probability mass, beyond what would be predicted solely by the respondent&#39;s underlying feeling or by pure random uncertainty. This happens because some respondents might gravitate towards this category for reasons unrelated to their precise preference or indecision.</span>
<span id="cb17-1926"><a href="#cb17-1926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1927"><a href="#cb17-1927" aria-hidden="true" tabindex="-1"></a>Reasons for this &quot;shelter-seeking&quot; behavior have been extensively discussed in the literature (e.g., Iannario, 2012; Piccolo &amp; Simone, 2019):</span>
<span id="cb17-1928"><a href="#cb17-1928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1929"><a href="#cb17-1929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1930"><a href="#cb17-1930" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Cognitive Simplification**: Respondents may choose an easy, or cognitively less demanding option to reduce mental effort. This could be the middle category (e.g., &quot;Neutral&quot;), a neutral option specifically provided, or even the first/last option if it serves as an easy default.</span>
<span id="cb17-1931"><a href="#cb17-1931" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Fatigue or Boredom**: Especially prevalent in long questionnaires or surveys, fatigue can lead respondents to disengage and simply pick a convenient category rather than carefully considering their true response.</span>
<span id="cb17-1932"><a href="#cb17-1932" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Social Desirability or Privacy Concerns**: Individuals might select a &quot;safe&quot;, non-committal, or socially acceptable answer to avoid expressing a strong or controversial opinion, or to protect their privacy. The neutral option often serves this purpose.</span>
<span id="cb17-1933"><a href="#cb17-1933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1934"><a href="#cb17-1934" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Questionnaire Design**: Poorly worded questions, ambiguous scale anchors, or an overwhelming number of options might inadvertently guide respondents towards a default or ambiguous middle ground.</span>
<span id="cb17-1935"><a href="#cb17-1935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1936"><a href="#cb17-1936" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Satisficing**: This refers to the tendency to select a minimally acceptable response rather than the optimal one, often to save cognitive resources. The shelter option becomes the &quot;good enough&quot; answer.</span>
<span id="cb17-1937"><a href="#cb17-1937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1938"><a href="#cb17-1938" aria-hidden="true" tabindex="-1"></a>The critical implication of the shelter effect is that the chosen category $c$ has an &quot;extra&quot; probability mass. This means the observed frequency for category $c$ is higher than what a standard two-component CUB model would predict. Effectively, a subset of respondents might be selecting $c$ directly, bypassing the usual feeling-uncertainty decision process.</span>
<span id="cb17-1939"><a href="#cb17-1939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1940"><a href="#cb17-1940" aria-hidden="true" tabindex="-1"></a><span class="fu">### Defining the shelter category</span></span>
<span id="cb17-1941"><a href="#cb17-1941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1942"><a href="#cb17-1942" aria-hidden="true" tabindex="-1"></a>The shelter category, denoted by $c$ (where $c \in <span class="sc">\{</span>1,2,…,m<span class="sc">\}</span>$), is a specific category on the ordinal scale that exhibits this inflated probability mass. Identifying this category is a crucial preliminary step. It can be:</span>
<span id="cb17-1943"><a href="#cb17-1943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1944"><a href="#cb17-1944" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Hypothesized a priori**: In many cases, the shelter category can be hypothesized beforehand based on the scale&#39;s design. For instance, on a 5-point Likert scale (1=Strongly Disagree, 5=Strongly Agree), the central category $c=3$ (&quot;Neutral&quot; or &quot;Neither agree nor disagree&quot;) is a very common candidate for a shelter option. Other possibilities could be the minimum ($c=1$) or maximum ($c=m$) category if they function as easy &quot;opt-out&quot; or default choices.</span>
<span id="cb17-1945"><a href="#cb17-1945" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>**Identified Empirically**: If no a priori hypothesis exists, the shelter category can be identified empirically. This involves observing an unusually high frequency for a particular category that is not well explained by a simple CUB model. A large positive residual for a specific category from a basic CUB fit can point towards a potential shelter effect.</span>
<span id="cb17-1946"><a href="#cb17-1946" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-1947"><a href="#cb17-1947" aria-hidden="true" tabindex="-1"></a>Once identified, the shelter category $c$ is treated as fixed in the model estimation.</span>
<span id="cb17-1948"><a href="#cb17-1948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1949"><a href="#cb17-1949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1950"><a href="#cb17-1950" aria-hidden="true" tabindex="-1"></a><span class="fu">### Statistical Formulation of CUB Model with Shelter Option</span></span>
<span id="cb17-1951"><a href="#cb17-1951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1952"><a href="#cb17-1952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1953"><a href="#cb17-1953" aria-hidden="true" tabindex="-1"></a>To account for the shelter effect, the basic CUB model is extended into a three-component mixture model. A common and highly interpretable approach is the CUB with Shelter (CUSH) model. This model introduces a third component: a degenerate distribution that assigns all probability mass exclusively to the shelter category $c$.</span>
<span id="cb17-1954"><a href="#cb17-1954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1955"><a href="#cb17-1955" aria-hidden="true" tabindex="-1"></a>The probability mass function (PMF) for the CUSH model for a rating $R=r$ is given by:</span>
<span id="cb17-1956"><a href="#cb17-1956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1957"><a href="#cb17-1957" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1958"><a href="#cb17-1958" aria-hidden="true" tabindex="-1"></a> P(R = r\mid \pi, \xi, \delta) = \delta \Big<span class="co">[</span><span class="ot">D_c(r)\Big</span><span class="co">]</span> + (1-\delta)\Big<span class="co">[</span><span class="ot">\pi B(r \mid \xi) + (1-\pi)U(r)\Big</span><span class="co">]</span></span>
<span id="cb17-1959"><a href="#cb17-1959" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1960"><a href="#cb17-1960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1961"><a href="#cb17-1961" aria-hidden="true" tabindex="-1"></a>where there is an additional component, compared to the basic CUB model: the degenerate distribution fir the shelter category $c$, $D_c(r)$:</span>
<span id="cb17-1962"><a href="#cb17-1962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1963"><a href="#cb17-1963" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1964"><a href="#cb17-1964" aria-hidden="true" tabindex="-1"></a>D_c(r) =</span>
<span id="cb17-1965"><a href="#cb17-1965" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb17-1966"><a href="#cb17-1966" aria-hidden="true" tabindex="-1"></a>    1, &amp; \text{if } r = s; <span class="sc">\\</span></span>
<span id="cb17-1967"><a href="#cb17-1967" aria-hidden="true" tabindex="-1"></a>    0, &amp; \text{otherwise;}</span>
<span id="cb17-1968"><a href="#cb17-1968" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb17-1969"><a href="#cb17-1969" aria-hidden="true" tabindex="-1"></a>\qquad r = 1, \dots, m.</span>
<span id="cb17-1970"><a href="#cb17-1970" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-1971"><a href="#cb17-1971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1972"><a href="#cb17-1972" aria-hidden="true" tabindex="-1"></a>The parameter $\delta \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ represents the probability of choosing the shelter category $c$ directly. This is the weight assigned to the degenerate distribution.</span>
<span id="cb17-1973"><a href="#cb17-1973" aria-hidden="true" tabindex="-1"></a>A higher $\delta$ indicates a stronger tendency for respondents to opt for the designated shelter category, irrespective of their true feeling or general uncertainty.</span>
<span id="cb17-1974"><a href="#cb17-1974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1975"><a href="#cb17-1975" aria-hidden="true" tabindex="-1"></a>**Model selection**</span>
<span id="cb17-1976"><a href="#cb17-1976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1977"><a href="#cb17-1977" aria-hidden="true" tabindex="-1"></a>Model selection is crucial when deciding whether a CUSH model offers a significantly better fit than a simpler CUB model. Standard statistical criteria can be used:</span>
<span id="cb17-1978"><a href="#cb17-1978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1979"><a href="#cb17-1979" aria-hidden="true" tabindex="-1"></a>Information criteria like Akaike Information Criterion and Bayesian information Criterion are widely used to balance model fit with model complexity.</span>
<span id="cb17-1980"><a href="#cb17-1980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1981"><a href="#cb17-1981" aria-hidden="true" tabindex="-1"></a>Lower values for AIC and BIC indicate a better-fitting model. BIC is often preferred in model selection for CUB models as it penalizes model complexity more heavily, which can help in choosing more parsimonious models.</span>
<span id="cb17-1982"><a href="#cb17-1982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1983"><a href="#cb17-1983" aria-hidden="true" tabindex="-1"></a>After fitting a basic CUB model, it&#39;s good practice to examine the residuals, which are the differences between observed and fitted probabilities/frequencies. If a simple CUB model shows a large positive residual for a specific category, it strongly suggests the presence of a shelter effect for that category. The Dissimilarity Index ($Diss$) can also be used to compare the overall fit improvement when a shelter component is added.</span>
<span id="cb17-1984"><a href="#cb17-1984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1985"><a href="#cb17-1985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1986"><a href="#cb17-1986" aria-hidden="true" tabindex="-1"></a><span class="fu">## Treatment of &quot;Don&#39;t Know&quot; (DK) Options within the CUB Framework</span></span>
<span id="cb17-1987"><a href="#cb17-1987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1988"><a href="#cb17-1988" aria-hidden="true" tabindex="-1"></a>Beyond the core rating scale, surveys often include an option for respondents to indicate &quot;Don&#39;t Know&quot; (DK), &quot;No Opinion&quot;, &quot;Not Applicable&quot;, or similar non-substantive responses. While seemingly innocuous, the handling of these responses presents a significant challenge for traditional statistical modeling, as they often don&#39;t fit neatly into standard analytical frameworks. </span>
<span id="cb17-1989"><a href="#cb17-1989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1990"><a href="#cb17-1990" aria-hidden="true" tabindex="-1"></a>The CUB framework, however, offers a theoretically robust and psychologically insightful approach to incorporating information from DK responses.</span>
<span id="cb17-1991"><a href="#cb17-1991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1992"><a href="#cb17-1992" aria-hidden="true" tabindex="-1"></a>&quot;Don&#39;t Know&quot; responses are common in surveys, and their treatment is critical for valid statistical inference. They are not merely missing data points; rather, they represent an active choice that reflects a specific cognitive or attitudinal state of the respondent.</span>
<span id="cb17-1993"><a href="#cb17-1993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1994"><a href="#cb17-1994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1995"><a href="#cb17-1995" aria-hidden="true" tabindex="-1"></a>DK responses are problematic for several reasons:</span>
<span id="cb17-1996"><a href="#cb17-1996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1997"><a href="#cb17-1997" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Not Simply Missing Data**: Treating DKs as simple missing values and discarding them (listwise deletion) can lead to biased samples and results. If respondents who choose DK differ systematically from those who provide substantive ratings, removing them can distort the representativeness of the remaining sample, affecting parameter estimates and generalizability. </span>
<span id="cb17-1998"><a href="#cb17-1998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-1999"><a href="#cb17-1999" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Imputation Issues**: Imputing a value for a DK response is inherently difficult and often relies on strong, untestable assumptions. Assigning a central value (e.g., the mean or median of the substantive responses) might mask genuine uncertainty, while more complex imputation methods (e.g., multiple imputation) can be challenging to implement and interpret accurately in the context of ordinal data.</span>
<span id="cb17-2000"><a href="#cb17-2000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2001"><a href="#cb17-2001" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>**Adding DK as a Category**: A seemingly straightforward approach is to include DK as just another category on the ordinal scale. However, this fundamentally breaks the ordinal nature of the scale. For example, a sequence like &quot;Strongly Disagree, Disagree, DK, Agree, Strongly Agree&quot; is conceptually problematic. The DK option is not naturally ordered between &quot;Disagree&quot; and &quot;Agree&quot;; it represents a different type of response altogether. Its inclusion disrupts the monotonic relationship implied by ordinal categories.</span>
<span id="cb17-2002"><a href="#cb17-2002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2003"><a href="#cb17-2003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2004"><a href="#cb17-2004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2005"><a href="#cb17-2005" aria-hidden="true" tabindex="-1"></a>To properly handle DK responses, it is essential to understand their underlying meanings. Research suggests that &quot;Don&#39;t Know&quot; can have several psychological interpretations:</span>
<span id="cb17-2006"><a href="#cb17-2006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2007"><a href="#cb17-2007" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>*True Lack of Knowledge/Opinion*: The respondent genuinely has no information, experience, or hasn&#39;t formed an opinion on the topic.</span>
<span id="cb17-2008"><a href="#cb17-2008" aria-hidden="true" tabindex="-1"></a>Unwillingness to Answer: The respondent might have an opinion but chooses not to express it due to a sensitive topic, privacy concerns, or wanting to appear socially desirable (e.g., not wanting to seem extreme or uninformed).</span>
<span id="cb17-2009"><a href="#cb17-2009" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>*Inability to Map Opinion to Scale*: The respondent might have an opinion but feels the provided scale categories are inadequate, too vague, or don&#39;t quite fit their nuanced view. They might feel their true sentiment falls &quot;between&quot; categories or doesn&#39;t align with any.</span>
<span id="cb17-2010"><a href="#cb17-2010" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span>*Question Ambiguity*: The respondent simply might not understand the question, its underlying assumptions, or the terms used, leading them to pick DK as a way out.</span>
<span id="cb17-2011"><a href="#cb17-2011" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-2012"><a href="#cb17-2012" aria-hidden="true" tabindex="-1"></a>The varied meanings of DK emphasize that it&#39;s a rich source of information, not just data to be thrown away or arbitrarily filled in.</span>
<span id="cb17-2013"><a href="#cb17-2013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2014"><a href="#cb17-2014" aria-hidden="true" tabindex="-1"></a>The approach for handling DK responses in the CUB framework is to think of the total population as having two unobserved (latent) groups:</span>
<span id="cb17-2015"><a href="#cb17-2015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2016"><a href="#cb17-2016" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Group A=0: Those who can give a substantive rating on the m-point scale. These people have a genuine underlying feeling or are able to make a choice, even if that choice has some general uncertainty.</span>
<span id="cb17-2017"><a href="#cb17-2017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2018"><a href="#cb17-2018" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Group A=1: Those who cannot (or would not) and would genuinely choose DK if it were an option. This group essentially represents the &quot;true&quot; non-responders when it comes to having a substantive opinion.</span>
<span id="cb17-2019"><a href="#cb17-2019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2020"><a href="#cb17-2020" aria-hidden="true" tabindex="-1"></a>We&#39;ll use $p_{DK}$ to represent the proportion of individuals in the population who would choose DK.</span>
<span id="cb17-2021"><a href="#cb17-2021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2022"><a href="#cb17-2022" aria-hidden="true" tabindex="-1"></a><span class="fu">### Modeling Assumptions for Latent Groups</span></span>
<span id="cb17-2023"><a href="#cb17-2023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2024"><a href="#cb17-2024" aria-hidden="true" tabindex="-1"></a>This approach makes specific assumptions about how each latent group generates responses:</span>
<span id="cb17-2025"><a href="#cb17-2025" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2026"><a href="#cb17-2026" aria-hidden="true" tabindex="-1"></a>For those who can answer (Group A=0, proportion $(1-p_{DK})$): When these individuals provide a substantive rating ($R=r$), their responses are assumed to follow a standard CUB model. This CUB model has its own parameters, $\pi_0$ (for uncertainty within this group) and $\xi_0$ (for feeling within this group), which describe the feeling and uncertainty among those capable of providing an opinion.</span>
<span id="cb17-2027"><a href="#cb17-2027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2028"><a href="#cb17-2028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2029"><a href="#cb17-2029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2030"><a href="#cb17-2030" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2031"><a href="#cb17-2031" aria-hidden="true" tabindex="-1"></a>P(R = r \mid A = 0, \pi_0, \xi_0) = \pi_0B(r\mid\xi_0) + (1-\pi_0)U(r)</span>
<span id="cb17-2032"><a href="#cb17-2032" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2033"><a href="#cb17-2033" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-2034"><a href="#cb17-2034" aria-hidden="true" tabindex="-1"></a>For those who would choose DK (Group A=1, proportion $p_{DK}$), if these individuals are forced to pick a category from the m-point scale (e.g., if the DK option isn&#39;t available, or if their preference for DK is part of their general uncertainty), their choice isn&#39;t based on a genuine &quot;feeling&quot;. Instead, their responses are driven purely by randomness or uncertainty across the available options. So, their responses are modeled by a discrete Uniform distribution.</span>
<span id="cb17-2035"><a href="#cb17-2035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2036"><a href="#cb17-2036" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2037"><a href="#cb17-2037" aria-hidden="true" tabindex="-1"></a>P(R = r\mid A =1) =U(r)= \frac{1}{m}</span>
<span id="cb17-2038"><a href="#cb17-2038" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2039"><a href="#cb17-2039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2040"><a href="#cb17-2040" aria-hidden="true" tabindex="-1"></a>The overall observed distribution of ratings, if all respondents are forced to choose from the m-point scale (meaning no explicit DK option is given, or if we consider the hypothetical responses of those who would pick DK if it were there), is a mix of the CUB model for &quot;knowers&quot; and the Uniform distribution for those &quot;forced&quot; to choose.</span>
<span id="cb17-2041"><a href="#cb17-2041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2042"><a href="#cb17-2042" aria-hidden="true" tabindex="-1"></a><span class="fu">### Adjusting CUB Parameters using Observed DKs</span></span>
<span id="cb17-2043"><a href="#cb17-2043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2044"><a href="#cb17-2044" aria-hidden="true" tabindex="-1"></a>The method proposed in this framework uses the presence of DKs to adjust the fundamental uncertainty in the main CUB model.</span>
<span id="cb17-2045"><a href="#cb17-2045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2046"><a href="#cb17-2046" aria-hidden="true" tabindex="-1"></a>When DK responses are explicitly allowed in a survey and are present in the data the approach proceeds as follows:</span>
<span id="cb17-2047"><a href="#cb17-2047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2048"><a href="#cb17-2048" aria-hidden="true" tabindex="-1"></a><span class="ss">  1. </span>Estimate $p_{DK}$: This is simply the observed proportion of DK responses in the sample.</span>
<span id="cb17-2049"><a href="#cb17-2049" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-2050"><a href="#cb17-2050" aria-hidden="true" tabindex="-1"></a> $$</span>
<span id="cb17-2051"><a href="#cb17-2051" aria-hidden="true" tabindex="-1"></a> \hat{p}_{DK} = \frac{Total\, number\, of\, DK\, responses}{Total\, number\, of\, responses}</span>
<span id="cb17-2052"><a href="#cb17-2052" aria-hidden="true" tabindex="-1"></a> $$</span>
<span id="cb17-2053"><a href="#cb17-2053" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-2054"><a href="#cb17-2054" aria-hidden="true" tabindex="-1"></a><span class="ss"> 2. </span>Focus on **Substantive Responders**: The remaining $(1- \hat{p}_{DK})$ proportion of the sample consists of individuals who gave a rating on the m-point ordinal scale (i.e., they picked a category from $1,…,m$). Let $N_{sub}$ be the number of these substantive responders.  </span>
<span id="cb17-2055"><a href="#cb17-2055" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-2056"><a href="#cb17-2056" aria-hidden="true" tabindex="-1"></a><span class="ss"> 3. </span>**Model for Substantive Responses**: A standard CUB model is then fitted only to these $N_{sub}$ substantive responses. This fitting process gives us estimates for their underlying parameters, called $\pi_S$ and $\xi_S$. This model describes the probability distribution of ratings given that a substantive response was provided:</span>
<span id="cb17-2057"><a href="#cb17-2057" aria-hidden="true" tabindex="-1"></a> $$</span>
<span id="cb17-2058"><a href="#cb17-2058" aria-hidden="true" tabindex="-1"></a> P(R = r \mid Substantive) = \pi_SB(r\mid\xi_S) + (1-\pi_S)U(r)</span>
<span id="cb17-2059"><a href="#cb17-2059" aria-hidden="true" tabindex="-1"></a> $$  </span>
<span id="cb17-2060"><a href="#cb17-2060" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-2061"><a href="#cb17-2061" aria-hidden="true" tabindex="-1"></a><span class="ss"> 4. </span>**Relating to the Overall Population Parameters**: The crucial step is to link these parameters $(\pi_S, \xi_S)$ back to the overall population&#39;s true feeling and uncertainty, taking into account the proportion of DKs.</span>
<span id="cb17-2062"><a href="#cb17-2062" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-2063"><a href="#cb17-2063" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>The feeling parameter for the overall population, $(1-\xi)$, is considered to be best represented by the feeling of those who actually gave a substantive rating. This is based on the idea that people who genuinely say &quot;Don&#39;t Know&quot; don&#39;t contribute to the &quot;feeling&quot; aspect of the scale. So:</span>
<span id="cb17-2064"><a href="#cb17-2064" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2065"><a href="#cb17-2065" aria-hidden="true" tabindex="-1"></a>(1-\xi) = (1-\xi_S)</span>
<span id="cb17-2066"><a href="#cb17-2066" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2067"><a href="#cb17-2067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2068"><a href="#cb17-2068" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>The overall uncertainty parameter for the population, $(1-\pi)$, comes from two sources:</span>
<span id="cb17-2069"><a href="#cb17-2069" aria-hidden="true" tabindex="-1"></a><span class="ss">        * </span>The inherent uncertainty among those who could answer (captured by $1-\pi_S$).</span>
<span id="cb17-2070"><a href="#cb17-2070" aria-hidden="true" tabindex="-1"></a><span class="ss">        * </span>The complete uncertainty of those who chose DK (who are considered 100% uncertain regarding the m-point scale).</span>
<span id="cb17-2071"><a href="#cb17-2071" aria-hidden="true" tabindex="-1"></a>      The overall $\pi$ for the population (the probability that a response is driven by feeling) is then calculated as:</span>
<span id="cb17-2072"><a href="#cb17-2072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2073"><a href="#cb17-2073" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2074"><a href="#cb17-2074" aria-hidden="true" tabindex="-1"></a>\pi = (1-\hat{p}_{DK})\cdot\pi_S</span>
<span id="cb17-2075"><a href="#cb17-2075" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2076"><a href="#cb17-2076" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-2077"><a href="#cb17-2077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2078"><a href="#cb17-2078" aria-hidden="true" tabindex="-1"></a>This means the overall probability that a response is based on feeling ($\pi$) is the probability that a respondent isn&#39;t a DK type $(1-\hat{p}_{DK})$ multiplied by the probability that, given they aren&#39;t a DK type, they respond based on feeling $(\pi_S)$.</span>
<span id="cb17-2079"><a href="#cb17-2079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2080"><a href="#cb17-2080" aria-hidden="true" tabindex="-1"></a>Consequently, the overall uncertainty for the population is:</span>
<span id="cb17-2081"><a href="#cb17-2081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2082"><a href="#cb17-2082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2083"><a href="#cb17-2083" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2084"><a href="#cb17-2084" aria-hidden="true" tabindex="-1"></a>(1-\pi) = 1-(1-\hat{p}_{DK})\cdot\pi_S</span>
<span id="cb17-2085"><a href="#cb17-2085" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2086"><a href="#cb17-2086" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-2087"><a href="#cb17-2087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2088"><a href="#cb17-2088" aria-hidden="true" tabindex="-1"></a>This can be rewritten as:</span>
<span id="cb17-2089"><a href="#cb17-2089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2090"><a href="#cb17-2090" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2091"><a href="#cb17-2091" aria-hidden="true" tabindex="-1"></a>(1-\pi) = \hat{p}_{DK} + (1-\hat{p}_{DK})\cdot(1-\pi_S)</span>
<span id="cb17-2092"><a href="#cb17-2092" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb17-2093"><a href="#cb17-2093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2094"><a href="#cb17-2094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2095"><a href="#cb17-2095" aria-hidden="true" tabindex="-1"></a>This last equation shows that the overall uncertainty in the population is the sum of the proportion of individuals who selected DK $(\hat{p}_{DK})$ and the proportion of uncertainty among those who provided a substantive response $(1-\pi_S)$, weighted by their share of the total population $(1-\hat{p}_{DK})$.</span></code></pre></div>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script id = "quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->

</body>

</html>